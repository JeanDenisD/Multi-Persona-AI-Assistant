{
  "video_id": "7bA0gTroJjw",
  "video_url": "https://www.youtube.com/watch?v=7bA0gTroJjw",
  "video_info": {
    "title": "you need to learn Kubernetes RIGHT NOW!!",
    "uploader": "NetworkChuck",
    "channel": "NetworkChuck",
    "duration": 1774,
    "upload_date": "20200909",
    "view_count": 1367638,
    "description": "Get started with Kubernetes RIGHT NOW with a FREE lab on Linode: ($100 credit) https://bit.ly/nc_linode\n\nLearn Kubernetes with NetworkChuck Academy: https://ntck.co/k8s_beginners\n\n*Sponsored by Linode\n\nLAB GUIDE: https://networkchuck.com/kubernetes/\n\nDIVE DEEPER:\nThis Kubernetes course is awesome: http://bit.ly/k8s_ps (PluralSight affiliate)\nThis book is legit: https://geni.us/POtpFf2 (Kubernetes in Action, affiliate)\n\nüëäüëäüëäsupport the mission, join thisisIT: https://bit.ly/thisisitio\n‚òï‚òïOFFICIAL NetworkChuck Coffee: https://NetworkChuck.coffee ‚òï‚òï\nmy FREE CCNA course: https://bit.ly/nc-ccna\nJoin the Discord server: http://bit.ly/nc-discord\n\n0:00   ‚è© Intro\n0:55   ‚è©  The problem with Docker\n3:11   ‚è©  K8s to the rescue\n3:42   ‚è©  K8s architecture\n4:31   ‚è©  FREE K8s Lab\n7:47   ‚è©  Install KubeCTL\n11:09 ‚è©  K8s Pod\n13:24 ‚è©  a K8s Deployment\n18:45 ‚è©  K8s Service (Load Balancer)\n\nüî•üî•Get your CCNA with BOSONüî•üî•\n-CCNA Lab: https://bit.ly/bosonccna2020 (Boson NetSim) (affiliate)\n-CCNA Practice Exam: https://bit.ly/bosonexsimccna (Boson ExSim) (affiliate)\n-CCNP Lab: https://bit.ly/encornetsim (Boson NetSim) (affiliate)\n-CCNP Practice Exam: https://bit.ly/encorexsim (Boson ExSim) (affiliate)\n\n‚û°Ô∏èSupport NetworkChuck: https://bit.ly/join_networkchuck\n‚òïor buy me a coffee: https://ko-fi.com/networkchuck ‚òï\n\nother FANTASTIC CCNA training resources:\nFULL CCNA course: http://bit.ly/2BJazQG ( @David Bombal  )\nITProTV: https://bit.ly/itprotvnetchuck\n\n\nüî•Learn Pythonüî•\nCodecademy: http://bit.ly/2Me22NH\n\n\n(GEAR I USE...STUFF I RECOMMEND)\n\nMy network gear: https://geni.us/L6wyIUj\n\nAmazon Affiliate Store: https://www.amazon.com/shop/networkchuck\n\nBuy a Raspberry Pi: https://geni.us/aBeqAL\n\n#kubernetes #k8s",
    "tags": [
      "kubernetes tutorial",
      "kubernetes for beginners",
      "learn kubernetes",
      "cloud computing",
      "kubernetes tutorial for beginners",
      "learn kubernetes step by step",
      "kubernetes architecture",
      "docker tutorial",
      "k8s",
      "kubernetes explained",
      "kubernetes networking",
      "kubernetes deployment",
      "kubernetes service",
      "kubeadm",
      "linode",
      "kubernetes linode",
      "kubectl",
      "kubelet",
      "kubeproxy",
      "kubernetes vs docker",
      "docker on kubernetes"
    ]
  },
  "personality": "networkchuck",
  "domain": "technology_networking",
  "expertise_areas": [
    "networking",
    "cybersecurity",
    "linux",
    "cloud",
    "vpn",
    "docker",
    "kubernetes"
  ],
  "language": "en",
  "text": " You need to learn Kubernetes right now. But why? Well, Kubernetes can deploy 100 Docker containers with one command. In this video, I'm going to teach you Kubernetes. We're going to walk through what it is, how do you use it, and you'll even get a chance to lad this up for free. Thanks to our sponsor, Linode. They're giving you a hundred dollar credit for 60 days. So check that out. Link below. I'm going to walk you through a lab in Linode. All right, let's do this. Kubernetes. Kubernetes. K8S. However you say it, it's amazing because it solves a huge problem we have with Docker containers or any kind of container. Like let me show you because you and I, we're going to create a website, a coffee website. We're going to sell network chug coffee and we're going to deploy it on a Docker container. Why? Because Docker is awesome. Isolated environment, better resource utilization, all kinds of stuff. If you want to learn more, if you have no idea what that is, go watch this video right here. You'll want to know more about Docker before you try and learn about Kubernetes because they go hand in hand. So I'll deploy my website in our Docker container. Let's go check it out. There it is. Beautiful. So professional. I mean, gosh, who professionally designed this? And guess what? People are buying our coffee like crazy. The website's doing so great. A little too great. Actually, we're getting so much traffic to our site that it can't handle it. It's crashing. Not only that, but the host it's running on has gone down a few times. We've had a few outages. So what do we do about that? How do we solve it? Pretty simple, right? Let's set up another host. So we get another one. So we set up our second container, running another host. And with Docker, it's so easy. Just one easy command. Boom. And done. But hold up. We're not done yet because we have to make sure that when people hit network.coffee when they visit the website that I could go to this server or this server. We typically do that with a load balancer. So we have to, you know, figure out how to do a load balancer. So we throw that in there. Okay, we're awesome. Both servers are being used because they're load balance. If one goes down, one's still up. We're solid. Well, we were because now people, they love our coffee, man. They're visiting the website like crazy. We're getting so many views and visits and purchases. It's almost like we're putting something in it and our servers can't handle it. They're crashing again. Yeah. So what do we do? We keep scaling out. This time we're going to be prepared. So we're going to add not one server, but two servers. But now the process is kind of getting cumbersome. I have to go in and set up another container on that server and then on this new server. And all dang it. I have to set up the load balancer to load balance between all these guys. So I got to set that up. So I got to add these suckers in there. Okay, we should be good now, right? Wrong. Turns out we're the Amazon of coffee. We're awesome. And we have to add a ton more servers, a ton more containers. We're talking just astronomical numbers. Business is good. So I have to set up and install all those machines and now I have two more load balancers to handle everything. This is too much. I can't do this. Oh, crap. I have to update my website now. We got some new coffee, which is great, but we have to make a change to every one of our containers and every one of our servers. Okay, I'm done. I got two options. I can either hire another engineer to do this for me because I'm done with this or I need another solution. I need to somehow automate this or maybe orchestrate this somehow. Maybe some kind of container orchestration. No any good ones? What about Kubernetes? Let's try that. This is where Kubernetes comes in. It will handle all this junk for us. So let's call up Kubernetes. Say, you know, man, I need some help. We're starting over. I can't do this anymore. Can you help us? And he can. Now we scaled back a bit just to start. So we have our three servers here. Now the good news is that part of the setup is already done. Kubernetes is a container orchestrator. So we're still going to have our servers and we'll still need some type of container runtime, which in our case will be Docker. It could be something else container D rocket or whatever. So just so you know to clear that up. It's not Kubernetes or Docker. It's yes, both. We're going to use both. Kubernetes is going to help us make Docker better. So what do we do? What do we start? We first introduce a new server. Someone who's going to call the shots are master. This guy, he's the boss. He calls the shots with all these servers. He tells them what to do, keeps them in line, make sure that I'm acting up. Now we do need to make our servers part of the team, part of the workforce. So we'll install Kubernetes on these servers. That's going to involve two components. We'll have our cube proxy and our cube lit. I love the names with those two components installed along with their container runtime, which in our case is Docker. They are now part of the team. They are team Kubernetes. They are now worker nodes. Now what these components do we'll cover here in a moment, but just know what's away from the master to control them and make all this Kubernetes goodness happen. Now the master, he's a server just like these guys right here, but he's got some special components, some special roles that we gave him. These are his four jobs or his four components and we'll cover that here in a moment. But for now, I don't know about you, but I want to do something. Theory is fun until it's not. So let's actually start making this. Let's take our network, Chuck coffee website and let's let's orchestrate it. Now hold on one second. Typically setting up Kubernetes is kind of hard. So in our environment here, we have four servers. We have our master server, which we have to install those four components, making it the Kubernetes master. And then we have our three servers here, which are our worker nodes where our containers will run. We'll install Docker, the cube proxy and the cubelit. Again, it's kind of a not really straightforward process, but I do have good news for you. We have an easier way. You see Kubernetes is big in the cloud. Many cloud providers have Kubernetes baked in and it's really easy to get it set up. One of those is Linode, the sponsor of this video. And through their cloud platform, we can go in there and create a Kubernetes cluster. This is called a cluster basically for free. They give you a hundred dollar credit to use for the first 60 days and you can go crazy. Well, not too crazy. And then make it so stupid simple. Let's go do it right now. So go ahead and use my link below. Get signed up and logged in and we'll go through this right now. So once you're in Linode on the left side here, we have a panel. If you scroll down just a little bit, you'll see right here, there it is. Kubernetes, hit that, click it. And they want us to add our first Kubernetes cluster. Let's do that. So we'll click create. Let's label it. It's just a name. We're going to give it. I'll name my networked shut coffee. Word I want it to be. I want it to be close to me. So in Dallas and then version, I'll just select the latest version of 1.17. And now we're on to how many servers do we want? How many worker nodes do we want to have in our cluster? For my lab, I'm going to go with the smaller version, the Linode two gigabytes. I'm going to add three worker nodes by hitting that plus sign right there. Keep in mind, it will be $10 a month. So kind of do that math with your hundred dollar credit you have. Also click on add to add those three nodes to my cluster. And as I scroll down and get my cluster summary, three worker nodes, 30 bucks a month. That's what I'm doing. I'll click create cluster. And now we wait. Coffee break. Let's enjoy our product. All right. If I scroll down to the bottom here, my three nodes are ready. They're running. Awesome. Now, hold on a second though. I see one, two, three worker nodes. Oh, where's my master node? Where is it? This is what's cool about doing Kubernetes on Linode. In the cloud, you pay for everything you use, which is a great model. So I've got my three worker nodes and those are costing me $10 a month. So you would probably assume that with our master node, that would be another server that would cost us $10 a month. No, good guy Linode says, you know what, don't worry about that. We're going to throw in the master for free, which is super cool. But still, where, where is he? How do we use him? Well, if you look at this link right here, this URL, the Kubernetes API endpoint, that's him. That's our master. So back at the master components, one of his components is the Kubernetes API server. That's one of the big ones that we care about because that's how we talk to our master. That's how we tell him what to do. I mean, he's the master, but we're the master master. We're the master of masters. Okay, cool. The Kubernetes API servers, how we communicate with them, but then how do we use that? It's really easy actually. So there's a tool we can install on any machine really. I think it's available for Windows, Mac, and of course, Linux. It's a tool called Cube CTL or Cube Cuddle. It's a command line tool that when we install it, we can then run our commands very, very similar to Docker and make things happen, tell our master what to do, and then he tells the worker nodes what to do. So let's get that Cube Cuddle set up. So here we're going to install it on Linux. So I've got my Kali Linux going. You can use Ubuntu or whatever you want to use. First we'll download the latest release of Cube CTL or Cuddle, Cube Cuddle. I had that link and these steps in the description below. So go ahead and follow that, paste that in there. I'll hit enter and it downloads the release. So I hit LS to list my files and directories. There it is right there, Cube Cuddle. Next we'll want to make sure that file is executable. So I'll use command CHMOD for change modification and then I'll do plus X to make it executable. And I'll do period forward slash cube CTL. That's the file we're going to be editing right now and done. And then I'll move that command to my path. This is important if you want to be able to use it. So we'll do sudo mvremove dot forward slash cube CTL. That's the same file we're looking at. And move that to the forward slash user slash local slash bin slash cube CTL. And hit the enter button, put in your sudo password and done. So Cube Cuddle is installed but how do we access our new cluster we created in Linode? Let's do it real quick. Get back to your Linode dashboard and we scroll up to right here we see cube config. It's a YAML file and it gives us all the information we need to know to connect to our cluster here. You can either download the file or do what I'm going to do right now and that's open up this little paper looking thing here and look at the code. I'm going to copy mine so I'll hit copy. And then I'll get back to my Linux box, my Kali box and we'll create our cube config file. I'm going to use nano to create that new file so I'll hit nano and then cubeconfig dot yaml dot yaml. I'll paste that in there, hit CTRL X and then Y to save. And then one last command to get this ready we'll use the command export cubeconfig all uppercase equals that file cubeconfig dot yaml. Done. So you're done. You're able to connect to your cluster and do stuff but what do we do now? Let's try it out. So the first command we're going to do is we're going to look at our worker nodes. Make sure they're there, okay, alive, are you guys okay? It'll be cubectl get nodes. This is going to get the 411 on our worker nodes that we just created in Linode. Let's check it out. There they are. Awesome. There's their names. They are ready. Only 24 minutes old, so young. Let's enter one more. We'll do cubectl cluster dash info. And we get some cool information right here. Cube DNS we're not going to cover that right now but there's our master right there. I told you that was the master. Okay, so now we have our Kubernetes cluster ready. The master, the worker nodes, we even have our workstation ready. We have the cube cuddle or cubectl tool installed so we can communicate and talk to our master through the Kubernetes API server. But what do we do now? How do we deploy our website? That was the whole point, right? Like how do we solve our problems? The good news is that it's very, very similar to Docker. We'll use a command that looks like this, cubectl and we'll say run. Just like our Docker run command and we'll create our container. Now hold on one second. I got to add one more term for you to know. When we create a container in Kubernetes, we're creating something called. A pod and inside that pod, we have our container. So when you think about Kubernetes, think about pods as containers. Now, technically the containers are inside the pods and you can even have multiple containers inside these pods. Like we can add another one, add another one. But typically you'll have one container per pod, which sounds weird. I know, but let's create one real quick. The command will be cubectl run. Like I just said, I'll name my pod, just name it network check coffee. And then I'll specify my Docker image that I'm going to use. I'll do dash dash image equals and then the image I'm going to pull down, which if you're going to follow along, it'll be this image right here. It'll be the network check forward slash NC coffee and then colon pour over and then we'll open up ports dash dash port equals 80 the website port, you know, HTTP. So we'll do that real quick and go. Created done. If we use a command cubectl get pods, we see it's happening right now. So the container is creating inside that pod. Let's do it again. She kind of, oh, it's done. It's running, but it's just done. We just created our first Kubernetes pod running our container, our website, which seems weird and kind of confusing. I know, trust me, but looking back at our diagram, this is what happened using cubes. E.T.L. We said, Hey, master, I want you to run with this. I want you to create a container for me, which I know will be inside a pod. So I said, cubes E.T.L run blah, blah, blah, do this. And he did using his scheduler component. He goes, Hmm, which one of my worker nodes gets this pod? You know what? This guy right here, he's not doing anything. Hey, hey, Roger. Roger, Roger, Roger, I want you to run this application. Go. And he did. Now I want to look inside this pod. I want to see what's going on. I want to know. So looking back at our Linux box, we can use a command called describe. It'll be cubectl describe. And we'll just put in pods and let's see what happens. Boom. We get the whole load down on what this guy's doing. A lot of information. We got the name network, Chuck coffee. We got his IP address. Every pod is assigned its own IP address. Notice it's not public. It's a private IP address. In fact, it's so private, it's only accessible from Kubernetes notes. We'll talk more about that here in a second. And all this stuff above this line was more pod information below here. We now have our container information. So the container is network.coffee. There's the ID, the image that we pulled down, the ports that are open, and a bunch of other stuff, logs and such. It's great. Now for our coffee company, we don't want to only deploy one container or one pod. We want to deploy a bunch. How do we do that with Kubernetes? That's what he's supposed to do, right? Let me show you. So what we just use the cubectl run command. That's more for like ad hoc, like let me just create a pod real quick. We're now going to try something more, more powerful, more organized, more intentional. It's called a deployment. With our deployment, we're going to say, Hey, master, I don't only want just one pod. I want three, three of what? Well, I want three network, Chuck coffee websites, and I want port 80 open. Now the deployment, instead of just telling him in one command, I want this to happen. We'll actually describe what we want to happen in a file and we'll tell him to look at that file. And I've already got the file built out. Let's go look at it real quick. This is our deployment file. It's a YAML file, just like our cube config earlier. These files that describe how Kubernetes can create our pods and design our infrastructure, we often call these manifest. Notice that Kubernetes is all very ship themed. The word Kubernetes is actually the Greek word for a helmsman or a captain, a person who steers the ship. And of course, ship manifest, things like that. It's all very nautical. And this particular manifest, the kind is obviously going to be a deployment. So here in this file, just a few things I'll show you real quick. We named it. This is going to be a deployment. The app will be named NC coffee replicas. How many of these suckers do we want out there? We specified right here, we want three. And then down here, we're specifying what container we want to use. We're naming our container NC coffee. And then there's our container that we're pulling from the Docker hub. And then of course, we want to use port 80 because that's the website port. So here's what we're going to do. We're going to copy all this mess. I'll have that a link to the file below. We're going to hop back into our terminal here in Linux. I'll create the file, do nano NC coffee deployment. You can use whatever you want to name it. Dot YAML. And then I'll paste that stuff in there and then control X Y enter to save and it's ready. And the command is very simple. Now before we do this, I want to delete our pod that we had earlier. Because if I do cube CTL get pods, he's still sitting there. Let's delete him real quick. So cube CTL delete pods. And I'll just specify his name, network Chuck coffee. And he's gone. How do we get pods again? He sure is gone. So now let's deploy our deployment. The command will be cube CTL apply dash F and then we'll specify that file name and see coffee deployment dot YAML. And that's it. I mean, it's pretty simple, right? All the work, all the know how is in that file and I'll hit enter. Done. So if I do real quick, I want to go fast, cube CTL get pods. Look, they're creating. So they're already done. They're already done. Okay, cool. And just like that, three containers, three pods created. And here's the cool part about Kubernetes. It's the concept of desired state that manifest file that deployment is saying, Hey, Kubernetes master, I want there to always be three pods with this image running always not to not for not 12, I want three. And he will constantly make sure that's the case. Be going, okay, so that manifests out. Okay. Yeah. Okay. We're good. And he's always making sure it's that state or desired state. Now, if you were to change that manifest file, we can like, let's say, you know, three isn't cutting it for me anymore. I want, I want 10. Let's do 10. We can edit that file. So let me do control L to clear it out here. I'll do a cube CTL edit deployment and whatever we name our deployment, which I believe was NC coffee deployment. Is that what it was? No, that's not what it was. I'm going to do a cube CTL and get deployments. There it is right there. That's another cool command, right? We can see our deployment right there three up to date, three available. Awesome. So now let's actually edit it. Cube CTL edit network Chuck coffee dash deployment. Now I got to specify deployment there. So let's scroll down to the replicas right here. I'm going to hit I to insert and start editing. I'll delete the three and let's put in 10. So this is going to be VI not nano. So I'll hit escape colon WQ to write and quit and enter. It's been updated. So let's let's do this real quick. Cube CTL get pods. It already started creating them. Look at that. That's amazing. Right. And just like that, 10 pods running. This is the, the commander, the helmsman, Kubernetes, the master. He was like, Oh, we got an updated manifest. Let me check it out. Oh, G. O. Lakers. We need 10. He talks like that. We need 10 of these, these 10 going right now and he does it. Now 10, we only have three servers, right? Like we looking back at our diagram here, we have three servers. How can we have 10 containers and pods? Well, that's the thing. You can have a bunch of pods of the same type on one node. That's fine. We're going to do the scheduler's job. The master with a scheduler component will look at all his worker nodes, figure out how busy they are and assign things, give them jobs. Again, if Rogers over there just kind of chilling out, he goes, Hey, you know, Roger can afford to do a few extra things. I'm going to give him something. I know the cool view of our pods is a cube CTL get pods dash O and wide. And we can see their name and their IP address and what server they're running on or what worker node they're serve. They're running on. This guy right here, he's running on blah, blah, blah. The end of it is 233. This guy's running on blah, blah, blah. The end of it is 712 and they're all distributed kind of evenly, right? And it's the job of the master node to keep monitoring that process to make sure that any one worker node isn't overworked. And if they are overworked, he'll take away those pods. I'll say, Hey, you know what? You're too busy. Let me take some of that work off you. He'll remove the pod and then give it to someone else. Now we still have a problem here though. Things are awesome. Actually, we, we ran our deployment and we've got a million pods out there, 10. But every one of these pods has an internal IP address and IP address that we can't access like a wet like we can't go to our web browser and and put the IP address in. It won't happen. Like right now your stuff, your website, our website cannot be accessed. How do we fix that? Well, we have to expose it. This is where the true power of Kubernetes comes in. I know at this point it's like, okay, Chuck, I'm not seeing the big picture. How is Kubernetes helping us with all this stuff? We're about to unwrap it here right now. It's cool that we can deploy pods like crazy. We can even say if our pods start to get stressed out, let's say they go over 712 percent of utilization on the CPU. I want you to scale out. I want you to go from 10 to 20 or 20 to 30. The master can monitor the metrics of your, your cluster and make sure your website's doing great. If your website isn't, well, then we better get some more stuff going. But anyways, let's talk about how we can get our website accessible to the outside world. So in order for Johnny right here to buy our coffee, to get to our websites and get to our pods, we have to expose them. But right now they're not exposed. In Kubernetes, when you want to expose a pod or a group of pods to a network, we're going to deploy a service. This will expose our pods to the internet like we want, and it'll actually be a load balancer. So when Johnny tries to access, it'll hit that service and the service will expose the pods and also load balance between the pods. So let's deploy that service right now. And just like our deployment, our service will be described in a YAML file, another manifest. Actually just a set of instructions to give our master saying, Hey, master, make this happen buddy. So a few things here real quick. The kind is a service. We're naming it coffee service. And then down here in the server specs, we have what type of service is going to be. It's going to be a load balancer. We're load balancing port 80 on both the load balancer and the pod website traffic. And then here's the important part and the killer thing about this, the selector, which pods are we going to load balance? It'll be any pod that has the app label and see coffee. This is important because if you look back at our deployment where we deployed our pods, our app label for our pods was NC coffee. So any pods that has the app label and see coffee, that low balance is going to load balance between those. So here's what's killer about that is that if we create two pods, it's going to load balance that as long as it has a label and see coffee. If we create 2000 pods, as long as it has the label and see coffee, it's going to load balance between those 2000 pods. It's just automatic. We don't have to worry about it once you create it. So let's do it. So just as before, I'm going to copy all this code here, this YAML, and I'll get back into my Linux box. Create a new file, nano coffee dash service dot YAML, paste that in there and do a control X to save Y for yes and get out of there. And then we'll apply that service. And all we have to do is a cube CTL, just like before, we'll do apply dash F to specify our template, our manifest, and it'll be coffee dash service dot YAML dot YAML. And let's do it. It's doing something very exciting. I'm going to, okay, I'm just going to enter this command. Cube CTL gets services. This is a service we're looking at now. And there it is right there, coffee service. And it's already done. Crazy fast. Now what's cool about this is that it created a load balancer in Kubernetes, but it also created a load balancer in our cloud provider. Remember I told you that Kubernetes loves cloud providers and then the love goes both ways. So when I do this command, it actually created what's called a node balancer in Linode. Let's go check it out real quick. In Linode, I'll go back to my side menu here. And right here is a node balancer. It's just their clever name for their load balancers. Click on that. There it is right there. My node balancer was created. You see that IP address right there? It's the same exact one. It's what we're seeing here in the Kubernetes master, the external IP right there. And we can see in the Linode portal in our backend status, we have three nodes up, which is our three worker nodes. But in Kubernetes, it's a load balancing between 10 pods. Let's see if it worked. Let's go to our website. We have the IP address. Open up a new tab and see if it worked. Bam. There's our coffee website being low balanced across 10 pods in Kubernetes. It's running. It's working. It's alive. And we can go in here and buy all the coffee we need. And so you believe me about the Kubernetes stuff. I want to show you how to look at that service and verify it's going between your 10 pods. If we do cube CTL, get services and we'll specify our coffee service. We'll get the low down. Sorry, not get. Describe. We want to describe that service. So describe services. Describe is always getting more detail. Coffee dash service. And there's all the beautiful information we want to see about this. And then right here are end points, these few suckers and then seven more. It's going to be low balancing for. So cool. Amazing. Oh, now hold on. You know what I realized? Looking at our coffee, we get a new coffee in Peru decaf and all we have is Peru. So now we have to update our website. Not too bad with Kubernetes. Let's try it out real quick. We've already got the Docker image out there. The Docker image is ready to go. All we have to do is pull it and put it out to our, what, 10 containers now, 10 pods. Let's do that right now. Back at our Linux box. I'm going to edit my deployment. So I'll do cube CTL, edit deployment. And it was network Chuck coffee dash deployment. Why did I make it so long? There we go. Okay. Two things I want to change right now. First is I want, instead of 10 servers, I want to go. The 20 servers. Why not? And then I'm going to change the image I'm looking for instead of a network check coffee slash NC coffee, colon, pour over the new label I'm going to use is vac pot. That's our latest version. So I'm changing the images going to pull from if you want to follow along, you can do this same thing right now. I'm going to hit escape colon WQ to write and quit and hit enter. It's been updated. It's been edited. And what should be happening now is if I do cube CTL, get pods. I should have a bunch of new pods. Now see it's creating some new ones and terminating old ones because it's updating the existing ones. And now just like that. Look at that. It's so crazy. So now we have 20 pods. The 10 we already had or updated. They were killed, brought down, terminated. You're fired. And we created 10 new ones with that new image. And then we added 10 more with that new image. And if we look at our load balancer, if I do cube CTL, get services. And I look at my load balancer again. So I do cube CTL, describe services, coffee dash service. Look at that. My endpoints, it's automatically load balancing between the 20. That's powerful. I save myself a lot of time now. When I update my website, I update it in one place, my Docker image. And then I just update my manifest file and the rest is history. How great, how amazing is that? Let's see if the website works though, by the way. Let's see if our Peru decaf has been added. So I'll just refresh this page. There it is. There it is. Oh my gosh. How exciting is that? Kubernetes, truly container orchestration, container automation. Now I just scratched the stinking surface with Kubernetes. So much I glossed over and so much you can do. If you want to dive deeper, it's right here in your website. First of all, if you don't know what a Docker container is, go watch my video. That's a link to that. What I used to go a bit deeper with Kubernetes is first this Pluralsight course by Nigel, Trevor's name is great. Fantastic. Check that out. And then a book called Kubernetes in Action. It is insanely detailed and amazing. Go check that out. And of course, if you want to support more of what I'm doing, go check out this is IT and support the mission. Now, if you haven't already, you can do this live yourself. Go sign up for a free account with Lenoade. You get $100 of credit just to play with and use and you can do this. So check it out. Link below and thanks to Lenoade for doing that and for sponsoring this video. Now real quick, if you did it already, make sure you clean up after yourself. And what I mean is you don't want to leave this running open-ended because you'll see a bill if you leave it going forever. So what I would do is once you're done playing, get to your Lenoade dashboard, go to the Kubernetes cluster and you can click your little dots here at the bottom right and say delete. You'll see, are you sure? You really want to do this? And yeah, I do. So just put your cluster name in there, network.coffee and click on delete. And it goes away. It goes away. And then it will cost you money being charged to you. And then also don't forget about the node balancers that will not go away by itself, I don't believe. So if you go to the left panel here, go to node balancers. There's the one you should have there. Same thing. Click on the dots and click delete and it goes away. That node balancer also does cost money. I think it's about $10 a month as well. And that's Kubernetes. It's kind of an intense thing to learn because you already have to know about Docker containers and then you build on that knowledge by learning about the container orchestration, which is really cool. But it can be very complex. Now if you want to play with Kubernetes more, of course you can do that in the cloud. Most cloud providers have Kubernetes built in. That's one of the reasons you should learn Kubernetes because it makes you more valuable when you're going down that cloud path. If you know how to operate and use Kubernetes, valuable skill. But as far as having your own lab, you can run Kubernetes in your own lab on bare metal servers, on virtual machines, or even just on your one computer. They have what's called Minicube. And you can just run Kubernetes on one workstation. That's pretty cool. So there are options. But anyways, let me know what you think in the comments below. Let me know if you're able to go through the lab. If you think Kubernetes is amazing, just let me know below. I love seeing your comments and it really encourages me to keep going and keep making videos like this. Well, that's all I got. This video took a lot. I had to learn Kubernetes from the ground up. But it's fun learning new things. And I encourage you to do what I did. When you learn something new like this, turn it around and make a video about it or make a blog post. Teach someone about it. Really two things happen. You learn it better when you teach it. And also you're helping people. You're helping someone else who's coming behind you to learn that same technology. And then third, kind of a bonus, it shows future employers that you can first of all communicate and learn something new. You're hungry for knowledge. Anyways, yeah, that's really all I got. I'm going to stop talking now. If you haven't already hit that like button. If you like the video, it does help. Subscribe, notification bell, you know, all that stuff. And if you want to help me do more of this, make training, make videos, make certification stuff, check out this as IT or hit the join button on the YouTube thing below. Or you know what? You can buy some network check copy because it's a legit thing. Go to networkcheck.coffee. You can actually go to my real website. Well guys, that's all I got. I'll catch you later.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 2.4,
      "text": " You need to learn Kubernetes right now.",
      "tokens": [
        50364,
        509,
        643,
        281,
        1466,
        23145,
        558,
        586,
        13,
        50484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20917810712541854,
      "compression_ratio": 1.6688963210702341,
      "no_speech_prob": 0.07704503834247589
    },
    {
      "id": 1,
      "seek": 0,
      "start": 2.4,
      "end": 3.1,
      "text": " But why?",
      "tokens": [
        50484,
        583,
        983,
        30,
        50519
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20917810712541854,
      "compression_ratio": 1.6688963210702341,
      "no_speech_prob": 0.07704503834247589
    },
    {
      "id": 2,
      "seek": 0,
      "start": 3.1,
      "end": 6.7,
      "text": " Well, Kubernetes can deploy 100 Docker containers with one command.",
      "tokens": [
        50519,
        1042,
        11,
        23145,
        393,
        7274,
        2319,
        33772,
        17089,
        365,
        472,
        5622,
        13,
        50699
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20917810712541854,
      "compression_ratio": 1.6688963210702341,
      "no_speech_prob": 0.07704503834247589
    },
    {
      "id": 3,
      "seek": 0,
      "start": 10.200000000000001,
      "end": 12.3,
      "text": " In this video, I'm going to teach you Kubernetes.",
      "tokens": [
        50874,
        682,
        341,
        960,
        11,
        286,
        478,
        516,
        281,
        2924,
        291,
        23145,
        13,
        50979
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20917810712541854,
      "compression_ratio": 1.6688963210702341,
      "no_speech_prob": 0.07704503834247589
    },
    {
      "id": 4,
      "seek": 0,
      "start": 12.3,
      "end": 14.5,
      "text": " We're going to walk through what it is, how do you use it,",
      "tokens": [
        50979,
        492,
        434,
        516,
        281,
        1792,
        807,
        437,
        309,
        307,
        11,
        577,
        360,
        291,
        764,
        309,
        11,
        51089
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20917810712541854,
      "compression_ratio": 1.6688963210702341,
      "no_speech_prob": 0.07704503834247589
    },
    {
      "id": 5,
      "seek": 0,
      "start": 14.5,
      "end": 16.9,
      "text": " and you'll even get a chance to lad this up for free.",
      "tokens": [
        51089,
        293,
        291,
        603,
        754,
        483,
        257,
        2931,
        281,
        6632,
        341,
        493,
        337,
        1737,
        13,
        51209
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20917810712541854,
      "compression_ratio": 1.6688963210702341,
      "no_speech_prob": 0.07704503834247589
    },
    {
      "id": 6,
      "seek": 0,
      "start": 16.9,
      "end": 18.2,
      "text": " Thanks to our sponsor, Linode.",
      "tokens": [
        51209,
        2561,
        281,
        527,
        16198,
        11,
        9355,
        1429,
        13,
        51274
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20917810712541854,
      "compression_ratio": 1.6688963210702341,
      "no_speech_prob": 0.07704503834247589
    },
    {
      "id": 7,
      "seek": 0,
      "start": 18.2,
      "end": 20.400000000000002,
      "text": " They're giving you a hundred dollar credit for 60 days.",
      "tokens": [
        51274,
        814,
        434,
        2902,
        291,
        257,
        3262,
        7241,
        5397,
        337,
        4060,
        1708,
        13,
        51384
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20917810712541854,
      "compression_ratio": 1.6688963210702341,
      "no_speech_prob": 0.07704503834247589
    },
    {
      "id": 8,
      "seek": 0,
      "start": 20.400000000000002,
      "end": 21.0,
      "text": " So check that out.",
      "tokens": [
        51384,
        407,
        1520,
        300,
        484,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20917810712541854,
      "compression_ratio": 1.6688963210702341,
      "no_speech_prob": 0.07704503834247589
    },
    {
      "id": 9,
      "seek": 0,
      "start": 21.0,
      "end": 21.5,
      "text": " Link below.",
      "tokens": [
        51414,
        8466,
        2507,
        13,
        51439
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20917810712541854,
      "compression_ratio": 1.6688963210702341,
      "no_speech_prob": 0.07704503834247589
    },
    {
      "id": 10,
      "seek": 0,
      "start": 21.5,
      "end": 23.900000000000002,
      "text": " I'm going to walk you through a lab in Linode.",
      "tokens": [
        51439,
        286,
        478,
        516,
        281,
        1792,
        291,
        807,
        257,
        2715,
        294,
        9355,
        1429,
        13,
        51559
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20917810712541854,
      "compression_ratio": 1.6688963210702341,
      "no_speech_prob": 0.07704503834247589
    },
    {
      "id": 11,
      "seek": 0,
      "start": 23.900000000000002,
      "end": 25.400000000000002,
      "text": " All right, let's do this.",
      "tokens": [
        51559,
        1057,
        558,
        11,
        718,
        311,
        360,
        341,
        13,
        51634
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20917810712541854,
      "compression_ratio": 1.6688963210702341,
      "no_speech_prob": 0.07704503834247589
    },
    {
      "id": 12,
      "seek": 0,
      "start": 25.400000000000002,
      "end": 26.2,
      "text": " Kubernetes.",
      "tokens": [
        51634,
        23145,
        13,
        51674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20917810712541854,
      "compression_ratio": 1.6688963210702341,
      "no_speech_prob": 0.07704503834247589
    },
    {
      "id": 13,
      "seek": 0,
      "start": 26.2,
      "end": 27.6,
      "text": " Kubernetes.",
      "tokens": [
        51674,
        23145,
        13,
        51744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20917810712541854,
      "compression_ratio": 1.6688963210702341,
      "no_speech_prob": 0.07704503834247589
    },
    {
      "id": 14,
      "seek": 0,
      "start": 27.6,
      "end": 28.6,
      "text": " K8S.",
      "tokens": [
        51744,
        591,
        23,
        50,
        13,
        51794
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20917810712541854,
      "compression_ratio": 1.6688963210702341,
      "no_speech_prob": 0.07704503834247589
    },
    {
      "id": 15,
      "seek": 2860,
      "start": 28.6,
      "end": 31.8,
      "text": " However you say it, it's amazing because it solves a huge problem",
      "tokens": [
        50364,
        2908,
        291,
        584,
        309,
        11,
        309,
        311,
        2243,
        570,
        309,
        39890,
        257,
        2603,
        1154,
        50524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13648193359375,
      "compression_ratio": 1.8186813186813187,
      "no_speech_prob": 0.004390504211187363
    },
    {
      "id": 16,
      "seek": 2860,
      "start": 31.8,
      "end": 34.2,
      "text": " we have with Docker containers or any kind of container.",
      "tokens": [
        50524,
        321,
        362,
        365,
        33772,
        17089,
        420,
        604,
        733,
        295,
        10129,
        13,
        50644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13648193359375,
      "compression_ratio": 1.8186813186813187,
      "no_speech_prob": 0.004390504211187363
    },
    {
      "id": 17,
      "seek": 2860,
      "start": 34.2,
      "end": 37.300000000000004,
      "text": " Like let me show you because you and I, we're going to create a website,",
      "tokens": [
        50644,
        1743,
        718,
        385,
        855,
        291,
        570,
        291,
        293,
        286,
        11,
        321,
        434,
        516,
        281,
        1884,
        257,
        3144,
        11,
        50799
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13648193359375,
      "compression_ratio": 1.8186813186813187,
      "no_speech_prob": 0.004390504211187363
    },
    {
      "id": 18,
      "seek": 2860,
      "start": 37.300000000000004,
      "end": 38.1,
      "text": " a coffee website.",
      "tokens": [
        50799,
        257,
        4982,
        3144,
        13,
        50839
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13648193359375,
      "compression_ratio": 1.8186813186813187,
      "no_speech_prob": 0.004390504211187363
    },
    {
      "id": 19,
      "seek": 2860,
      "start": 38.1,
      "end": 41.1,
      "text": " We're going to sell network chug coffee and we're going to deploy it",
      "tokens": [
        50839,
        492,
        434,
        516,
        281,
        3607,
        3209,
        417,
        697,
        4982,
        293,
        321,
        434,
        516,
        281,
        7274,
        309,
        50989
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13648193359375,
      "compression_ratio": 1.8186813186813187,
      "no_speech_prob": 0.004390504211187363
    },
    {
      "id": 20,
      "seek": 2860,
      "start": 41.1,
      "end": 42.1,
      "text": " on a Docker container.",
      "tokens": [
        50989,
        322,
        257,
        33772,
        10129,
        13,
        51039
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13648193359375,
      "compression_ratio": 1.8186813186813187,
      "no_speech_prob": 0.004390504211187363
    },
    {
      "id": 21,
      "seek": 2860,
      "start": 42.1,
      "end": 42.6,
      "text": " Why?",
      "tokens": [
        51039,
        1545,
        30,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13648193359375,
      "compression_ratio": 1.8186813186813187,
      "no_speech_prob": 0.004390504211187363
    },
    {
      "id": 22,
      "seek": 2860,
      "start": 42.6,
      "end": 44.0,
      "text": " Because Docker is awesome.",
      "tokens": [
        51064,
        1436,
        33772,
        307,
        3476,
        13,
        51134
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13648193359375,
      "compression_ratio": 1.8186813186813187,
      "no_speech_prob": 0.004390504211187363
    },
    {
      "id": 23,
      "seek": 2860,
      "start": 44.0,
      "end": 46.900000000000006,
      "text": " Isolated environment, better resource utilization, all kinds of stuff.",
      "tokens": [
        51134,
        1119,
        401,
        770,
        2823,
        11,
        1101,
        7684,
        37074,
        11,
        439,
        3685,
        295,
        1507,
        13,
        51279
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13648193359375,
      "compression_ratio": 1.8186813186813187,
      "no_speech_prob": 0.004390504211187363
    },
    {
      "id": 24,
      "seek": 2860,
      "start": 46.900000000000006,
      "end": 49.3,
      "text": " If you want to learn more, if you have no idea what that is,",
      "tokens": [
        51279,
        759,
        291,
        528,
        281,
        1466,
        544,
        11,
        498,
        291,
        362,
        572,
        1558,
        437,
        300,
        307,
        11,
        51399
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13648193359375,
      "compression_ratio": 1.8186813186813187,
      "no_speech_prob": 0.004390504211187363
    },
    {
      "id": 25,
      "seek": 2860,
      "start": 49.3,
      "end": 50.6,
      "text": " go watch this video right here.",
      "tokens": [
        51399,
        352,
        1159,
        341,
        960,
        558,
        510,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13648193359375,
      "compression_ratio": 1.8186813186813187,
      "no_speech_prob": 0.004390504211187363
    },
    {
      "id": 26,
      "seek": 2860,
      "start": 50.6,
      "end": 53.7,
      "text": " You'll want to know more about Docker before you try and learn about Kubernetes",
      "tokens": [
        51464,
        509,
        603,
        528,
        281,
        458,
        544,
        466,
        33772,
        949,
        291,
        853,
        293,
        1466,
        466,
        23145,
        51619
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13648193359375,
      "compression_ratio": 1.8186813186813187,
      "no_speech_prob": 0.004390504211187363
    },
    {
      "id": 27,
      "seek": 2860,
      "start": 53.7,
      "end": 55.400000000000006,
      "text": " because they go hand in hand.",
      "tokens": [
        51619,
        570,
        436,
        352,
        1011,
        294,
        1011,
        13,
        51704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13648193359375,
      "compression_ratio": 1.8186813186813187,
      "no_speech_prob": 0.004390504211187363
    },
    {
      "id": 28,
      "seek": 2860,
      "start": 55.400000000000006,
      "end": 57.8,
      "text": " So I'll deploy my website in our Docker container.",
      "tokens": [
        51704,
        407,
        286,
        603,
        7274,
        452,
        3144,
        294,
        527,
        33772,
        10129,
        13,
        51824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13648193359375,
      "compression_ratio": 1.8186813186813187,
      "no_speech_prob": 0.004390504211187363
    },
    {
      "id": 29,
      "seek": 5780,
      "start": 57.8,
      "end": 58.699999999999996,
      "text": " Let's go check it out.",
      "tokens": [
        50364,
        961,
        311,
        352,
        1520,
        309,
        484,
        13,
        50409
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 30,
      "seek": 5780,
      "start": 58.699999999999996,
      "end": 59.599999999999994,
      "text": " There it is.",
      "tokens": [
        50409,
        821,
        309,
        307,
        13,
        50454
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 31,
      "seek": 5780,
      "start": 59.599999999999994,
      "end": 60.3,
      "text": " Beautiful.",
      "tokens": [
        50454,
        14724,
        13,
        50489
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 32,
      "seek": 5780,
      "start": 60.3,
      "end": 61.4,
      "text": " So professional.",
      "tokens": [
        50489,
        407,
        4843,
        13,
        50544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 33,
      "seek": 5780,
      "start": 61.4,
      "end": 64.1,
      "text": " I mean, gosh, who professionally designed this?",
      "tokens": [
        50544,
        286,
        914,
        11,
        6502,
        11,
        567,
        27941,
        4761,
        341,
        30,
        50679
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 34,
      "seek": 5780,
      "start": 64.1,
      "end": 64.8,
      "text": " And guess what?",
      "tokens": [
        50679,
        400,
        2041,
        437,
        30,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 35,
      "seek": 5780,
      "start": 64.8,
      "end": 66.5,
      "text": " People are buying our coffee like crazy.",
      "tokens": [
        50714,
        3432,
        366,
        6382,
        527,
        4982,
        411,
        3219,
        13,
        50799
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 36,
      "seek": 5780,
      "start": 66.5,
      "end": 68.5,
      "text": " The website's doing so great.",
      "tokens": [
        50799,
        440,
        3144,
        311,
        884,
        370,
        869,
        13,
        50899
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 37,
      "seek": 5780,
      "start": 68.5,
      "end": 69.3,
      "text": " A little too great.",
      "tokens": [
        50899,
        316,
        707,
        886,
        869,
        13,
        50939
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 38,
      "seek": 5780,
      "start": 69.3,
      "end": 74.1,
      "text": " Actually, we're getting so much traffic to our site that it can't handle it.",
      "tokens": [
        50939,
        5135,
        11,
        321,
        434,
        1242,
        370,
        709,
        6419,
        281,
        527,
        3621,
        300,
        309,
        393,
        380,
        4813,
        309,
        13,
        51179
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 39,
      "seek": 5780,
      "start": 74.1,
      "end": 74.9,
      "text": " It's crashing.",
      "tokens": [
        51179,
        467,
        311,
        26900,
        13,
        51219
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 40,
      "seek": 5780,
      "start": 74.9,
      "end": 78.4,
      "text": " Not only that, but the host it's running on has gone down a few times.",
      "tokens": [
        51219,
        1726,
        787,
        300,
        11,
        457,
        264,
        3975,
        309,
        311,
        2614,
        322,
        575,
        2780,
        760,
        257,
        1326,
        1413,
        13,
        51394
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 41,
      "seek": 5780,
      "start": 78.4,
      "end": 79.4,
      "text": " We've had a few outages.",
      "tokens": [
        51394,
        492,
        600,
        632,
        257,
        1326,
        484,
        1660,
        13,
        51444
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 42,
      "seek": 5780,
      "start": 79.4,
      "end": 80.2,
      "text": " So what do we do about that?",
      "tokens": [
        51444,
        407,
        437,
        360,
        321,
        360,
        466,
        300,
        30,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 43,
      "seek": 5780,
      "start": 80.2,
      "end": 81.2,
      "text": " How do we solve it?",
      "tokens": [
        51484,
        1012,
        360,
        321,
        5039,
        309,
        30,
        51534
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 44,
      "seek": 5780,
      "start": 81.2,
      "end": 82.2,
      "text": " Pretty simple, right?",
      "tokens": [
        51534,
        10693,
        2199,
        11,
        558,
        30,
        51584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 45,
      "seek": 5780,
      "start": 82.2,
      "end": 83.6,
      "text": " Let's set up another host.",
      "tokens": [
        51584,
        961,
        311,
        992,
        493,
        1071,
        3975,
        13,
        51654
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 46,
      "seek": 5780,
      "start": 83.6,
      "end": 84.6,
      "text": " So we get another one.",
      "tokens": [
        51654,
        407,
        321,
        483,
        1071,
        472,
        13,
        51704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 47,
      "seek": 5780,
      "start": 84.6,
      "end": 87.4,
      "text": " So we set up our second container, running another host.",
      "tokens": [
        51704,
        407,
        321,
        992,
        493,
        527,
        1150,
        10129,
        11,
        2614,
        1071,
        3975,
        13,
        51844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12159235398847978,
      "compression_ratio": 1.7227138643067847,
      "no_speech_prob": 0.0020027293357998133
    },
    {
      "id": 48,
      "seek": 8740,
      "start": 87.4,
      "end": 88.60000000000001,
      "text": " And with Docker, it's so easy.",
      "tokens": [
        50364,
        400,
        365,
        33772,
        11,
        309,
        311,
        370,
        1858,
        13,
        50424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 49,
      "seek": 8740,
      "start": 88.60000000000001,
      "end": 90.2,
      "text": " Just one easy command.",
      "tokens": [
        50424,
        1449,
        472,
        1858,
        5622,
        13,
        50504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 50,
      "seek": 8740,
      "start": 90.2,
      "end": 91.2,
      "text": " Boom.",
      "tokens": [
        50504,
        15523,
        13,
        50554
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 51,
      "seek": 8740,
      "start": 91.2,
      "end": 92.2,
      "text": " And done.",
      "tokens": [
        50554,
        400,
        1096,
        13,
        50604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 52,
      "seek": 8740,
      "start": 92.2,
      "end": 92.60000000000001,
      "text": " But hold up.",
      "tokens": [
        50604,
        583,
        1797,
        493,
        13,
        50624
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 53,
      "seek": 8740,
      "start": 92.60000000000001,
      "end": 96.10000000000001,
      "text": " We're not done yet because we have to make sure that when people hit network.coffee",
      "tokens": [
        50624,
        492,
        434,
        406,
        1096,
        1939,
        570,
        321,
        362,
        281,
        652,
        988,
        300,
        562,
        561,
        2045,
        3209,
        13,
        1291,
        4617,
        50799
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 54,
      "seek": 8740,
      "start": 96.10000000000001,
      "end": 99.60000000000001,
      "text": " when they visit the website that I could go to this server or this server.",
      "tokens": [
        50799,
        562,
        436,
        3441,
        264,
        3144,
        300,
        286,
        727,
        352,
        281,
        341,
        7154,
        420,
        341,
        7154,
        13,
        50974
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 55,
      "seek": 8740,
      "start": 99.60000000000001,
      "end": 100.9,
      "text": " We typically do that with a load balancer.",
      "tokens": [
        50974,
        492,
        5850,
        360,
        300,
        365,
        257,
        3677,
        3119,
        28347,
        13,
        51039
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 56,
      "seek": 8740,
      "start": 100.9,
      "end": 103.30000000000001,
      "text": " So we have to, you know, figure out how to do a load balancer.",
      "tokens": [
        51039,
        407,
        321,
        362,
        281,
        11,
        291,
        458,
        11,
        2573,
        484,
        577,
        281,
        360,
        257,
        3677,
        3119,
        28347,
        13,
        51159
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 57,
      "seek": 8740,
      "start": 103.30000000000001,
      "end": 104.7,
      "text": " So we throw that in there.",
      "tokens": [
        51159,
        407,
        321,
        3507,
        300,
        294,
        456,
        13,
        51229
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 58,
      "seek": 8740,
      "start": 104.7,
      "end": 105.60000000000001,
      "text": " Okay, we're awesome.",
      "tokens": [
        51229,
        1033,
        11,
        321,
        434,
        3476,
        13,
        51274
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 59,
      "seek": 8740,
      "start": 105.60000000000001,
      "end": 107.5,
      "text": " Both servers are being used because they're load balance.",
      "tokens": [
        51274,
        6767,
        15909,
        366,
        885,
        1143,
        570,
        436,
        434,
        3677,
        4772,
        13,
        51369
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 60,
      "seek": 8740,
      "start": 107.5,
      "end": 109.60000000000001,
      "text": " If one goes down, one's still up.",
      "tokens": [
        51369,
        759,
        472,
        1709,
        760,
        11,
        472,
        311,
        920,
        493,
        13,
        51474
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 61,
      "seek": 8740,
      "start": 109.60000000000001,
      "end": 110.5,
      "text": " We're solid.",
      "tokens": [
        51474,
        492,
        434,
        5100,
        13,
        51519
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 62,
      "seek": 8740,
      "start": 110.5,
      "end": 113.9,
      "text": " Well, we were because now people, they love our coffee, man.",
      "tokens": [
        51519,
        1042,
        11,
        321,
        645,
        570,
        586,
        561,
        11,
        436,
        959,
        527,
        4982,
        11,
        587,
        13,
        51689
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 63,
      "seek": 8740,
      "start": 113.9,
      "end": 115.80000000000001,
      "text": " They're visiting the website like crazy.",
      "tokens": [
        51689,
        814,
        434,
        11700,
        264,
        3144,
        411,
        3219,
        13,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13447192492406013,
      "compression_ratio": 1.8297872340425532,
      "no_speech_prob": 0.0033498546108603477
    },
    {
      "id": 64,
      "seek": 11580,
      "start": 115.8,
      "end": 119.0,
      "text": " We're getting so many views and visits and purchases.",
      "tokens": [
        50364,
        492,
        434,
        1242,
        370,
        867,
        6809,
        293,
        17753,
        293,
        26762,
        13,
        50524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11443503096296981,
      "compression_ratio": 1.8150289017341041,
      "no_speech_prob": 0.0029551030602306128
    },
    {
      "id": 65,
      "seek": 11580,
      "start": 119.0,
      "end": 122.2,
      "text": " It's almost like we're putting something in it and our servers can't handle it.",
      "tokens": [
        50524,
        467,
        311,
        1920,
        411,
        321,
        434,
        3372,
        746,
        294,
        309,
        293,
        527,
        15909,
        393,
        380,
        4813,
        309,
        13,
        50684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11443503096296981,
      "compression_ratio": 1.8150289017341041,
      "no_speech_prob": 0.0029551030602306128
    },
    {
      "id": 66,
      "seek": 11580,
      "start": 122.2,
      "end": 123.39999999999999,
      "text": " They're crashing again.",
      "tokens": [
        50684,
        814,
        434,
        26900,
        797,
        13,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11443503096296981,
      "compression_ratio": 1.8150289017341041,
      "no_speech_prob": 0.0029551030602306128
    },
    {
      "id": 67,
      "seek": 11580,
      "start": 123.39999999999999,
      "end": 124.0,
      "text": " Yeah.",
      "tokens": [
        50744,
        865,
        13,
        50774
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11443503096296981,
      "compression_ratio": 1.8150289017341041,
      "no_speech_prob": 0.0029551030602306128
    },
    {
      "id": 68,
      "seek": 11580,
      "start": 124.0,
      "end": 124.89999999999999,
      "text": " So what do we do?",
      "tokens": [
        50774,
        407,
        437,
        360,
        321,
        360,
        30,
        50819
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11443503096296981,
      "compression_ratio": 1.8150289017341041,
      "no_speech_prob": 0.0029551030602306128
    },
    {
      "id": 69,
      "seek": 11580,
      "start": 124.89999999999999,
      "end": 125.89999999999999,
      "text": " We keep scaling out.",
      "tokens": [
        50819,
        492,
        1066,
        21589,
        484,
        13,
        50869
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11443503096296981,
      "compression_ratio": 1.8150289017341041,
      "no_speech_prob": 0.0029551030602306128
    },
    {
      "id": 70,
      "seek": 11580,
      "start": 125.89999999999999,
      "end": 126.89999999999999,
      "text": " This time we're going to be prepared.",
      "tokens": [
        50869,
        639,
        565,
        321,
        434,
        516,
        281,
        312,
        4927,
        13,
        50919
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11443503096296981,
      "compression_ratio": 1.8150289017341041,
      "no_speech_prob": 0.0029551030602306128
    },
    {
      "id": 71,
      "seek": 11580,
      "start": 126.89999999999999,
      "end": 130.5,
      "text": " So we're going to add not one server, but two servers.",
      "tokens": [
        50919,
        407,
        321,
        434,
        516,
        281,
        909,
        406,
        472,
        7154,
        11,
        457,
        732,
        15909,
        13,
        51099
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11443503096296981,
      "compression_ratio": 1.8150289017341041,
      "no_speech_prob": 0.0029551030602306128
    },
    {
      "id": 72,
      "seek": 11580,
      "start": 130.5,
      "end": 132.8,
      "text": " But now the process is kind of getting cumbersome.",
      "tokens": [
        51099,
        583,
        586,
        264,
        1399,
        307,
        733,
        295,
        1242,
        12713,
        1616,
        423,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11443503096296981,
      "compression_ratio": 1.8150289017341041,
      "no_speech_prob": 0.0029551030602306128
    },
    {
      "id": 73,
      "seek": 11580,
      "start": 132.8,
      "end": 137.6,
      "text": " I have to go in and set up another container on that server and then on this new server.",
      "tokens": [
        51214,
        286,
        362,
        281,
        352,
        294,
        293,
        992,
        493,
        1071,
        10129,
        322,
        300,
        7154,
        293,
        550,
        322,
        341,
        777,
        7154,
        13,
        51454
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11443503096296981,
      "compression_ratio": 1.8150289017341041,
      "no_speech_prob": 0.0029551030602306128
    },
    {
      "id": 74,
      "seek": 11580,
      "start": 137.6,
      "end": 138.3,
      "text": " And all dang it.",
      "tokens": [
        51454,
        400,
        439,
        21892,
        309,
        13,
        51489
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11443503096296981,
      "compression_ratio": 1.8150289017341041,
      "no_speech_prob": 0.0029551030602306128
    },
    {
      "id": 75,
      "seek": 11580,
      "start": 138.3,
      "end": 140.9,
      "text": " I have to set up the load balancer to load balance between all these guys.",
      "tokens": [
        51489,
        286,
        362,
        281,
        992,
        493,
        264,
        3677,
        3119,
        28347,
        281,
        3677,
        4772,
        1296,
        439,
        613,
        1074,
        13,
        51619
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11443503096296981,
      "compression_ratio": 1.8150289017341041,
      "no_speech_prob": 0.0029551030602306128
    },
    {
      "id": 76,
      "seek": 11580,
      "start": 140.9,
      "end": 141.9,
      "text": " So I got to set that up.",
      "tokens": [
        51619,
        407,
        286,
        658,
        281,
        992,
        300,
        493,
        13,
        51669
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11443503096296981,
      "compression_ratio": 1.8150289017341041,
      "no_speech_prob": 0.0029551030602306128
    },
    {
      "id": 77,
      "seek": 11580,
      "start": 141.9,
      "end": 143.6,
      "text": " So I got to add these suckers in there.",
      "tokens": [
        51669,
        407,
        286,
        658,
        281,
        909,
        613,
        9967,
        433,
        294,
        456,
        13,
        51754
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11443503096296981,
      "compression_ratio": 1.8150289017341041,
      "no_speech_prob": 0.0029551030602306128
    },
    {
      "id": 78,
      "seek": 11580,
      "start": 143.6,
      "end": 145.5,
      "text": " Okay, we should be good now, right?",
      "tokens": [
        51754,
        1033,
        11,
        321,
        820,
        312,
        665,
        586,
        11,
        558,
        30,
        51849
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11443503096296981,
      "compression_ratio": 1.8150289017341041,
      "no_speech_prob": 0.0029551030602306128
    },
    {
      "id": 79,
      "seek": 14550,
      "start": 145.5,
      "end": 146.0,
      "text": " Wrong.",
      "tokens": [
        50364,
        28150,
        13,
        50389
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 80,
      "seek": 14550,
      "start": 146.0,
      "end": 147.5,
      "text": " Turns out we're the Amazon of coffee.",
      "tokens": [
        50389,
        29524,
        484,
        321,
        434,
        264,
        6795,
        295,
        4982,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 81,
      "seek": 14550,
      "start": 147.5,
      "end": 148.4,
      "text": " We're awesome.",
      "tokens": [
        50464,
        492,
        434,
        3476,
        13,
        50509
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 82,
      "seek": 14550,
      "start": 148.4,
      "end": 150.9,
      "text": " And we have to add a ton more servers, a ton more containers.",
      "tokens": [
        50509,
        400,
        321,
        362,
        281,
        909,
        257,
        2952,
        544,
        15909,
        11,
        257,
        2952,
        544,
        17089,
        13,
        50634
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 83,
      "seek": 14550,
      "start": 150.9,
      "end": 154.0,
      "text": " We're talking just astronomical numbers.",
      "tokens": [
        50634,
        492,
        434,
        1417,
        445,
        49035,
        3547,
        13,
        50789
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 84,
      "seek": 14550,
      "start": 154.0,
      "end": 155.2,
      "text": " Business is good.",
      "tokens": [
        50789,
        10715,
        307,
        665,
        13,
        50849
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 85,
      "seek": 14550,
      "start": 155.2,
      "end": 158.4,
      "text": " So I have to set up and install all those machines and now I have two more load balancers to",
      "tokens": [
        50849,
        407,
        286,
        362,
        281,
        992,
        493,
        293,
        3625,
        439,
        729,
        8379,
        293,
        586,
        286,
        362,
        732,
        544,
        3677,
        3119,
        4463,
        433,
        281,
        51009
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 86,
      "seek": 14550,
      "start": 158.4,
      "end": 159.6,
      "text": " handle everything.",
      "tokens": [
        51009,
        4813,
        1203,
        13,
        51069
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 87,
      "seek": 14550,
      "start": 159.6,
      "end": 160.5,
      "text": " This is too much.",
      "tokens": [
        51069,
        639,
        307,
        886,
        709,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 88,
      "seek": 14550,
      "start": 160.5,
      "end": 161.3,
      "text": " I can't do this.",
      "tokens": [
        51114,
        286,
        393,
        380,
        360,
        341,
        13,
        51154
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 89,
      "seek": 14550,
      "start": 161.3,
      "end": 162.4,
      "text": " Oh, crap.",
      "tokens": [
        51154,
        876,
        11,
        12426,
        13,
        51209
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 90,
      "seek": 14550,
      "start": 162.4,
      "end": 164.0,
      "text": " I have to update my website now.",
      "tokens": [
        51209,
        286,
        362,
        281,
        5623,
        452,
        3144,
        586,
        13,
        51289
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 91,
      "seek": 14550,
      "start": 164.0,
      "end": 167.4,
      "text": " We got some new coffee, which is great, but we have to make a change to every one of",
      "tokens": [
        51289,
        492,
        658,
        512,
        777,
        4982,
        11,
        597,
        307,
        869,
        11,
        457,
        321,
        362,
        281,
        652,
        257,
        1319,
        281,
        633,
        472,
        295,
        51459
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 92,
      "seek": 14550,
      "start": 167.4,
      "end": 169.7,
      "text": " our containers and every one of our servers.",
      "tokens": [
        51459,
        527,
        17089,
        293,
        633,
        472,
        295,
        527,
        15909,
        13,
        51574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 93,
      "seek": 14550,
      "start": 169.7,
      "end": 171.0,
      "text": " Okay, I'm done.",
      "tokens": [
        51574,
        1033,
        11,
        286,
        478,
        1096,
        13,
        51639
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 94,
      "seek": 14550,
      "start": 171.0,
      "end": 172.2,
      "text": " I got two options.",
      "tokens": [
        51639,
        286,
        658,
        732,
        3956,
        13,
        51699
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09738505758890291,
      "compression_ratio": 1.7483660130718954,
      "no_speech_prob": 0.0005793114542029798
    },
    {
      "id": 95,
      "seek": 17220,
      "start": 172.2,
      "end": 176.2,
      "text": " I can either hire another engineer to do this for me because I'm done with this or I need",
      "tokens": [
        50364,
        286,
        393,
        2139,
        11158,
        1071,
        11403,
        281,
        360,
        341,
        337,
        385,
        570,
        286,
        478,
        1096,
        365,
        341,
        420,
        286,
        643,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 96,
      "seek": 17220,
      "start": 176.2,
      "end": 177.2,
      "text": " another solution.",
      "tokens": [
        50564,
        1071,
        3827,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 97,
      "seek": 17220,
      "start": 177.2,
      "end": 182.39999999999998,
      "text": " I need to somehow automate this or maybe orchestrate this somehow.",
      "tokens": [
        50614,
        286,
        643,
        281,
        6063,
        31605,
        341,
        420,
        1310,
        14161,
        4404,
        341,
        6063,
        13,
        50874
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 98,
      "seek": 17220,
      "start": 182.39999999999998,
      "end": 184.6,
      "text": " Maybe some kind of container orchestration.",
      "tokens": [
        50874,
        2704,
        512,
        733,
        295,
        10129,
        14161,
        2405,
        13,
        50984
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 99,
      "seek": 17220,
      "start": 184.6,
      "end": 186.1,
      "text": " No any good ones?",
      "tokens": [
        50984,
        883,
        604,
        665,
        2306,
        30,
        51059
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 100,
      "seek": 17220,
      "start": 186.1,
      "end": 187.1,
      "text": " What about Kubernetes?",
      "tokens": [
        51059,
        708,
        466,
        23145,
        30,
        51109
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 101,
      "seek": 17220,
      "start": 187.1,
      "end": 188.1,
      "text": " Let's try that.",
      "tokens": [
        51109,
        961,
        311,
        853,
        300,
        13,
        51159
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 102,
      "seek": 17220,
      "start": 188.1,
      "end": 189.39999999999998,
      "text": " This is where Kubernetes comes in.",
      "tokens": [
        51159,
        639,
        307,
        689,
        23145,
        1487,
        294,
        13,
        51224
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 103,
      "seek": 17220,
      "start": 189.39999999999998,
      "end": 191.7,
      "text": " It will handle all this junk for us.",
      "tokens": [
        51224,
        467,
        486,
        4813,
        439,
        341,
        19109,
        337,
        505,
        13,
        51339
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 104,
      "seek": 17220,
      "start": 191.7,
      "end": 192.7,
      "text": " So let's call up Kubernetes.",
      "tokens": [
        51339,
        407,
        718,
        311,
        818,
        493,
        23145,
        13,
        51389
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 105,
      "seek": 17220,
      "start": 192.7,
      "end": 194.0,
      "text": " Say, you know, man, I need some help.",
      "tokens": [
        51389,
        6463,
        11,
        291,
        458,
        11,
        587,
        11,
        286,
        643,
        512,
        854,
        13,
        51454
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 106,
      "seek": 17220,
      "start": 194.0,
      "end": 195.0,
      "text": " We're starting over.",
      "tokens": [
        51454,
        492,
        434,
        2891,
        670,
        13,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 107,
      "seek": 17220,
      "start": 195.0,
      "end": 196.0,
      "text": " I can't do this anymore.",
      "tokens": [
        51504,
        286,
        393,
        380,
        360,
        341,
        3602,
        13,
        51554
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 108,
      "seek": 17220,
      "start": 196.0,
      "end": 197.0,
      "text": " Can you help us?",
      "tokens": [
        51554,
        1664,
        291,
        854,
        505,
        30,
        51604
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 109,
      "seek": 17220,
      "start": 197.0,
      "end": 198.0,
      "text": " And he can.",
      "tokens": [
        51604,
        400,
        415,
        393,
        13,
        51654
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 110,
      "seek": 17220,
      "start": 198.0,
      "end": 199.2,
      "text": " Now we scaled back a bit just to start.",
      "tokens": [
        51654,
        823,
        321,
        36039,
        646,
        257,
        857,
        445,
        281,
        722,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 111,
      "seek": 17220,
      "start": 199.2,
      "end": 200.7,
      "text": " So we have our three servers here.",
      "tokens": [
        51714,
        407,
        321,
        362,
        527,
        1045,
        15909,
        510,
        13,
        51789
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11348765236990792,
      "compression_ratio": 1.7407407407407407,
      "no_speech_prob": 0.0034429235383868217
    },
    {
      "id": 112,
      "seek": 20070,
      "start": 200.7,
      "end": 203.7,
      "text": " Now the good news is that part of the setup is already done.",
      "tokens": [
        50364,
        823,
        264,
        665,
        2583,
        307,
        300,
        644,
        295,
        264,
        8657,
        307,
        1217,
        1096,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.139665964792466,
      "compression_ratio": 1.8103975535168195,
      "no_speech_prob": 0.004788470920175314
    },
    {
      "id": 113,
      "seek": 20070,
      "start": 203.7,
      "end": 205.1,
      "text": " Kubernetes is a container orchestrator.",
      "tokens": [
        50514,
        23145,
        307,
        257,
        10129,
        14161,
        19802,
        13,
        50584
      ],
      "temperature": 0.0,
      "avg_logprob": -0.139665964792466,
      "compression_ratio": 1.8103975535168195,
      "no_speech_prob": 0.004788470920175314
    },
    {
      "id": 114,
      "seek": 20070,
      "start": 205.1,
      "end": 209.7,
      "text": " So we're still going to have our servers and we'll still need some type of container runtime,",
      "tokens": [
        50584,
        407,
        321,
        434,
        920,
        516,
        281,
        362,
        527,
        15909,
        293,
        321,
        603,
        920,
        643,
        512,
        2010,
        295,
        10129,
        34474,
        11,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.139665964792466,
      "compression_ratio": 1.8103975535168195,
      "no_speech_prob": 0.004788470920175314
    },
    {
      "id": 115,
      "seek": 20070,
      "start": 209.7,
      "end": 210.7,
      "text": " which in our case will be Docker.",
      "tokens": [
        50814,
        597,
        294,
        527,
        1389,
        486,
        312,
        33772,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.139665964792466,
      "compression_ratio": 1.8103975535168195,
      "no_speech_prob": 0.004788470920175314
    },
    {
      "id": 116,
      "seek": 20070,
      "start": 210.7,
      "end": 213.79999999999998,
      "text": " It could be something else container D rocket or whatever.",
      "tokens": [
        50864,
        467,
        727,
        312,
        746,
        1646,
        10129,
        413,
        13012,
        420,
        2035,
        13,
        51019
      ],
      "temperature": 0.0,
      "avg_logprob": -0.139665964792466,
      "compression_ratio": 1.8103975535168195,
      "no_speech_prob": 0.004788470920175314
    },
    {
      "id": 117,
      "seek": 20070,
      "start": 213.79999999999998,
      "end": 215.29999999999998,
      "text": " So just so you know to clear that up.",
      "tokens": [
        51019,
        407,
        445,
        370,
        291,
        458,
        281,
        1850,
        300,
        493,
        13,
        51094
      ],
      "temperature": 0.0,
      "avg_logprob": -0.139665964792466,
      "compression_ratio": 1.8103975535168195,
      "no_speech_prob": 0.004788470920175314
    },
    {
      "id": 118,
      "seek": 20070,
      "start": 215.29999999999998,
      "end": 217.0,
      "text": " It's not Kubernetes or Docker.",
      "tokens": [
        51094,
        467,
        311,
        406,
        23145,
        420,
        33772,
        13,
        51179
      ],
      "temperature": 0.0,
      "avg_logprob": -0.139665964792466,
      "compression_ratio": 1.8103975535168195,
      "no_speech_prob": 0.004788470920175314
    },
    {
      "id": 119,
      "seek": 20070,
      "start": 217.0,
      "end": 218.0,
      "text": " It's yes, both.",
      "tokens": [
        51179,
        467,
        311,
        2086,
        11,
        1293,
        13,
        51229
      ],
      "temperature": 0.0,
      "avg_logprob": -0.139665964792466,
      "compression_ratio": 1.8103975535168195,
      "no_speech_prob": 0.004788470920175314
    },
    {
      "id": 120,
      "seek": 20070,
      "start": 218.0,
      "end": 219.5,
      "text": " We're going to use both.",
      "tokens": [
        51229,
        492,
        434,
        516,
        281,
        764,
        1293,
        13,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.139665964792466,
      "compression_ratio": 1.8103975535168195,
      "no_speech_prob": 0.004788470920175314
    },
    {
      "id": 121,
      "seek": 20070,
      "start": 219.5,
      "end": 221.7,
      "text": " Kubernetes is going to help us make Docker better.",
      "tokens": [
        51304,
        23145,
        307,
        516,
        281,
        854,
        505,
        652,
        33772,
        1101,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.139665964792466,
      "compression_ratio": 1.8103975535168195,
      "no_speech_prob": 0.004788470920175314
    },
    {
      "id": 122,
      "seek": 20070,
      "start": 221.7,
      "end": 222.7,
      "text": " So what do we do?",
      "tokens": [
        51414,
        407,
        437,
        360,
        321,
        360,
        30,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.139665964792466,
      "compression_ratio": 1.8103975535168195,
      "no_speech_prob": 0.004788470920175314
    },
    {
      "id": 123,
      "seek": 20070,
      "start": 222.7,
      "end": 223.7,
      "text": " What do we start?",
      "tokens": [
        51464,
        708,
        360,
        321,
        722,
        30,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.139665964792466,
      "compression_ratio": 1.8103975535168195,
      "no_speech_prob": 0.004788470920175314
    },
    {
      "id": 124,
      "seek": 20070,
      "start": 223.7,
      "end": 224.7,
      "text": " We first introduce a new server.",
      "tokens": [
        51514,
        492,
        700,
        5366,
        257,
        777,
        7154,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.139665964792466,
      "compression_ratio": 1.8103975535168195,
      "no_speech_prob": 0.004788470920175314
    },
    {
      "id": 125,
      "seek": 20070,
      "start": 224.7,
      "end": 227.06,
      "text": " Someone who's going to call the shots are master.",
      "tokens": [
        51564,
        8734,
        567,
        311,
        516,
        281,
        818,
        264,
        8305,
        366,
        4505,
        13,
        51682
      ],
      "temperature": 0.0,
      "avg_logprob": -0.139665964792466,
      "compression_ratio": 1.8103975535168195,
      "no_speech_prob": 0.004788470920175314
    },
    {
      "id": 126,
      "seek": 20070,
      "start": 227.06,
      "end": 228.56,
      "text": " This guy, he's the boss.",
      "tokens": [
        51682,
        639,
        2146,
        11,
        415,
        311,
        264,
        5741,
        13,
        51757
      ],
      "temperature": 0.0,
      "avg_logprob": -0.139665964792466,
      "compression_ratio": 1.8103975535168195,
      "no_speech_prob": 0.004788470920175314
    },
    {
      "id": 127,
      "seek": 22856,
      "start": 228.56,
      "end": 231.08,
      "text": " He calls the shots with all these servers.",
      "tokens": [
        50364,
        634,
        5498,
        264,
        8305,
        365,
        439,
        613,
        15909,
        13,
        50490
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16763874336525245,
      "compression_ratio": 1.9190031152647975,
      "no_speech_prob": 0.008182144723832607
    },
    {
      "id": 128,
      "seek": 22856,
      "start": 231.08,
      "end": 234.0,
      "text": " He tells them what to do, keeps them in line, make sure that I'm acting up.",
      "tokens": [
        50490,
        634,
        5112,
        552,
        437,
        281,
        360,
        11,
        5965,
        552,
        294,
        1622,
        11,
        652,
        988,
        300,
        286,
        478,
        6577,
        493,
        13,
        50636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16763874336525245,
      "compression_ratio": 1.9190031152647975,
      "no_speech_prob": 0.008182144723832607
    },
    {
      "id": 129,
      "seek": 22856,
      "start": 234.0,
      "end": 237.16,
      "text": " Now we do need to make our servers part of the team, part of the workforce.",
      "tokens": [
        50636,
        823,
        321,
        360,
        643,
        281,
        652,
        527,
        15909,
        644,
        295,
        264,
        1469,
        11,
        644,
        295,
        264,
        14201,
        13,
        50794
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16763874336525245,
      "compression_ratio": 1.9190031152647975,
      "no_speech_prob": 0.008182144723832607
    },
    {
      "id": 130,
      "seek": 22856,
      "start": 237.16,
      "end": 239.28,
      "text": " So we'll install Kubernetes on these servers.",
      "tokens": [
        50794,
        407,
        321,
        603,
        3625,
        23145,
        322,
        613,
        15909,
        13,
        50900
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16763874336525245,
      "compression_ratio": 1.9190031152647975,
      "no_speech_prob": 0.008182144723832607
    },
    {
      "id": 131,
      "seek": 22856,
      "start": 239.28,
      "end": 240.48,
      "text": " That's going to involve two components.",
      "tokens": [
        50900,
        663,
        311,
        516,
        281,
        9494,
        732,
        6677,
        13,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16763874336525245,
      "compression_ratio": 1.9190031152647975,
      "no_speech_prob": 0.008182144723832607
    },
    {
      "id": 132,
      "seek": 22856,
      "start": 240.48,
      "end": 244.76,
      "text": " We'll have our cube proxy and our cube lit.",
      "tokens": [
        50960,
        492,
        603,
        362,
        527,
        13728,
        29690,
        293,
        527,
        13728,
        7997,
        13,
        51174
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16763874336525245,
      "compression_ratio": 1.9190031152647975,
      "no_speech_prob": 0.008182144723832607
    },
    {
      "id": 133,
      "seek": 22856,
      "start": 244.76,
      "end": 248.4,
      "text": " I love the names with those two components installed along with their container runtime,",
      "tokens": [
        51174,
        286,
        959,
        264,
        5288,
        365,
        729,
        732,
        6677,
        8899,
        2051,
        365,
        641,
        10129,
        34474,
        11,
        51356
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16763874336525245,
      "compression_ratio": 1.9190031152647975,
      "no_speech_prob": 0.008182144723832607
    },
    {
      "id": 134,
      "seek": 22856,
      "start": 248.4,
      "end": 249.72,
      "text": " which in our case is Docker.",
      "tokens": [
        51356,
        597,
        294,
        527,
        1389,
        307,
        33772,
        13,
        51422
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16763874336525245,
      "compression_ratio": 1.9190031152647975,
      "no_speech_prob": 0.008182144723832607
    },
    {
      "id": 135,
      "seek": 22856,
      "start": 249.72,
      "end": 251.2,
      "text": " They are now part of the team.",
      "tokens": [
        51422,
        814,
        366,
        586,
        644,
        295,
        264,
        1469,
        13,
        51496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16763874336525245,
      "compression_ratio": 1.9190031152647975,
      "no_speech_prob": 0.008182144723832607
    },
    {
      "id": 136,
      "seek": 22856,
      "start": 251.2,
      "end": 253.24,
      "text": " They are team Kubernetes.",
      "tokens": [
        51496,
        814,
        366,
        1469,
        23145,
        13,
        51598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16763874336525245,
      "compression_ratio": 1.9190031152647975,
      "no_speech_prob": 0.008182144723832607
    },
    {
      "id": 137,
      "seek": 22856,
      "start": 253.24,
      "end": 255.04,
      "text": " They are now worker nodes.",
      "tokens": [
        51598,
        814,
        366,
        586,
        11346,
        13891,
        13,
        51688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16763874336525245,
      "compression_ratio": 1.9190031152647975,
      "no_speech_prob": 0.008182144723832607
    },
    {
      "id": 138,
      "seek": 22856,
      "start": 255.04,
      "end": 258.16,
      "text": " Now what these components do we'll cover here in a moment, but just know what's away from",
      "tokens": [
        51688,
        823,
        437,
        613,
        6677,
        360,
        321,
        603,
        2060,
        510,
        294,
        257,
        1623,
        11,
        457,
        445,
        458,
        437,
        311,
        1314,
        490,
        51844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16763874336525245,
      "compression_ratio": 1.9190031152647975,
      "no_speech_prob": 0.008182144723832607
    },
    {
      "id": 139,
      "seek": 25816,
      "start": 258.16,
      "end": 262.16,
      "text": " the master to control them and make all this Kubernetes goodness happen.",
      "tokens": [
        50364,
        264,
        4505,
        281,
        1969,
        552,
        293,
        652,
        439,
        341,
        23145,
        8387,
        1051,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1592317638975201,
      "compression_ratio": 1.7493036211699164,
      "no_speech_prob": 0.017183322459459305
    },
    {
      "id": 140,
      "seek": 25816,
      "start": 262.16,
      "end": 265.76000000000005,
      "text": " Now the master, he's a server just like these guys right here, but he's got some special",
      "tokens": [
        50564,
        823,
        264,
        4505,
        11,
        415,
        311,
        257,
        7154,
        445,
        411,
        613,
        1074,
        558,
        510,
        11,
        457,
        415,
        311,
        658,
        512,
        2121,
        50744
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1592317638975201,
      "compression_ratio": 1.7493036211699164,
      "no_speech_prob": 0.017183322459459305
    },
    {
      "id": 141,
      "seek": 25816,
      "start": 265.76000000000005,
      "end": 268.52000000000004,
      "text": " components, some special roles that we gave him.",
      "tokens": [
        50744,
        6677,
        11,
        512,
        2121,
        9604,
        300,
        321,
        2729,
        796,
        13,
        50882
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1592317638975201,
      "compression_ratio": 1.7493036211699164,
      "no_speech_prob": 0.017183322459459305
    },
    {
      "id": 142,
      "seek": 25816,
      "start": 268.52000000000004,
      "end": 271.6,
      "text": " These are his four jobs or his four components and we'll cover that here in a moment.",
      "tokens": [
        50882,
        1981,
        366,
        702,
        1451,
        4782,
        420,
        702,
        1451,
        6677,
        293,
        321,
        603,
        2060,
        300,
        510,
        294,
        257,
        1623,
        13,
        51036
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1592317638975201,
      "compression_ratio": 1.7493036211699164,
      "no_speech_prob": 0.017183322459459305
    },
    {
      "id": 143,
      "seek": 25816,
      "start": 271.6,
      "end": 274.76000000000005,
      "text": " But for now, I don't know about you, but I want to do something.",
      "tokens": [
        51036,
        583,
        337,
        586,
        11,
        286,
        500,
        380,
        458,
        466,
        291,
        11,
        457,
        286,
        528,
        281,
        360,
        746,
        13,
        51194
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1592317638975201,
      "compression_ratio": 1.7493036211699164,
      "no_speech_prob": 0.017183322459459305
    },
    {
      "id": 144,
      "seek": 25816,
      "start": 274.76000000000005,
      "end": 276.0,
      "text": " Theory is fun until it's not.",
      "tokens": [
        51194,
        29009,
        307,
        1019,
        1826,
        309,
        311,
        406,
        13,
        51256
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1592317638975201,
      "compression_ratio": 1.7493036211699164,
      "no_speech_prob": 0.017183322459459305
    },
    {
      "id": 145,
      "seek": 25816,
      "start": 276.0,
      "end": 278.04,
      "text": " So let's actually start making this.",
      "tokens": [
        51256,
        407,
        718,
        311,
        767,
        722,
        1455,
        341,
        13,
        51358
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1592317638975201,
      "compression_ratio": 1.7493036211699164,
      "no_speech_prob": 0.017183322459459305
    },
    {
      "id": 146,
      "seek": 25816,
      "start": 278.04,
      "end": 280.96000000000004,
      "text": " Let's take our network, Chuck coffee website and let's let's orchestrate it.",
      "tokens": [
        51358,
        961,
        311,
        747,
        527,
        3209,
        11,
        21607,
        4982,
        3144,
        293,
        718,
        311,
        718,
        311,
        14161,
        4404,
        309,
        13,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1592317638975201,
      "compression_ratio": 1.7493036211699164,
      "no_speech_prob": 0.017183322459459305
    },
    {
      "id": 147,
      "seek": 25816,
      "start": 280.96000000000004,
      "end": 281.96000000000004,
      "text": " Now hold on one second.",
      "tokens": [
        51504,
        823,
        1797,
        322,
        472,
        1150,
        13,
        51554
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1592317638975201,
      "compression_ratio": 1.7493036211699164,
      "no_speech_prob": 0.017183322459459305
    },
    {
      "id": 148,
      "seek": 25816,
      "start": 281.96000000000004,
      "end": 284.88,
      "text": " Typically setting up Kubernetes is kind of hard.",
      "tokens": [
        51554,
        23129,
        3287,
        493,
        23145,
        307,
        733,
        295,
        1152,
        13,
        51700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1592317638975201,
      "compression_ratio": 1.7493036211699164,
      "no_speech_prob": 0.017183322459459305
    },
    {
      "id": 149,
      "seek": 25816,
      "start": 284.88,
      "end": 286.88,
      "text": " So in our environment here, we have four servers.",
      "tokens": [
        51700,
        407,
        294,
        527,
        2823,
        510,
        11,
        321,
        362,
        1451,
        15909,
        13,
        51800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1592317638975201,
      "compression_ratio": 1.7493036211699164,
      "no_speech_prob": 0.017183322459459305
    },
    {
      "id": 150,
      "seek": 28688,
      "start": 286.88,
      "end": 290.48,
      "text": " We have our master server, which we have to install those four components, making it",
      "tokens": [
        50364,
        492,
        362,
        527,
        4505,
        7154,
        11,
        597,
        321,
        362,
        281,
        3625,
        729,
        1451,
        6677,
        11,
        1455,
        309,
        50544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1698897017372979,
      "compression_ratio": 1.7571884984025559,
      "no_speech_prob": 0.002623282838612795
    },
    {
      "id": 151,
      "seek": 28688,
      "start": 290.48,
      "end": 292.04,
      "text": " the Kubernetes master.",
      "tokens": [
        50544,
        264,
        23145,
        4505,
        13,
        50622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1698897017372979,
      "compression_ratio": 1.7571884984025559,
      "no_speech_prob": 0.002623282838612795
    },
    {
      "id": 152,
      "seek": 28688,
      "start": 292.04,
      "end": 295.96,
      "text": " And then we have our three servers here, which are our worker nodes where our containers",
      "tokens": [
        50622,
        400,
        550,
        321,
        362,
        527,
        1045,
        15909,
        510,
        11,
        597,
        366,
        527,
        11346,
        13891,
        689,
        527,
        17089,
        50818
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1698897017372979,
      "compression_ratio": 1.7571884984025559,
      "no_speech_prob": 0.002623282838612795
    },
    {
      "id": 153,
      "seek": 28688,
      "start": 295.96,
      "end": 296.96,
      "text": " will run.",
      "tokens": [
        50818,
        486,
        1190,
        13,
        50868
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1698897017372979,
      "compression_ratio": 1.7571884984025559,
      "no_speech_prob": 0.002623282838612795
    },
    {
      "id": 154,
      "seek": 28688,
      "start": 296.96,
      "end": 299.2,
      "text": " We'll install Docker, the cube proxy and the cubelit.",
      "tokens": [
        50868,
        492,
        603,
        3625,
        33772,
        11,
        264,
        13728,
        29690,
        293,
        264,
        10057,
        338,
        270,
        13,
        50980
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1698897017372979,
      "compression_ratio": 1.7571884984025559,
      "no_speech_prob": 0.002623282838612795
    },
    {
      "id": 155,
      "seek": 28688,
      "start": 299.2,
      "end": 303.86,
      "text": " Again, it's kind of a not really straightforward process, but I do have good news for you.",
      "tokens": [
        50980,
        3764,
        11,
        309,
        311,
        733,
        295,
        257,
        406,
        534,
        15325,
        1399,
        11,
        457,
        286,
        360,
        362,
        665,
        2583,
        337,
        291,
        13,
        51213
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1698897017372979,
      "compression_ratio": 1.7571884984025559,
      "no_speech_prob": 0.002623282838612795
    },
    {
      "id": 156,
      "seek": 28688,
      "start": 303.86,
      "end": 305.0,
      "text": " We have an easier way.",
      "tokens": [
        51213,
        492,
        362,
        364,
        3571,
        636,
        13,
        51270
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1698897017372979,
      "compression_ratio": 1.7571884984025559,
      "no_speech_prob": 0.002623282838612795
    },
    {
      "id": 157,
      "seek": 28688,
      "start": 305.0,
      "end": 307.4,
      "text": " You see Kubernetes is big in the cloud.",
      "tokens": [
        51270,
        509,
        536,
        23145,
        307,
        955,
        294,
        264,
        4588,
        13,
        51390
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1698897017372979,
      "compression_ratio": 1.7571884984025559,
      "no_speech_prob": 0.002623282838612795
    },
    {
      "id": 158,
      "seek": 28688,
      "start": 307.4,
      "end": 311.52,
      "text": " Many cloud providers have Kubernetes baked in and it's really easy to get it set up.",
      "tokens": [
        51390,
        5126,
        4588,
        11330,
        362,
        23145,
        19453,
        294,
        293,
        309,
        311,
        534,
        1858,
        281,
        483,
        309,
        992,
        493,
        13,
        51596
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1698897017372979,
      "compression_ratio": 1.7571884984025559,
      "no_speech_prob": 0.002623282838612795
    },
    {
      "id": 159,
      "seek": 28688,
      "start": 311.52,
      "end": 314.0,
      "text": " One of those is Linode, the sponsor of this video.",
      "tokens": [
        51596,
        1485,
        295,
        729,
        307,
        9355,
        1429,
        11,
        264,
        16198,
        295,
        341,
        960,
        13,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1698897017372979,
      "compression_ratio": 1.7571884984025559,
      "no_speech_prob": 0.002623282838612795
    },
    {
      "id": 160,
      "seek": 31400,
      "start": 314.0,
      "end": 317.44,
      "text": " And through their cloud platform, we can go in there and create a Kubernetes cluster.",
      "tokens": [
        50364,
        400,
        807,
        641,
        4588,
        3663,
        11,
        321,
        393,
        352,
        294,
        456,
        293,
        1884,
        257,
        23145,
        13630,
        13,
        50536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1789118010422279,
      "compression_ratio": 1.7584269662921348,
      "no_speech_prob": 0.16229301691055298
    },
    {
      "id": 161,
      "seek": 31400,
      "start": 317.44,
      "end": 319.36,
      "text": " This is called a cluster basically for free.",
      "tokens": [
        50536,
        639,
        307,
        1219,
        257,
        13630,
        1936,
        337,
        1737,
        13,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1789118010422279,
      "compression_ratio": 1.7584269662921348,
      "no_speech_prob": 0.16229301691055298
    },
    {
      "id": 162,
      "seek": 31400,
      "start": 319.36,
      "end": 323.72,
      "text": " They give you a hundred dollar credit to use for the first 60 days and you can go crazy.",
      "tokens": [
        50632,
        814,
        976,
        291,
        257,
        3262,
        7241,
        5397,
        281,
        764,
        337,
        264,
        700,
        4060,
        1708,
        293,
        291,
        393,
        352,
        3219,
        13,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1789118010422279,
      "compression_ratio": 1.7584269662921348,
      "no_speech_prob": 0.16229301691055298
    },
    {
      "id": 163,
      "seek": 31400,
      "start": 323.72,
      "end": 325.32,
      "text": " Well, not too crazy.",
      "tokens": [
        50850,
        1042,
        11,
        406,
        886,
        3219,
        13,
        50930
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1789118010422279,
      "compression_ratio": 1.7584269662921348,
      "no_speech_prob": 0.16229301691055298
    },
    {
      "id": 164,
      "seek": 31400,
      "start": 325.32,
      "end": 327.12,
      "text": " And then make it so stupid simple.",
      "tokens": [
        50930,
        400,
        550,
        652,
        309,
        370,
        6631,
        2199,
        13,
        51020
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1789118010422279,
      "compression_ratio": 1.7584269662921348,
      "no_speech_prob": 0.16229301691055298
    },
    {
      "id": 165,
      "seek": 31400,
      "start": 327.12,
      "end": 328.64,
      "text": " Let's go do it right now.",
      "tokens": [
        51020,
        961,
        311,
        352,
        360,
        309,
        558,
        586,
        13,
        51096
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1789118010422279,
      "compression_ratio": 1.7584269662921348,
      "no_speech_prob": 0.16229301691055298
    },
    {
      "id": 166,
      "seek": 31400,
      "start": 328.64,
      "end": 329.8,
      "text": " So go ahead and use my link below.",
      "tokens": [
        51096,
        407,
        352,
        2286,
        293,
        764,
        452,
        2113,
        2507,
        13,
        51154
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1789118010422279,
      "compression_ratio": 1.7584269662921348,
      "no_speech_prob": 0.16229301691055298
    },
    {
      "id": 167,
      "seek": 31400,
      "start": 329.8,
      "end": 333.0,
      "text": " Get signed up and logged in and we'll go through this right now.",
      "tokens": [
        51154,
        3240,
        8175,
        493,
        293,
        27231,
        294,
        293,
        321,
        603,
        352,
        807,
        341,
        558,
        586,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1789118010422279,
      "compression_ratio": 1.7584269662921348,
      "no_speech_prob": 0.16229301691055298
    },
    {
      "id": 168,
      "seek": 31400,
      "start": 333.0,
      "end": 336.0,
      "text": " So once you're in Linode on the left side here, we have a panel.",
      "tokens": [
        51314,
        407,
        1564,
        291,
        434,
        294,
        9355,
        1429,
        322,
        264,
        1411,
        1252,
        510,
        11,
        321,
        362,
        257,
        4831,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1789118010422279,
      "compression_ratio": 1.7584269662921348,
      "no_speech_prob": 0.16229301691055298
    },
    {
      "id": 169,
      "seek": 31400,
      "start": 336.0,
      "end": 339.4,
      "text": " If you scroll down just a little bit, you'll see right here, there it is.",
      "tokens": [
        51464,
        759,
        291,
        11369,
        760,
        445,
        257,
        707,
        857,
        11,
        291,
        603,
        536,
        558,
        510,
        11,
        456,
        309,
        307,
        13,
        51634
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1789118010422279,
      "compression_ratio": 1.7584269662921348,
      "no_speech_prob": 0.16229301691055298
    },
    {
      "id": 170,
      "seek": 31400,
      "start": 339.4,
      "end": 341.24,
      "text": " Kubernetes, hit that, click it.",
      "tokens": [
        51634,
        23145,
        11,
        2045,
        300,
        11,
        2052,
        309,
        13,
        51726
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1789118010422279,
      "compression_ratio": 1.7584269662921348,
      "no_speech_prob": 0.16229301691055298
    },
    {
      "id": 171,
      "seek": 31400,
      "start": 341.24,
      "end": 343.88,
      "text": " And they want us to add our first Kubernetes cluster.",
      "tokens": [
        51726,
        400,
        436,
        528,
        505,
        281,
        909,
        527,
        700,
        23145,
        13630,
        13,
        51858
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1789118010422279,
      "compression_ratio": 1.7584269662921348,
      "no_speech_prob": 0.16229301691055298
    },
    {
      "id": 172,
      "seek": 34388,
      "start": 343.88,
      "end": 344.88,
      "text": " Let's do that.",
      "tokens": [
        50364,
        961,
        311,
        360,
        300,
        13,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16303041685430497,
      "compression_ratio": 1.7698863636363635,
      "no_speech_prob": 0.039482828229665756
    },
    {
      "id": 173,
      "seek": 34388,
      "start": 344.88,
      "end": 345.88,
      "text": " So we'll click create.",
      "tokens": [
        50414,
        407,
        321,
        603,
        2052,
        1884,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16303041685430497,
      "compression_ratio": 1.7698863636363635,
      "no_speech_prob": 0.039482828229665756
    },
    {
      "id": 174,
      "seek": 34388,
      "start": 345.88,
      "end": 346.88,
      "text": " Let's label it.",
      "tokens": [
        50464,
        961,
        311,
        7645,
        309,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16303041685430497,
      "compression_ratio": 1.7698863636363635,
      "no_speech_prob": 0.039482828229665756
    },
    {
      "id": 175,
      "seek": 34388,
      "start": 346.88,
      "end": 347.88,
      "text": " It's just a name.",
      "tokens": [
        50514,
        467,
        311,
        445,
        257,
        1315,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16303041685430497,
      "compression_ratio": 1.7698863636363635,
      "no_speech_prob": 0.039482828229665756
    },
    {
      "id": 176,
      "seek": 34388,
      "start": 347.88,
      "end": 348.88,
      "text": " We're going to give it.",
      "tokens": [
        50564,
        492,
        434,
        516,
        281,
        976,
        309,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16303041685430497,
      "compression_ratio": 1.7698863636363635,
      "no_speech_prob": 0.039482828229665756
    },
    {
      "id": 177,
      "seek": 34388,
      "start": 348.88,
      "end": 349.88,
      "text": " I'll name my networked shut coffee.",
      "tokens": [
        50614,
        286,
        603,
        1315,
        452,
        3209,
        292,
        5309,
        4982,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16303041685430497,
      "compression_ratio": 1.7698863636363635,
      "no_speech_prob": 0.039482828229665756
    },
    {
      "id": 178,
      "seek": 34388,
      "start": 349.88,
      "end": 350.88,
      "text": " Word I want it to be.",
      "tokens": [
        50664,
        8725,
        286,
        528,
        309,
        281,
        312,
        13,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16303041685430497,
      "compression_ratio": 1.7698863636363635,
      "no_speech_prob": 0.039482828229665756
    },
    {
      "id": 179,
      "seek": 34388,
      "start": 350.88,
      "end": 351.88,
      "text": " I want it to be close to me.",
      "tokens": [
        50714,
        286,
        528,
        309,
        281,
        312,
        1998,
        281,
        385,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16303041685430497,
      "compression_ratio": 1.7698863636363635,
      "no_speech_prob": 0.039482828229665756
    },
    {
      "id": 180,
      "seek": 34388,
      "start": 351.88,
      "end": 355.96,
      "text": " So in Dallas and then version, I'll just select the latest version of 1.17.",
      "tokens": [
        50764,
        407,
        294,
        22923,
        293,
        550,
        3037,
        11,
        286,
        603,
        445,
        3048,
        264,
        6792,
        3037,
        295,
        502,
        13,
        7773,
        13,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16303041685430497,
      "compression_ratio": 1.7698863636363635,
      "no_speech_prob": 0.039482828229665756
    },
    {
      "id": 181,
      "seek": 34388,
      "start": 355.96,
      "end": 358.12,
      "text": " And now we're on to how many servers do we want?",
      "tokens": [
        50968,
        400,
        586,
        321,
        434,
        322,
        281,
        577,
        867,
        15909,
        360,
        321,
        528,
        30,
        51076
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16303041685430497,
      "compression_ratio": 1.7698863636363635,
      "no_speech_prob": 0.039482828229665756
    },
    {
      "id": 182,
      "seek": 34388,
      "start": 358.12,
      "end": 360.52,
      "text": " How many worker nodes do we want to have in our cluster?",
      "tokens": [
        51076,
        1012,
        867,
        11346,
        13891,
        360,
        321,
        528,
        281,
        362,
        294,
        527,
        13630,
        30,
        51196
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16303041685430497,
      "compression_ratio": 1.7698863636363635,
      "no_speech_prob": 0.039482828229665756
    },
    {
      "id": 183,
      "seek": 34388,
      "start": 360.52,
      "end": 363.24,
      "text": " For my lab, I'm going to go with the smaller version, the Linode two gigabytes.",
      "tokens": [
        51196,
        1171,
        452,
        2715,
        11,
        286,
        478,
        516,
        281,
        352,
        365,
        264,
        4356,
        3037,
        11,
        264,
        9355,
        1429,
        732,
        42741,
        13,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16303041685430497,
      "compression_ratio": 1.7698863636363635,
      "no_speech_prob": 0.039482828229665756
    },
    {
      "id": 184,
      "seek": 34388,
      "start": 363.24,
      "end": 367.15999999999997,
      "text": " I'm going to add three worker nodes by hitting that plus sign right there.",
      "tokens": [
        51332,
        286,
        478,
        516,
        281,
        909,
        1045,
        11346,
        13891,
        538,
        8850,
        300,
        1804,
        1465,
        558,
        456,
        13,
        51528
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16303041685430497,
      "compression_ratio": 1.7698863636363635,
      "no_speech_prob": 0.039482828229665756
    },
    {
      "id": 185,
      "seek": 34388,
      "start": 367.15999999999997,
      "end": 369.52,
      "text": " Keep in mind, it will be $10 a month.",
      "tokens": [
        51528,
        5527,
        294,
        1575,
        11,
        309,
        486,
        312,
        1848,
        3279,
        257,
        1618,
        13,
        51646
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16303041685430497,
      "compression_ratio": 1.7698863636363635,
      "no_speech_prob": 0.039482828229665756
    },
    {
      "id": 186,
      "seek": 34388,
      "start": 369.52,
      "end": 372.15999999999997,
      "text": " So kind of do that math with your hundred dollar credit you have.",
      "tokens": [
        51646,
        407,
        733,
        295,
        360,
        300,
        5221,
        365,
        428,
        3262,
        7241,
        5397,
        291,
        362,
        13,
        51778
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16303041685430497,
      "compression_ratio": 1.7698863636363635,
      "no_speech_prob": 0.039482828229665756
    },
    {
      "id": 187,
      "seek": 37216,
      "start": 372.16,
      "end": 374.88000000000005,
      "text": " Also click on add to add those three nodes to my cluster.",
      "tokens": [
        50364,
        2743,
        2052,
        322,
        909,
        281,
        909,
        729,
        1045,
        13891,
        281,
        452,
        13630,
        13,
        50500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 188,
      "seek": 37216,
      "start": 374.88000000000005,
      "end": 378.72,
      "text": " And as I scroll down and get my cluster summary, three worker nodes, 30 bucks a month.",
      "tokens": [
        50500,
        400,
        382,
        286,
        11369,
        760,
        293,
        483,
        452,
        13630,
        12691,
        11,
        1045,
        11346,
        13891,
        11,
        2217,
        11829,
        257,
        1618,
        13,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 189,
      "seek": 37216,
      "start": 378.72,
      "end": 379.72,
      "text": " That's what I'm doing.",
      "tokens": [
        50692,
        663,
        311,
        437,
        286,
        478,
        884,
        13,
        50742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 190,
      "seek": 37216,
      "start": 379.72,
      "end": 381.76000000000005,
      "text": " I'll click create cluster.",
      "tokens": [
        50742,
        286,
        603,
        2052,
        1884,
        13630,
        13,
        50844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 191,
      "seek": 37216,
      "start": 381.76000000000005,
      "end": 382.76000000000005,
      "text": " And now we wait.",
      "tokens": [
        50844,
        400,
        586,
        321,
        1699,
        13,
        50894
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 192,
      "seek": 37216,
      "start": 382.76000000000005,
      "end": 383.76000000000005,
      "text": " Coffee break.",
      "tokens": [
        50894,
        25481,
        1821,
        13,
        50944
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 193,
      "seek": 37216,
      "start": 383.76000000000005,
      "end": 384.76000000000005,
      "text": " Let's enjoy our product.",
      "tokens": [
        50944,
        961,
        311,
        2103,
        527,
        1674,
        13,
        50994
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 194,
      "seek": 37216,
      "start": 384.76000000000005,
      "end": 385.76000000000005,
      "text": " All right.",
      "tokens": [
        50994,
        1057,
        558,
        13,
        51044
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 195,
      "seek": 37216,
      "start": 385.76000000000005,
      "end": 387.72,
      "text": " If I scroll down to the bottom here, my three nodes are ready.",
      "tokens": [
        51044,
        759,
        286,
        11369,
        760,
        281,
        264,
        2767,
        510,
        11,
        452,
        1045,
        13891,
        366,
        1919,
        13,
        51142
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 196,
      "seek": 37216,
      "start": 387.72,
      "end": 388.72,
      "text": " They're running.",
      "tokens": [
        51142,
        814,
        434,
        2614,
        13,
        51192
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 197,
      "seek": 37216,
      "start": 388.72,
      "end": 389.72,
      "text": " Awesome.",
      "tokens": [
        51192,
        10391,
        13,
        51242
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 198,
      "seek": 37216,
      "start": 389.72,
      "end": 390.72,
      "text": " Now, hold on a second though.",
      "tokens": [
        51242,
        823,
        11,
        1797,
        322,
        257,
        1150,
        1673,
        13,
        51292
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 199,
      "seek": 37216,
      "start": 390.72,
      "end": 393.52000000000004,
      "text": " I see one, two, three worker nodes.",
      "tokens": [
        51292,
        286,
        536,
        472,
        11,
        732,
        11,
        1045,
        11346,
        13891,
        13,
        51432
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 200,
      "seek": 37216,
      "start": 393.52000000000004,
      "end": 397.0,
      "text": " Oh, where's my master node?",
      "tokens": [
        51432,
        876,
        11,
        689,
        311,
        452,
        4505,
        9984,
        30,
        51606
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 201,
      "seek": 37216,
      "start": 397.0,
      "end": 398.0,
      "text": " Where is it?",
      "tokens": [
        51606,
        2305,
        307,
        309,
        30,
        51656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 202,
      "seek": 37216,
      "start": 398.0,
      "end": 399.64000000000004,
      "text": " This is what's cool about doing Kubernetes on Linode.",
      "tokens": [
        51656,
        639,
        307,
        437,
        311,
        1627,
        466,
        884,
        23145,
        322,
        9355,
        1429,
        13,
        51738
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17506532669067382,
      "compression_ratio": 1.7033333333333334,
      "no_speech_prob": 0.16100315749645233
    },
    {
      "id": 203,
      "seek": 39964,
      "start": 399.64,
      "end": 402.84,
      "text": " In the cloud, you pay for everything you use, which is a great model.",
      "tokens": [
        50364,
        682,
        264,
        4588,
        11,
        291,
        1689,
        337,
        1203,
        291,
        764,
        11,
        597,
        307,
        257,
        869,
        2316,
        13,
        50524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13389274644555513,
      "compression_ratio": 1.688073394495413,
      "no_speech_prob": 0.020326849073171616
    },
    {
      "id": 204,
      "seek": 39964,
      "start": 402.84,
      "end": 406.0,
      "text": " So I've got my three worker nodes and those are costing me $10 a month.",
      "tokens": [
        50524,
        407,
        286,
        600,
        658,
        452,
        1045,
        11346,
        13891,
        293,
        729,
        366,
        37917,
        385,
        1848,
        3279,
        257,
        1618,
        13,
        50682
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13389274644555513,
      "compression_ratio": 1.688073394495413,
      "no_speech_prob": 0.020326849073171616
    },
    {
      "id": 205,
      "seek": 39964,
      "start": 406.0,
      "end": 408.71999999999997,
      "text": " So you would probably assume that with our master node, that would be another server",
      "tokens": [
        50682,
        407,
        291,
        576,
        1391,
        6552,
        300,
        365,
        527,
        4505,
        9984,
        11,
        300,
        576,
        312,
        1071,
        7154,
        50818
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13389274644555513,
      "compression_ratio": 1.688073394495413,
      "no_speech_prob": 0.020326849073171616
    },
    {
      "id": 206,
      "seek": 39964,
      "start": 408.71999999999997,
      "end": 410.4,
      "text": " that would cost us $10 a month.",
      "tokens": [
        50818,
        300,
        576,
        2063,
        505,
        1848,
        3279,
        257,
        1618,
        13,
        50902
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13389274644555513,
      "compression_ratio": 1.688073394495413,
      "no_speech_prob": 0.020326849073171616
    },
    {
      "id": 207,
      "seek": 39964,
      "start": 410.4,
      "end": 413.47999999999996,
      "text": " No, good guy Linode says, you know what, don't worry about that.",
      "tokens": [
        50902,
        883,
        11,
        665,
        2146,
        9355,
        1429,
        1619,
        11,
        291,
        458,
        437,
        11,
        500,
        380,
        3292,
        466,
        300,
        13,
        51056
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13389274644555513,
      "compression_ratio": 1.688073394495413,
      "no_speech_prob": 0.020326849073171616
    },
    {
      "id": 208,
      "seek": 39964,
      "start": 413.47999999999996,
      "end": 416.4,
      "text": " We're going to throw in the master for free, which is super cool.",
      "tokens": [
        51056,
        492,
        434,
        516,
        281,
        3507,
        294,
        264,
        4505,
        337,
        1737,
        11,
        597,
        307,
        1687,
        1627,
        13,
        51202
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13389274644555513,
      "compression_ratio": 1.688073394495413,
      "no_speech_prob": 0.020326849073171616
    },
    {
      "id": 209,
      "seek": 39964,
      "start": 416.4,
      "end": 418.4,
      "text": " But still, where, where is he?",
      "tokens": [
        51202,
        583,
        920,
        11,
        689,
        11,
        689,
        307,
        415,
        30,
        51302
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13389274644555513,
      "compression_ratio": 1.688073394495413,
      "no_speech_prob": 0.020326849073171616
    },
    {
      "id": 210,
      "seek": 39964,
      "start": 418.4,
      "end": 419.4,
      "text": " How do we use him?",
      "tokens": [
        51302,
        1012,
        360,
        321,
        764,
        796,
        30,
        51352
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13389274644555513,
      "compression_ratio": 1.688073394495413,
      "no_speech_prob": 0.020326849073171616
    },
    {
      "id": 211,
      "seek": 39964,
      "start": 419.4,
      "end": 424.76,
      "text": " Well, if you look at this link right here, this URL, the Kubernetes API endpoint, that's",
      "tokens": [
        51352,
        1042,
        11,
        498,
        291,
        574,
        412,
        341,
        2113,
        558,
        510,
        11,
        341,
        12905,
        11,
        264,
        23145,
        9362,
        35795,
        11,
        300,
        311,
        51620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13389274644555513,
      "compression_ratio": 1.688073394495413,
      "no_speech_prob": 0.020326849073171616
    },
    {
      "id": 212,
      "seek": 39964,
      "start": 424.76,
      "end": 425.76,
      "text": " him.",
      "tokens": [
        51620,
        796,
        13,
        51670
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13389274644555513,
      "compression_ratio": 1.688073394495413,
      "no_speech_prob": 0.020326849073171616
    },
    {
      "id": 213,
      "seek": 39964,
      "start": 425.76,
      "end": 426.76,
      "text": " That's our master.",
      "tokens": [
        51670,
        663,
        311,
        527,
        4505,
        13,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13389274644555513,
      "compression_ratio": 1.688073394495413,
      "no_speech_prob": 0.020326849073171616
    },
    {
      "id": 214,
      "seek": 42676,
      "start": 426.76,
      "end": 430.8,
      "text": " So back at the master components, one of his components is the Kubernetes API server.",
      "tokens": [
        50364,
        407,
        646,
        412,
        264,
        4505,
        6677,
        11,
        472,
        295,
        702,
        6677,
        307,
        264,
        23145,
        9362,
        7154,
        13,
        50566
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18617536935461573,
      "compression_ratio": 1.8412698412698412,
      "no_speech_prob": 0.07078996300697327
    },
    {
      "id": 215,
      "seek": 42676,
      "start": 430.8,
      "end": 434.48,
      "text": " That's one of the big ones that we care about because that's how we talk to our master.",
      "tokens": [
        50566,
        663,
        311,
        472,
        295,
        264,
        955,
        2306,
        300,
        321,
        1127,
        466,
        570,
        300,
        311,
        577,
        321,
        751,
        281,
        527,
        4505,
        13,
        50750
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18617536935461573,
      "compression_ratio": 1.8412698412698412,
      "no_speech_prob": 0.07078996300697327
    },
    {
      "id": 216,
      "seek": 42676,
      "start": 434.48,
      "end": 435.68,
      "text": " That's how we tell him what to do.",
      "tokens": [
        50750,
        663,
        311,
        577,
        321,
        980,
        796,
        437,
        281,
        360,
        13,
        50810
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18617536935461573,
      "compression_ratio": 1.8412698412698412,
      "no_speech_prob": 0.07078996300697327
    },
    {
      "id": 217,
      "seek": 42676,
      "start": 435.68,
      "end": 438.0,
      "text": " I mean, he's the master, but we're the master master.",
      "tokens": [
        50810,
        286,
        914,
        11,
        415,
        311,
        264,
        4505,
        11,
        457,
        321,
        434,
        264,
        4505,
        4505,
        13,
        50926
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18617536935461573,
      "compression_ratio": 1.8412698412698412,
      "no_speech_prob": 0.07078996300697327
    },
    {
      "id": 218,
      "seek": 42676,
      "start": 438.0,
      "end": 439.2,
      "text": " We're the master of masters.",
      "tokens": [
        50926,
        492,
        434,
        264,
        4505,
        295,
        19294,
        13,
        50986
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18617536935461573,
      "compression_ratio": 1.8412698412698412,
      "no_speech_prob": 0.07078996300697327
    },
    {
      "id": 219,
      "seek": 42676,
      "start": 439.2,
      "end": 440.2,
      "text": " Okay, cool.",
      "tokens": [
        50986,
        1033,
        11,
        1627,
        13,
        51036
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18617536935461573,
      "compression_ratio": 1.8412698412698412,
      "no_speech_prob": 0.07078996300697327
    },
    {
      "id": 220,
      "seek": 42676,
      "start": 440.2,
      "end": 445.56,
      "text": " The Kubernetes API servers, how we communicate with them, but then how do we use that?",
      "tokens": [
        51036,
        440,
        23145,
        9362,
        15909,
        11,
        577,
        321,
        7890,
        365,
        552,
        11,
        457,
        550,
        577,
        360,
        321,
        764,
        300,
        30,
        51304
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18617536935461573,
      "compression_ratio": 1.8412698412698412,
      "no_speech_prob": 0.07078996300697327
    },
    {
      "id": 221,
      "seek": 42676,
      "start": 445.56,
      "end": 446.56,
      "text": " It's really easy actually.",
      "tokens": [
        51304,
        467,
        311,
        534,
        1858,
        767,
        13,
        51354
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18617536935461573,
      "compression_ratio": 1.8412698412698412,
      "no_speech_prob": 0.07078996300697327
    },
    {
      "id": 222,
      "seek": 42676,
      "start": 446.56,
      "end": 449.03999999999996,
      "text": " So there's a tool we can install on any machine really.",
      "tokens": [
        51354,
        407,
        456,
        311,
        257,
        2290,
        321,
        393,
        3625,
        322,
        604,
        3479,
        534,
        13,
        51478
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18617536935461573,
      "compression_ratio": 1.8412698412698412,
      "no_speech_prob": 0.07078996300697327
    },
    {
      "id": 223,
      "seek": 42676,
      "start": 449.03999999999996,
      "end": 451.88,
      "text": " I think it's available for Windows, Mac, and of course, Linux.",
      "tokens": [
        51478,
        286,
        519,
        309,
        311,
        2435,
        337,
        8591,
        11,
        5707,
        11,
        293,
        295,
        1164,
        11,
        18734,
        13,
        51620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18617536935461573,
      "compression_ratio": 1.8412698412698412,
      "no_speech_prob": 0.07078996300697327
    },
    {
      "id": 224,
      "seek": 42676,
      "start": 451.88,
      "end": 456.32,
      "text": " It's a tool called Cube CTL or Cube Cuddle.",
      "tokens": [
        51620,
        467,
        311,
        257,
        2290,
        1219,
        33003,
        19529,
        43,
        420,
        33003,
        383,
        532,
        2285,
        13,
        51842
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18617536935461573,
      "compression_ratio": 1.8412698412698412,
      "no_speech_prob": 0.07078996300697327
    },
    {
      "id": 225,
      "seek": 45632,
      "start": 456.32,
      "end": 460.15999999999997,
      "text": " It's a command line tool that when we install it, we can then run our commands very, very",
      "tokens": [
        50364,
        467,
        311,
        257,
        5622,
        1622,
        2290,
        300,
        562,
        321,
        3625,
        309,
        11,
        321,
        393,
        550,
        1190,
        527,
        16901,
        588,
        11,
        588,
        50556
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15355713604486476,
      "compression_ratio": 1.812121212121212,
      "no_speech_prob": 0.054895441979169846
    },
    {
      "id": 226,
      "seek": 45632,
      "start": 460.15999999999997,
      "end": 464.12,
      "text": " similar to Docker and make things happen, tell our master what to do, and then he tells the",
      "tokens": [
        50556,
        2531,
        281,
        33772,
        293,
        652,
        721,
        1051,
        11,
        980,
        527,
        4505,
        437,
        281,
        360,
        11,
        293,
        550,
        415,
        5112,
        264,
        50754
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15355713604486476,
      "compression_ratio": 1.812121212121212,
      "no_speech_prob": 0.054895441979169846
    },
    {
      "id": 227,
      "seek": 45632,
      "start": 464.12,
      "end": 465.96,
      "text": " worker nodes what to do.",
      "tokens": [
        50754,
        11346,
        13891,
        437,
        281,
        360,
        13,
        50846
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15355713604486476,
      "compression_ratio": 1.812121212121212,
      "no_speech_prob": 0.054895441979169846
    },
    {
      "id": 228,
      "seek": 45632,
      "start": 465.96,
      "end": 467.96,
      "text": " So let's get that Cube Cuddle set up.",
      "tokens": [
        50846,
        407,
        718,
        311,
        483,
        300,
        33003,
        383,
        532,
        2285,
        992,
        493,
        13,
        50946
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15355713604486476,
      "compression_ratio": 1.812121212121212,
      "no_speech_prob": 0.054895441979169846
    },
    {
      "id": 229,
      "seek": 45632,
      "start": 467.96,
      "end": 469.28,
      "text": " So here we're going to install it on Linux.",
      "tokens": [
        50946,
        407,
        510,
        321,
        434,
        516,
        281,
        3625,
        309,
        322,
        18734,
        13,
        51012
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15355713604486476,
      "compression_ratio": 1.812121212121212,
      "no_speech_prob": 0.054895441979169846
    },
    {
      "id": 230,
      "seek": 45632,
      "start": 469.28,
      "end": 470.8,
      "text": " So I've got my Kali Linux going.",
      "tokens": [
        51012,
        407,
        286,
        600,
        658,
        452,
        591,
        5103,
        18734,
        516,
        13,
        51088
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15355713604486476,
      "compression_ratio": 1.812121212121212,
      "no_speech_prob": 0.054895441979169846
    },
    {
      "id": 231,
      "seek": 45632,
      "start": 470.8,
      "end": 472.96,
      "text": " You can use Ubuntu or whatever you want to use.",
      "tokens": [
        51088,
        509,
        393,
        764,
        30230,
        45605,
        420,
        2035,
        291,
        528,
        281,
        764,
        13,
        51196
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15355713604486476,
      "compression_ratio": 1.812121212121212,
      "no_speech_prob": 0.054895441979169846
    },
    {
      "id": 232,
      "seek": 45632,
      "start": 472.96,
      "end": 477.0,
      "text": " First we'll download the latest release of Cube CTL or Cuddle, Cube Cuddle.",
      "tokens": [
        51196,
        2386,
        321,
        603,
        5484,
        264,
        6792,
        4374,
        295,
        33003,
        19529,
        43,
        420,
        383,
        532,
        2285,
        11,
        33003,
        383,
        532,
        2285,
        13,
        51398
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15355713604486476,
      "compression_ratio": 1.812121212121212,
      "no_speech_prob": 0.054895441979169846
    },
    {
      "id": 233,
      "seek": 45632,
      "start": 477.0,
      "end": 479.28,
      "text": " I had that link and these steps in the description below.",
      "tokens": [
        51398,
        286,
        632,
        300,
        2113,
        293,
        613,
        4439,
        294,
        264,
        3855,
        2507,
        13,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15355713604486476,
      "compression_ratio": 1.812121212121212,
      "no_speech_prob": 0.054895441979169846
    },
    {
      "id": 234,
      "seek": 45632,
      "start": 479.28,
      "end": 481.44,
      "text": " So go ahead and follow that, paste that in there.",
      "tokens": [
        51512,
        407,
        352,
        2286,
        293,
        1524,
        300,
        11,
        9163,
        300,
        294,
        456,
        13,
        51620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15355713604486476,
      "compression_ratio": 1.812121212121212,
      "no_speech_prob": 0.054895441979169846
    },
    {
      "id": 235,
      "seek": 45632,
      "start": 481.44,
      "end": 484.48,
      "text": " I'll hit enter and it downloads the release.",
      "tokens": [
        51620,
        286,
        603,
        2045,
        3242,
        293,
        309,
        36553,
        264,
        4374,
        13,
        51772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15355713604486476,
      "compression_ratio": 1.812121212121212,
      "no_speech_prob": 0.054895441979169846
    },
    {
      "id": 236,
      "seek": 48448,
      "start": 484.48,
      "end": 487.20000000000005,
      "text": " So I hit LS to list my files and directories.",
      "tokens": [
        50364,
        407,
        286,
        2045,
        36657,
        281,
        1329,
        452,
        7098,
        293,
        5391,
        530,
        13,
        50500
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1814420920650975,
      "compression_ratio": 1.7717391304347827,
      "no_speech_prob": 0.044606346637010574
    },
    {
      "id": 237,
      "seek": 48448,
      "start": 487.20000000000005,
      "end": 489.16,
      "text": " There it is right there, Cube Cuddle.",
      "tokens": [
        50500,
        821,
        309,
        307,
        558,
        456,
        11,
        33003,
        383,
        532,
        2285,
        13,
        50598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1814420920650975,
      "compression_ratio": 1.7717391304347827,
      "no_speech_prob": 0.044606346637010574
    },
    {
      "id": 238,
      "seek": 48448,
      "start": 489.16,
      "end": 491.28000000000003,
      "text": " Next we'll want to make sure that file is executable.",
      "tokens": [
        50598,
        3087,
        321,
        603,
        528,
        281,
        652,
        988,
        300,
        3991,
        307,
        7568,
        712,
        13,
        50704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1814420920650975,
      "compression_ratio": 1.7717391304347827,
      "no_speech_prob": 0.044606346637010574
    },
    {
      "id": 239,
      "seek": 48448,
      "start": 491.28000000000003,
      "end": 497.28000000000003,
      "text": " So I'll use command CHMOD for change modification and then I'll do plus X to make it executable.",
      "tokens": [
        50704,
        407,
        286,
        603,
        764,
        5622,
        5995,
        44,
        14632,
        337,
        1319,
        26747,
        293,
        550,
        286,
        603,
        360,
        1804,
        1783,
        281,
        652,
        309,
        7568,
        712,
        13,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1814420920650975,
      "compression_ratio": 1.7717391304347827,
      "no_speech_prob": 0.044606346637010574
    },
    {
      "id": 240,
      "seek": 48448,
      "start": 497.28000000000003,
      "end": 501.08000000000004,
      "text": " And I'll do period forward slash cube CTL.",
      "tokens": [
        51004,
        400,
        286,
        603,
        360,
        2896,
        2128,
        17330,
        13728,
        19529,
        43,
        13,
        51194
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1814420920650975,
      "compression_ratio": 1.7717391304347827,
      "no_speech_prob": 0.044606346637010574
    },
    {
      "id": 241,
      "seek": 48448,
      "start": 501.08000000000004,
      "end": 504.64000000000004,
      "text": " That's the file we're going to be editing right now and done.",
      "tokens": [
        51194,
        663,
        311,
        264,
        3991,
        321,
        434,
        516,
        281,
        312,
        10000,
        558,
        586,
        293,
        1096,
        13,
        51372
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1814420920650975,
      "compression_ratio": 1.7717391304347827,
      "no_speech_prob": 0.044606346637010574
    },
    {
      "id": 242,
      "seek": 48448,
      "start": 504.64000000000004,
      "end": 506.56,
      "text": " And then I'll move that command to my path.",
      "tokens": [
        51372,
        400,
        550,
        286,
        603,
        1286,
        300,
        5622,
        281,
        452,
        3100,
        13,
        51468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1814420920650975,
      "compression_ratio": 1.7717391304347827,
      "no_speech_prob": 0.044606346637010574
    },
    {
      "id": 243,
      "seek": 48448,
      "start": 506.56,
      "end": 508.36,
      "text": " This is important if you want to be able to use it.",
      "tokens": [
        51468,
        639,
        307,
        1021,
        498,
        291,
        528,
        281,
        312,
        1075,
        281,
        764,
        309,
        13,
        51558
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1814420920650975,
      "compression_ratio": 1.7717391304347827,
      "no_speech_prob": 0.044606346637010574
    },
    {
      "id": 244,
      "seek": 48448,
      "start": 508.36,
      "end": 512.6,
      "text": " So we'll do sudo mvremove dot forward slash cube CTL.",
      "tokens": [
        51558,
        407,
        321,
        603,
        360,
        459,
        2595,
        275,
        85,
        2579,
        1682,
        5893,
        2128,
        17330,
        13728,
        19529,
        43,
        13,
        51770
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1814420920650975,
      "compression_ratio": 1.7717391304347827,
      "no_speech_prob": 0.044606346637010574
    },
    {
      "id": 245,
      "seek": 51260,
      "start": 512.6,
      "end": 514.48,
      "text": " That's the same file we're looking at.",
      "tokens": [
        50364,
        663,
        311,
        264,
        912,
        3991,
        321,
        434,
        1237,
        412,
        13,
        50458
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16307286482590896,
      "compression_ratio": 1.6267123287671232,
      "no_speech_prob": 0.019739478826522827
    },
    {
      "id": 246,
      "seek": 51260,
      "start": 514.48,
      "end": 522.24,
      "text": " And move that to the forward slash user slash local slash bin slash cube CTL.",
      "tokens": [
        50458,
        400,
        1286,
        300,
        281,
        264,
        2128,
        17330,
        4195,
        17330,
        2654,
        17330,
        5171,
        17330,
        13728,
        19529,
        43,
        13,
        50846
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16307286482590896,
      "compression_ratio": 1.6267123287671232,
      "no_speech_prob": 0.019739478826522827
    },
    {
      "id": 247,
      "seek": 51260,
      "start": 522.24,
      "end": 526.28,
      "text": " And hit the enter button, put in your sudo password and done.",
      "tokens": [
        50846,
        400,
        2045,
        264,
        3242,
        2960,
        11,
        829,
        294,
        428,
        459,
        2595,
        11524,
        293,
        1096,
        13,
        51048
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16307286482590896,
      "compression_ratio": 1.6267123287671232,
      "no_speech_prob": 0.019739478826522827
    },
    {
      "id": 248,
      "seek": 51260,
      "start": 526.28,
      "end": 530.76,
      "text": " So Cube Cuddle is installed but how do we access our new cluster we created in Linode?",
      "tokens": [
        51048,
        407,
        33003,
        383,
        532,
        2285,
        307,
        8899,
        457,
        577,
        360,
        321,
        2105,
        527,
        777,
        13630,
        321,
        2942,
        294,
        9355,
        1429,
        30,
        51272
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16307286482590896,
      "compression_ratio": 1.6267123287671232,
      "no_speech_prob": 0.019739478826522827
    },
    {
      "id": 249,
      "seek": 51260,
      "start": 530.76,
      "end": 531.76,
      "text": " Let's do it real quick.",
      "tokens": [
        51272,
        961,
        311,
        360,
        309,
        957,
        1702,
        13,
        51322
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16307286482590896,
      "compression_ratio": 1.6267123287671232,
      "no_speech_prob": 0.019739478826522827
    },
    {
      "id": 250,
      "seek": 51260,
      "start": 531.76,
      "end": 536.6800000000001,
      "text": " Get back to your Linode dashboard and we scroll up to right here we see cube config.",
      "tokens": [
        51322,
        3240,
        646,
        281,
        428,
        9355,
        1429,
        18342,
        293,
        321,
        11369,
        493,
        281,
        558,
        510,
        321,
        536,
        13728,
        6662,
        13,
        51568
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16307286482590896,
      "compression_ratio": 1.6267123287671232,
      "no_speech_prob": 0.019739478826522827
    },
    {
      "id": 251,
      "seek": 51260,
      "start": 536.6800000000001,
      "end": 540.6,
      "text": " It's a YAML file and it gives us all the information we need to know to connect to our cluster here.",
      "tokens": [
        51568,
        467,
        311,
        257,
        398,
        2865,
        43,
        3991,
        293,
        309,
        2709,
        505,
        439,
        264,
        1589,
        321,
        643,
        281,
        458,
        281,
        1745,
        281,
        527,
        13630,
        510,
        13,
        51764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16307286482590896,
      "compression_ratio": 1.6267123287671232,
      "no_speech_prob": 0.019739478826522827
    },
    {
      "id": 252,
      "seek": 54060,
      "start": 540.6,
      "end": 543.84,
      "text": " You can either download the file or do what I'm going to do right now and that's open",
      "tokens": [
        50364,
        509,
        393,
        2139,
        5484,
        264,
        3991,
        420,
        360,
        437,
        286,
        478,
        516,
        281,
        360,
        558,
        586,
        293,
        300,
        311,
        1269,
        50526
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20639269279711175,
      "compression_ratio": 1.7950819672131149,
      "no_speech_prob": 0.07262313365936279
    },
    {
      "id": 253,
      "seek": 54060,
      "start": 543.84,
      "end": 546.72,
      "text": " up this little paper looking thing here and look at the code.",
      "tokens": [
        50526,
        493,
        341,
        707,
        3035,
        1237,
        551,
        510,
        293,
        574,
        412,
        264,
        3089,
        13,
        50670
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20639269279711175,
      "compression_ratio": 1.7950819672131149,
      "no_speech_prob": 0.07262313365936279
    },
    {
      "id": 254,
      "seek": 54060,
      "start": 546.72,
      "end": 548.6800000000001,
      "text": " I'm going to copy mine so I'll hit copy.",
      "tokens": [
        50670,
        286,
        478,
        516,
        281,
        5055,
        3892,
        370,
        286,
        603,
        2045,
        5055,
        13,
        50768
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20639269279711175,
      "compression_ratio": 1.7950819672131149,
      "no_speech_prob": 0.07262313365936279
    },
    {
      "id": 255,
      "seek": 54060,
      "start": 548.6800000000001,
      "end": 554.16,
      "text": " And then I'll get back to my Linux box, my Kali box and we'll create our cube config file.",
      "tokens": [
        50768,
        400,
        550,
        286,
        603,
        483,
        646,
        281,
        452,
        18734,
        2424,
        11,
        452,
        591,
        5103,
        2424,
        293,
        321,
        603,
        1884,
        527,
        13728,
        6662,
        3991,
        13,
        51042
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20639269279711175,
      "compression_ratio": 1.7950819672131149,
      "no_speech_prob": 0.07262313365936279
    },
    {
      "id": 256,
      "seek": 54060,
      "start": 554.16,
      "end": 560.6,
      "text": " I'm going to use nano to create that new file so I'll hit nano and then cubeconfig dot yaml",
      "tokens": [
        51042,
        286,
        478,
        516,
        281,
        764,
        30129,
        281,
        1884,
        300,
        777,
        3991,
        370,
        286,
        603,
        2045,
        30129,
        293,
        550,
        13728,
        1671,
        20646,
        5893,
        288,
        335,
        75,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20639269279711175,
      "compression_ratio": 1.7950819672131149,
      "no_speech_prob": 0.07262313365936279
    },
    {
      "id": 257,
      "seek": 54060,
      "start": 560.6,
      "end": 561.6,
      "text": " dot yaml.",
      "tokens": [
        51364,
        5893,
        288,
        335,
        75,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20639269279711175,
      "compression_ratio": 1.7950819672131149,
      "no_speech_prob": 0.07262313365936279
    },
    {
      "id": 258,
      "seek": 54060,
      "start": 561.6,
      "end": 566.12,
      "text": " I'll paste that in there, hit CTRL X and then Y to save.",
      "tokens": [
        51414,
        286,
        603,
        9163,
        300,
        294,
        456,
        11,
        2045,
        19529,
        10740,
        1783,
        293,
        550,
        398,
        281,
        3155,
        13,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20639269279711175,
      "compression_ratio": 1.7950819672131149,
      "no_speech_prob": 0.07262313365936279
    },
    {
      "id": 259,
      "seek": 56612,
      "start": 566.12,
      "end": 571.4,
      "text": " And then one last command to get this ready we'll use the command export cubeconfig all",
      "tokens": [
        50364,
        400,
        550,
        472,
        1036,
        5622,
        281,
        483,
        341,
        1919,
        321,
        603,
        764,
        264,
        5622,
        10725,
        13728,
        1671,
        20646,
        439,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18392734229564667,
      "compression_ratio": 1.6587301587301588,
      "no_speech_prob": 0.028017202392220497
    },
    {
      "id": 260,
      "seek": 56612,
      "start": 571.4,
      "end": 576.72,
      "text": " uppercase equals that file cubeconfig dot yaml.",
      "tokens": [
        50628,
        11775,
        2869,
        651,
        6915,
        300,
        3991,
        13728,
        1671,
        20646,
        5893,
        288,
        335,
        75,
        13,
        50894
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18392734229564667,
      "compression_ratio": 1.6587301587301588,
      "no_speech_prob": 0.028017202392220497
    },
    {
      "id": 261,
      "seek": 56612,
      "start": 576.72,
      "end": 577.92,
      "text": " Done.",
      "tokens": [
        50894,
        18658,
        13,
        50954
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18392734229564667,
      "compression_ratio": 1.6587301587301588,
      "no_speech_prob": 0.028017202392220497
    },
    {
      "id": 262,
      "seek": 56612,
      "start": 577.92,
      "end": 578.92,
      "text": " So you're done.",
      "tokens": [
        50954,
        407,
        291,
        434,
        1096,
        13,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18392734229564667,
      "compression_ratio": 1.6587301587301588,
      "no_speech_prob": 0.028017202392220497
    },
    {
      "id": 263,
      "seek": 56612,
      "start": 578.92,
      "end": 583.48,
      "text": " You're able to connect to your cluster and do stuff but what do we do now?",
      "tokens": [
        51004,
        509,
        434,
        1075,
        281,
        1745,
        281,
        428,
        13630,
        293,
        360,
        1507,
        457,
        437,
        360,
        321,
        360,
        586,
        30,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18392734229564667,
      "compression_ratio": 1.6587301587301588,
      "no_speech_prob": 0.028017202392220497
    },
    {
      "id": 264,
      "seek": 56612,
      "start": 583.48,
      "end": 584.48,
      "text": " Let's try it out.",
      "tokens": [
        51232,
        961,
        311,
        853,
        309,
        484,
        13,
        51282
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18392734229564667,
      "compression_ratio": 1.6587301587301588,
      "no_speech_prob": 0.028017202392220497
    },
    {
      "id": 265,
      "seek": 56612,
      "start": 584.48,
      "end": 586.44,
      "text": " So the first command we're going to do is we're going to look at our worker nodes.",
      "tokens": [
        51282,
        407,
        264,
        700,
        5622,
        321,
        434,
        516,
        281,
        360,
        307,
        321,
        434,
        516,
        281,
        574,
        412,
        527,
        11346,
        13891,
        13,
        51380
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18392734229564667,
      "compression_ratio": 1.6587301587301588,
      "no_speech_prob": 0.028017202392220497
    },
    {
      "id": 266,
      "seek": 56612,
      "start": 586.44,
      "end": 589.2,
      "text": " Make sure they're there, okay, alive, are you guys okay?",
      "tokens": [
        51380,
        4387,
        988,
        436,
        434,
        456,
        11,
        1392,
        11,
        5465,
        11,
        366,
        291,
        1074,
        1392,
        30,
        51518
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18392734229564667,
      "compression_ratio": 1.6587301587301588,
      "no_speech_prob": 0.028017202392220497
    },
    {
      "id": 267,
      "seek": 56612,
      "start": 589.2,
      "end": 593.28,
      "text": " It'll be cubectl get nodes.",
      "tokens": [
        51518,
        467,
        603,
        312,
        13728,
        349,
        75,
        483,
        13891,
        13,
        51722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18392734229564667,
      "compression_ratio": 1.6587301587301588,
      "no_speech_prob": 0.028017202392220497
    },
    {
      "id": 268,
      "seek": 59328,
      "start": 593.28,
      "end": 596.8399999999999,
      "text": " This is going to get the 411 on our worker nodes that we just created in Linode.",
      "tokens": [
        50364,
        639,
        307,
        516,
        281,
        483,
        264,
        1017,
        5348,
        322,
        527,
        11346,
        13891,
        300,
        321,
        445,
        2942,
        294,
        9355,
        1429,
        13,
        50542
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18565626205152766,
      "compression_ratio": 1.7491749174917492,
      "no_speech_prob": 0.15658916532993317
    },
    {
      "id": 269,
      "seek": 59328,
      "start": 596.8399999999999,
      "end": 597.8399999999999,
      "text": " Let's check it out.",
      "tokens": [
        50542,
        961,
        311,
        1520,
        309,
        484,
        13,
        50592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18565626205152766,
      "compression_ratio": 1.7491749174917492,
      "no_speech_prob": 0.15658916532993317
    },
    {
      "id": 270,
      "seek": 59328,
      "start": 597.8399999999999,
      "end": 598.8399999999999,
      "text": " There they are.",
      "tokens": [
        50592,
        821,
        436,
        366,
        13,
        50642
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18565626205152766,
      "compression_ratio": 1.7491749174917492,
      "no_speech_prob": 0.15658916532993317
    },
    {
      "id": 271,
      "seek": 59328,
      "start": 598.8399999999999,
      "end": 599.8399999999999,
      "text": " Awesome.",
      "tokens": [
        50642,
        10391,
        13,
        50692
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18565626205152766,
      "compression_ratio": 1.7491749174917492,
      "no_speech_prob": 0.15658916532993317
    },
    {
      "id": 272,
      "seek": 59328,
      "start": 599.8399999999999,
      "end": 600.8399999999999,
      "text": " There's their names.",
      "tokens": [
        50692,
        821,
        311,
        641,
        5288,
        13,
        50742
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18565626205152766,
      "compression_ratio": 1.7491749174917492,
      "no_speech_prob": 0.15658916532993317
    },
    {
      "id": 273,
      "seek": 59328,
      "start": 600.8399999999999,
      "end": 601.8399999999999,
      "text": " They are ready.",
      "tokens": [
        50742,
        814,
        366,
        1919,
        13,
        50792
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18565626205152766,
      "compression_ratio": 1.7491749174917492,
      "no_speech_prob": 0.15658916532993317
    },
    {
      "id": 274,
      "seek": 59328,
      "start": 601.8399999999999,
      "end": 603.8,
      "text": " Only 24 minutes old, so young.",
      "tokens": [
        50792,
        5686,
        4022,
        2077,
        1331,
        11,
        370,
        2037,
        13,
        50890
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18565626205152766,
      "compression_ratio": 1.7491749174917492,
      "no_speech_prob": 0.15658916532993317
    },
    {
      "id": 275,
      "seek": 59328,
      "start": 603.8,
      "end": 604.8,
      "text": " Let's enter one more.",
      "tokens": [
        50890,
        961,
        311,
        3242,
        472,
        544,
        13,
        50940
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18565626205152766,
      "compression_ratio": 1.7491749174917492,
      "no_speech_prob": 0.15658916532993317
    },
    {
      "id": 276,
      "seek": 59328,
      "start": 604.8,
      "end": 608.4399999999999,
      "text": " We'll do cubectl cluster dash info.",
      "tokens": [
        50940,
        492,
        603,
        360,
        13728,
        349,
        75,
        13630,
        8240,
        13614,
        13,
        51122
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18565626205152766,
      "compression_ratio": 1.7491749174917492,
      "no_speech_prob": 0.15658916532993317
    },
    {
      "id": 277,
      "seek": 59328,
      "start": 608.4399999999999,
      "end": 609.76,
      "text": " And we get some cool information right here.",
      "tokens": [
        51122,
        400,
        321,
        483,
        512,
        1627,
        1589,
        558,
        510,
        13,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18565626205152766,
      "compression_ratio": 1.7491749174917492,
      "no_speech_prob": 0.15658916532993317
    },
    {
      "id": 278,
      "seek": 59328,
      "start": 609.76,
      "end": 612.4399999999999,
      "text": " Cube DNS we're not going to cover that right now but there's our master right there.",
      "tokens": [
        51188,
        33003,
        35153,
        321,
        434,
        406,
        516,
        281,
        2060,
        300,
        558,
        586,
        457,
        456,
        311,
        527,
        4505,
        558,
        456,
        13,
        51322
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18565626205152766,
      "compression_ratio": 1.7491749174917492,
      "no_speech_prob": 0.15658916532993317
    },
    {
      "id": 279,
      "seek": 59328,
      "start": 612.4399999999999,
      "end": 613.72,
      "text": " I told you that was the master.",
      "tokens": [
        51322,
        286,
        1907,
        291,
        300,
        390,
        264,
        4505,
        13,
        51386
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18565626205152766,
      "compression_ratio": 1.7491749174917492,
      "no_speech_prob": 0.15658916532993317
    },
    {
      "id": 280,
      "seek": 59328,
      "start": 613.72,
      "end": 616.28,
      "text": " Okay, so now we have our Kubernetes cluster ready.",
      "tokens": [
        51386,
        1033,
        11,
        370,
        586,
        321,
        362,
        527,
        23145,
        13630,
        1919,
        13,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18565626205152766,
      "compression_ratio": 1.7491749174917492,
      "no_speech_prob": 0.15658916532993317
    },
    {
      "id": 281,
      "seek": 59328,
      "start": 616.28,
      "end": 619.28,
      "text": " The master, the worker nodes, we even have our workstation ready.",
      "tokens": [
        51514,
        440,
        4505,
        11,
        264,
        11346,
        13891,
        11,
        321,
        754,
        362,
        527,
        589,
        19159,
        1919,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18565626205152766,
      "compression_ratio": 1.7491749174917492,
      "no_speech_prob": 0.15658916532993317
    },
    {
      "id": 282,
      "seek": 61928,
      "start": 619.28,
      "end": 623.8399999999999,
      "text": " We have the cube cuddle or cubectl tool installed so we can communicate and talk to our master",
      "tokens": [
        50364,
        492,
        362,
        264,
        13728,
        40287,
        2285,
        420,
        13728,
        349,
        75,
        2290,
        8899,
        370,
        321,
        393,
        7890,
        293,
        751,
        281,
        527,
        4505,
        50592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17459889524471686,
      "compression_ratio": 1.727810650887574,
      "no_speech_prob": 0.1544564962387085
    },
    {
      "id": 283,
      "seek": 61928,
      "start": 623.8399999999999,
      "end": 627.72,
      "text": " through the Kubernetes API server.",
      "tokens": [
        50592,
        807,
        264,
        23145,
        9362,
        7154,
        13,
        50786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17459889524471686,
      "compression_ratio": 1.727810650887574,
      "no_speech_prob": 0.1544564962387085
    },
    {
      "id": 284,
      "seek": 61928,
      "start": 627.72,
      "end": 628.8,
      "text": " But what do we do now?",
      "tokens": [
        50786,
        583,
        437,
        360,
        321,
        360,
        586,
        30,
        50840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17459889524471686,
      "compression_ratio": 1.727810650887574,
      "no_speech_prob": 0.1544564962387085
    },
    {
      "id": 285,
      "seek": 61928,
      "start": 628.8,
      "end": 630.56,
      "text": " How do we deploy our website?",
      "tokens": [
        50840,
        1012,
        360,
        321,
        7274,
        527,
        3144,
        30,
        50928
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17459889524471686,
      "compression_ratio": 1.727810650887574,
      "no_speech_prob": 0.1544564962387085
    },
    {
      "id": 286,
      "seek": 61928,
      "start": 630.56,
      "end": 631.72,
      "text": " That was the whole point, right?",
      "tokens": [
        50928,
        663,
        390,
        264,
        1379,
        935,
        11,
        558,
        30,
        50986
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17459889524471686,
      "compression_ratio": 1.727810650887574,
      "no_speech_prob": 0.1544564962387085
    },
    {
      "id": 287,
      "seek": 61928,
      "start": 631.72,
      "end": 632.92,
      "text": " Like how do we solve our problems?",
      "tokens": [
        50986,
        1743,
        577,
        360,
        321,
        5039,
        527,
        2740,
        30,
        51046
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17459889524471686,
      "compression_ratio": 1.727810650887574,
      "no_speech_prob": 0.1544564962387085
    },
    {
      "id": 288,
      "seek": 61928,
      "start": 632.92,
      "end": 635.6,
      "text": " The good news is that it's very, very similar to Docker.",
      "tokens": [
        51046,
        440,
        665,
        2583,
        307,
        300,
        309,
        311,
        588,
        11,
        588,
        2531,
        281,
        33772,
        13,
        51180
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17459889524471686,
      "compression_ratio": 1.727810650887574,
      "no_speech_prob": 0.1544564962387085
    },
    {
      "id": 289,
      "seek": 61928,
      "start": 635.6,
      "end": 640.4,
      "text": " We'll use a command that looks like this, cubectl and we'll say run.",
      "tokens": [
        51180,
        492,
        603,
        764,
        257,
        5622,
        300,
        1542,
        411,
        341,
        11,
        13728,
        349,
        75,
        293,
        321,
        603,
        584,
        1190,
        13,
        51420
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17459889524471686,
      "compression_ratio": 1.727810650887574,
      "no_speech_prob": 0.1544564962387085
    },
    {
      "id": 290,
      "seek": 61928,
      "start": 640.4,
      "end": 643.0,
      "text": " Just like our Docker run command and we'll create our container.",
      "tokens": [
        51420,
        1449,
        411,
        527,
        33772,
        1190,
        5622,
        293,
        321,
        603,
        1884,
        527,
        10129,
        13,
        51550
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17459889524471686,
      "compression_ratio": 1.727810650887574,
      "no_speech_prob": 0.1544564962387085
    },
    {
      "id": 291,
      "seek": 61928,
      "start": 643.0,
      "end": 644.12,
      "text": " Now hold on one second.",
      "tokens": [
        51550,
        823,
        1797,
        322,
        472,
        1150,
        13,
        51606
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17459889524471686,
      "compression_ratio": 1.727810650887574,
      "no_speech_prob": 0.1544564962387085
    },
    {
      "id": 292,
      "seek": 61928,
      "start": 644.12,
      "end": 646.12,
      "text": " I got to add one more term for you to know.",
      "tokens": [
        51606,
        286,
        658,
        281,
        909,
        472,
        544,
        1433,
        337,
        291,
        281,
        458,
        13,
        51706
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17459889524471686,
      "compression_ratio": 1.727810650887574,
      "no_speech_prob": 0.1544564962387085
    },
    {
      "id": 293,
      "seek": 61928,
      "start": 646.12,
      "end": 649.24,
      "text": " When we create a container in Kubernetes, we're creating something called.",
      "tokens": [
        51706,
        1133,
        321,
        1884,
        257,
        10129,
        294,
        23145,
        11,
        321,
        434,
        4084,
        746,
        1219,
        13,
        51862
      ],
      "temperature": 0.0,
      "avg_logprob": -0.17459889524471686,
      "compression_ratio": 1.727810650887574,
      "no_speech_prob": 0.1544564962387085
    },
    {
      "id": 294,
      "seek": 64924,
      "start": 649.6800000000001,
      "end": 652.76,
      "text": " A pod and inside that pod, we have our container.",
      "tokens": [
        50386,
        316,
        2497,
        293,
        1854,
        300,
        2497,
        11,
        321,
        362,
        527,
        10129,
        13,
        50540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21082004678660426,
      "compression_ratio": 1.8065573770491803,
      "no_speech_prob": 0.0011277369922026992
    },
    {
      "id": 295,
      "seek": 64924,
      "start": 652.76,
      "end": 655.72,
      "text": " So when you think about Kubernetes, think about pods as containers.",
      "tokens": [
        50540,
        407,
        562,
        291,
        519,
        466,
        23145,
        11,
        519,
        466,
        31925,
        382,
        17089,
        13,
        50688
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21082004678660426,
      "compression_ratio": 1.8065573770491803,
      "no_speech_prob": 0.0011277369922026992
    },
    {
      "id": 296,
      "seek": 64924,
      "start": 655.72,
      "end": 660.48,
      "text": " Now, technically the containers are inside the pods and you can even have multiple containers",
      "tokens": [
        50688,
        823,
        11,
        12120,
        264,
        17089,
        366,
        1854,
        264,
        31925,
        293,
        291,
        393,
        754,
        362,
        3866,
        17089,
        50926
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21082004678660426,
      "compression_ratio": 1.8065573770491803,
      "no_speech_prob": 0.0011277369922026992
    },
    {
      "id": 297,
      "seek": 64924,
      "start": 660.48,
      "end": 661.48,
      "text": " inside these pods.",
      "tokens": [
        50926,
        1854,
        613,
        31925,
        13,
        50976
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21082004678660426,
      "compression_ratio": 1.8065573770491803,
      "no_speech_prob": 0.0011277369922026992
    },
    {
      "id": 298,
      "seek": 64924,
      "start": 661.48,
      "end": 664.08,
      "text": " Like we can add another one, add another one.",
      "tokens": [
        50976,
        1743,
        321,
        393,
        909,
        1071,
        472,
        11,
        909,
        1071,
        472,
        13,
        51106
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21082004678660426,
      "compression_ratio": 1.8065573770491803,
      "no_speech_prob": 0.0011277369922026992
    },
    {
      "id": 299,
      "seek": 64924,
      "start": 664.08,
      "end": 668.08,
      "text": " But typically you'll have one container per pod, which sounds weird.",
      "tokens": [
        51106,
        583,
        5850,
        291,
        603,
        362,
        472,
        10129,
        680,
        2497,
        11,
        597,
        3263,
        3657,
        13,
        51306
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21082004678660426,
      "compression_ratio": 1.8065573770491803,
      "no_speech_prob": 0.0011277369922026992
    },
    {
      "id": 300,
      "seek": 64924,
      "start": 668.08,
      "end": 669.96,
      "text": " I know, but let's create one real quick.",
      "tokens": [
        51306,
        286,
        458,
        11,
        457,
        718,
        311,
        1884,
        472,
        957,
        1702,
        13,
        51400
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21082004678660426,
      "compression_ratio": 1.8065573770491803,
      "no_speech_prob": 0.0011277369922026992
    },
    {
      "id": 301,
      "seek": 64924,
      "start": 669.96,
      "end": 672.6800000000001,
      "text": " The command will be cubectl run.",
      "tokens": [
        51400,
        440,
        5622,
        486,
        312,
        13728,
        349,
        75,
        1190,
        13,
        51536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21082004678660426,
      "compression_ratio": 1.8065573770491803,
      "no_speech_prob": 0.0011277369922026992
    },
    {
      "id": 302,
      "seek": 64924,
      "start": 672.6800000000001,
      "end": 675.76,
      "text": " Like I just said, I'll name my pod, just name it network check coffee.",
      "tokens": [
        51536,
        1743,
        286,
        445,
        848,
        11,
        286,
        603,
        1315,
        452,
        2497,
        11,
        445,
        1315,
        309,
        3209,
        1520,
        4982,
        13,
        51690
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21082004678660426,
      "compression_ratio": 1.8065573770491803,
      "no_speech_prob": 0.0011277369922026992
    },
    {
      "id": 303,
      "seek": 64924,
      "start": 675.76,
      "end": 678.84,
      "text": " And then I'll specify my Docker image that I'm going to use.",
      "tokens": [
        51690,
        400,
        550,
        286,
        603,
        16500,
        452,
        33772,
        3256,
        300,
        286,
        478,
        516,
        281,
        764,
        13,
        51844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21082004678660426,
      "compression_ratio": 1.8065573770491803,
      "no_speech_prob": 0.0011277369922026992
    },
    {
      "id": 304,
      "seek": 67884,
      "start": 678.84,
      "end": 682.88,
      "text": " I'll do dash dash image equals and then the image I'm going to pull down, which if you're",
      "tokens": [
        50364,
        286,
        603,
        360,
        8240,
        8240,
        3256,
        6915,
        293,
        550,
        264,
        3256,
        286,
        478,
        516,
        281,
        2235,
        760,
        11,
        597,
        498,
        291,
        434,
        50566
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21169204711914064,
      "compression_ratio": 1.6692607003891051,
      "no_speech_prob": 0.0024313798639923334
    },
    {
      "id": 305,
      "seek": 67884,
      "start": 682.88,
      "end": 684.84,
      "text": " going to follow along, it'll be this image right here.",
      "tokens": [
        50566,
        516,
        281,
        1524,
        2051,
        11,
        309,
        603,
        312,
        341,
        3256,
        558,
        510,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21169204711914064,
      "compression_ratio": 1.6692607003891051,
      "no_speech_prob": 0.0024313798639923334
    },
    {
      "id": 306,
      "seek": 67884,
      "start": 684.84,
      "end": 692.0,
      "text": " It'll be the network check forward slash NC coffee and then colon pour over and then",
      "tokens": [
        50664,
        467,
        603,
        312,
        264,
        3209,
        1520,
        2128,
        17330,
        20786,
        4982,
        293,
        550,
        8255,
        2016,
        670,
        293,
        550,
        51022
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21169204711914064,
      "compression_ratio": 1.6692607003891051,
      "no_speech_prob": 0.0024313798639923334
    },
    {
      "id": 307,
      "seek": 67884,
      "start": 692.0,
      "end": 697.84,
      "text": " we'll open up ports dash dash port equals 80 the website port, you know, HTTP.",
      "tokens": [
        51022,
        321,
        603,
        1269,
        493,
        18160,
        8240,
        8240,
        2436,
        6915,
        4688,
        264,
        3144,
        2436,
        11,
        291,
        458,
        11,
        33283,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21169204711914064,
      "compression_ratio": 1.6692607003891051,
      "no_speech_prob": 0.0024313798639923334
    },
    {
      "id": 308,
      "seek": 67884,
      "start": 697.84,
      "end": 701.72,
      "text": " So we'll do that real quick and go.",
      "tokens": [
        51314,
        407,
        321,
        603,
        360,
        300,
        957,
        1702,
        293,
        352,
        13,
        51508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21169204711914064,
      "compression_ratio": 1.6692607003891051,
      "no_speech_prob": 0.0024313798639923334
    },
    {
      "id": 309,
      "seek": 67884,
      "start": 701.72,
      "end": 702.84,
      "text": " Created done.",
      "tokens": [
        51508,
        11972,
        292,
        1096,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21169204711914064,
      "compression_ratio": 1.6692607003891051,
      "no_speech_prob": 0.0024313798639923334
    },
    {
      "id": 310,
      "seek": 67884,
      "start": 702.84,
      "end": 707.32,
      "text": " If we use a command cubectl get pods, we see it's happening right now.",
      "tokens": [
        51564,
        759,
        321,
        764,
        257,
        5622,
        13728,
        349,
        75,
        483,
        31925,
        11,
        321,
        536,
        309,
        311,
        2737,
        558,
        586,
        13,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21169204711914064,
      "compression_ratio": 1.6692607003891051,
      "no_speech_prob": 0.0024313798639923334
    },
    {
      "id": 311,
      "seek": 70732,
      "start": 707.32,
      "end": 710.48,
      "text": " So the container is creating inside that pod.",
      "tokens": [
        50364,
        407,
        264,
        10129,
        307,
        4084,
        1854,
        300,
        2497,
        13,
        50522
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1994463233060615,
      "compression_ratio": 1.7891373801916932,
      "no_speech_prob": 0.08797095715999603
    },
    {
      "id": 312,
      "seek": 70732,
      "start": 710.48,
      "end": 711.48,
      "text": " Let's do it again.",
      "tokens": [
        50522,
        961,
        311,
        360,
        309,
        797,
        13,
        50572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1994463233060615,
      "compression_ratio": 1.7891373801916932,
      "no_speech_prob": 0.08797095715999603
    },
    {
      "id": 313,
      "seek": 70732,
      "start": 711.48,
      "end": 712.6,
      "text": " She kind of, oh, it's done.",
      "tokens": [
        50572,
        1240,
        733,
        295,
        11,
        1954,
        11,
        309,
        311,
        1096,
        13,
        50628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1994463233060615,
      "compression_ratio": 1.7891373801916932,
      "no_speech_prob": 0.08797095715999603
    },
    {
      "id": 314,
      "seek": 70732,
      "start": 712.6,
      "end": 715.36,
      "text": " It's running, but it's just done.",
      "tokens": [
        50628,
        467,
        311,
        2614,
        11,
        457,
        309,
        311,
        445,
        1096,
        13,
        50766
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1994463233060615,
      "compression_ratio": 1.7891373801916932,
      "no_speech_prob": 0.08797095715999603
    },
    {
      "id": 315,
      "seek": 70732,
      "start": 715.36,
      "end": 720.24,
      "text": " We just created our first Kubernetes pod running our container, our website, which seems weird",
      "tokens": [
        50766,
        492,
        445,
        2942,
        527,
        700,
        23145,
        2497,
        2614,
        527,
        10129,
        11,
        527,
        3144,
        11,
        597,
        2544,
        3657,
        51010
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1994463233060615,
      "compression_ratio": 1.7891373801916932,
      "no_speech_prob": 0.08797095715999603
    },
    {
      "id": 316,
      "seek": 70732,
      "start": 720.24,
      "end": 721.24,
      "text": " and kind of confusing.",
      "tokens": [
        51010,
        293,
        733,
        295,
        13181,
        13,
        51060
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1994463233060615,
      "compression_ratio": 1.7891373801916932,
      "no_speech_prob": 0.08797095715999603
    },
    {
      "id": 317,
      "seek": 70732,
      "start": 721.24,
      "end": 725.0,
      "text": " I know, trust me, but looking back at our diagram, this is what happened using cubes.",
      "tokens": [
        51060,
        286,
        458,
        11,
        3361,
        385,
        11,
        457,
        1237,
        646,
        412,
        527,
        10686,
        11,
        341,
        307,
        437,
        2011,
        1228,
        25415,
        13,
        51248
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1994463233060615,
      "compression_ratio": 1.7891373801916932,
      "no_speech_prob": 0.08797095715999603
    },
    {
      "id": 318,
      "seek": 70732,
      "start": 725.0,
      "end": 726.0,
      "text": " E.T.L.",
      "tokens": [
        51248,
        462,
        13,
        51,
        13,
        43,
        13,
        51298
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1994463233060615,
      "compression_ratio": 1.7891373801916932,
      "no_speech_prob": 0.08797095715999603
    },
    {
      "id": 319,
      "seek": 70732,
      "start": 726.0,
      "end": 727.6800000000001,
      "text": " We said, Hey, master, I want you to run with this.",
      "tokens": [
        51298,
        492,
        848,
        11,
        1911,
        11,
        4505,
        11,
        286,
        528,
        291,
        281,
        1190,
        365,
        341,
        13,
        51382
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1994463233060615,
      "compression_ratio": 1.7891373801916932,
      "no_speech_prob": 0.08797095715999603
    },
    {
      "id": 320,
      "seek": 70732,
      "start": 727.6800000000001,
      "end": 731.32,
      "text": " I want you to create a container for me, which I know will be inside a pod.",
      "tokens": [
        51382,
        286,
        528,
        291,
        281,
        1884,
        257,
        10129,
        337,
        385,
        11,
        597,
        286,
        458,
        486,
        312,
        1854,
        257,
        2497,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1994463233060615,
      "compression_ratio": 1.7891373801916932,
      "no_speech_prob": 0.08797095715999603
    },
    {
      "id": 321,
      "seek": 70732,
      "start": 731.32,
      "end": 733.72,
      "text": " So I said, cubes E.T.L run blah, blah, blah, do this.",
      "tokens": [
        51564,
        407,
        286,
        848,
        11,
        25415,
        462,
        13,
        51,
        13,
        43,
        1190,
        12288,
        11,
        12288,
        11,
        12288,
        11,
        360,
        341,
        13,
        51684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1994463233060615,
      "compression_ratio": 1.7891373801916932,
      "no_speech_prob": 0.08797095715999603
    },
    {
      "id": 322,
      "seek": 70732,
      "start": 733.72,
      "end": 735.6,
      "text": " And he did using his scheduler component.",
      "tokens": [
        51684,
        400,
        415,
        630,
        1228,
        702,
        12000,
        260,
        6542,
        13,
        51778
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1994463233060615,
      "compression_ratio": 1.7891373801916932,
      "no_speech_prob": 0.08797095715999603
    },
    {
      "id": 323,
      "seek": 73560,
      "start": 735.6,
      "end": 738.9200000000001,
      "text": " He goes, Hmm, which one of my worker nodes gets this pod?",
      "tokens": [
        50364,
        634,
        1709,
        11,
        8239,
        11,
        597,
        472,
        295,
        452,
        11346,
        13891,
        2170,
        341,
        2497,
        30,
        50530
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 324,
      "seek": 73560,
      "start": 738.9200000000001,
      "end": 739.9200000000001,
      "text": " You know what?",
      "tokens": [
        50530,
        509,
        458,
        437,
        30,
        50580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 325,
      "seek": 73560,
      "start": 739.9200000000001,
      "end": 740.9200000000001,
      "text": " This guy right here, he's not doing anything.",
      "tokens": [
        50580,
        639,
        2146,
        558,
        510,
        11,
        415,
        311,
        406,
        884,
        1340,
        13,
        50630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 326,
      "seek": 73560,
      "start": 740.9200000000001,
      "end": 741.9200000000001,
      "text": " Hey, hey, Roger.",
      "tokens": [
        50630,
        1911,
        11,
        4177,
        11,
        17666,
        13,
        50680
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 327,
      "seek": 73560,
      "start": 741.9200000000001,
      "end": 745.4,
      "text": " Roger, Roger, Roger, I want you to run this application.",
      "tokens": [
        50680,
        17666,
        11,
        17666,
        11,
        17666,
        11,
        286,
        528,
        291,
        281,
        1190,
        341,
        3861,
        13,
        50854
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 328,
      "seek": 73560,
      "start": 745.4,
      "end": 746.4,
      "text": " Go.",
      "tokens": [
        50854,
        1037,
        13,
        50904
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 329,
      "seek": 73560,
      "start": 746.4,
      "end": 747.4,
      "text": " And he did.",
      "tokens": [
        50904,
        400,
        415,
        630,
        13,
        50954
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 330,
      "seek": 73560,
      "start": 747.4,
      "end": 748.4,
      "text": " Now I want to look inside this pod.",
      "tokens": [
        50954,
        823,
        286,
        528,
        281,
        574,
        1854,
        341,
        2497,
        13,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 331,
      "seek": 73560,
      "start": 748.4,
      "end": 749.4,
      "text": " I want to see what's going on.",
      "tokens": [
        51004,
        286,
        528,
        281,
        536,
        437,
        311,
        516,
        322,
        13,
        51054
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 332,
      "seek": 73560,
      "start": 749.4,
      "end": 750.4,
      "text": " I want to know.",
      "tokens": [
        51054,
        286,
        528,
        281,
        458,
        13,
        51104
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 333,
      "seek": 73560,
      "start": 750.4,
      "end": 753.32,
      "text": " So looking back at our Linux box, we can use a command called describe.",
      "tokens": [
        51104,
        407,
        1237,
        646,
        412,
        527,
        18734,
        2424,
        11,
        321,
        393,
        764,
        257,
        5622,
        1219,
        6786,
        13,
        51250
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 334,
      "seek": 73560,
      "start": 753.32,
      "end": 755.12,
      "text": " It'll be cubectl describe.",
      "tokens": [
        51250,
        467,
        603,
        312,
        13728,
        349,
        75,
        6786,
        13,
        51340
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 335,
      "seek": 73560,
      "start": 755.12,
      "end": 759.28,
      "text": " And we'll just put in pods and let's see what happens.",
      "tokens": [
        51340,
        400,
        321,
        603,
        445,
        829,
        294,
        31925,
        293,
        718,
        311,
        536,
        437,
        2314,
        13,
        51548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 336,
      "seek": 73560,
      "start": 759.28,
      "end": 760.28,
      "text": " Boom.",
      "tokens": [
        51548,
        15523,
        13,
        51598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 337,
      "seek": 73560,
      "start": 760.28,
      "end": 762.44,
      "text": " We get the whole load down on what this guy's doing.",
      "tokens": [
        51598,
        492,
        483,
        264,
        1379,
        3677,
        760,
        322,
        437,
        341,
        2146,
        311,
        884,
        13,
        51706
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 338,
      "seek": 73560,
      "start": 762.44,
      "end": 763.44,
      "text": " A lot of information.",
      "tokens": [
        51706,
        316,
        688,
        295,
        1589,
        13,
        51756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 339,
      "seek": 73560,
      "start": 763.44,
      "end": 765.2,
      "text": " We got the name network, Chuck coffee.",
      "tokens": [
        51756,
        492,
        658,
        264,
        1315,
        3209,
        11,
        21607,
        4982,
        13,
        51844
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20716547704004978,
      "compression_ratio": 1.7069486404833838,
      "no_speech_prob": 0.02678057551383972
    },
    {
      "id": 340,
      "seek": 76520,
      "start": 765.2,
      "end": 766.48,
      "text": " We got his IP address.",
      "tokens": [
        50364,
        492,
        658,
        702,
        8671,
        2985,
        13,
        50428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1635102821118904,
      "compression_ratio": 1.7787878787878788,
      "no_speech_prob": 0.01685609668493271
    },
    {
      "id": 341,
      "seek": 76520,
      "start": 766.48,
      "end": 769.08,
      "text": " Every pod is assigned its own IP address.",
      "tokens": [
        50428,
        2048,
        2497,
        307,
        13279,
        1080,
        1065,
        8671,
        2985,
        13,
        50558
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1635102821118904,
      "compression_ratio": 1.7787878787878788,
      "no_speech_prob": 0.01685609668493271
    },
    {
      "id": 342,
      "seek": 76520,
      "start": 769.08,
      "end": 770.08,
      "text": " Notice it's not public.",
      "tokens": [
        50558,
        13428,
        309,
        311,
        406,
        1908,
        13,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1635102821118904,
      "compression_ratio": 1.7787878787878788,
      "no_speech_prob": 0.01685609668493271
    },
    {
      "id": 343,
      "seek": 76520,
      "start": 770.08,
      "end": 771.2800000000001,
      "text": " It's a private IP address.",
      "tokens": [
        50608,
        467,
        311,
        257,
        4551,
        8671,
        2985,
        13,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1635102821118904,
      "compression_ratio": 1.7787878787878788,
      "no_speech_prob": 0.01685609668493271
    },
    {
      "id": 344,
      "seek": 76520,
      "start": 771.2800000000001,
      "end": 775.76,
      "text": " In fact, it's so private, it's only accessible from Kubernetes notes.",
      "tokens": [
        50668,
        682,
        1186,
        11,
        309,
        311,
        370,
        4551,
        11,
        309,
        311,
        787,
        9515,
        490,
        23145,
        5570,
        13,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1635102821118904,
      "compression_ratio": 1.7787878787878788,
      "no_speech_prob": 0.01685609668493271
    },
    {
      "id": 345,
      "seek": 76520,
      "start": 775.76,
      "end": 777.1600000000001,
      "text": " We'll talk more about that here in a second.",
      "tokens": [
        50892,
        492,
        603,
        751,
        544,
        466,
        300,
        510,
        294,
        257,
        1150,
        13,
        50962
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1635102821118904,
      "compression_ratio": 1.7787878787878788,
      "no_speech_prob": 0.01685609668493271
    },
    {
      "id": 346,
      "seek": 76520,
      "start": 777.1600000000001,
      "end": 779.8000000000001,
      "text": " And all this stuff above this line was more pod information below here.",
      "tokens": [
        50962,
        400,
        439,
        341,
        1507,
        3673,
        341,
        1622,
        390,
        544,
        2497,
        1589,
        2507,
        510,
        13,
        51094
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1635102821118904,
      "compression_ratio": 1.7787878787878788,
      "no_speech_prob": 0.01685609668493271
    },
    {
      "id": 347,
      "seek": 76520,
      "start": 779.8000000000001,
      "end": 781.44,
      "text": " We now have our container information.",
      "tokens": [
        51094,
        492,
        586,
        362,
        527,
        10129,
        1589,
        13,
        51176
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1635102821118904,
      "compression_ratio": 1.7787878787878788,
      "no_speech_prob": 0.01685609668493271
    },
    {
      "id": 348,
      "seek": 76520,
      "start": 781.44,
      "end": 782.88,
      "text": " So the container is network.coffee.",
      "tokens": [
        51176,
        407,
        264,
        10129,
        307,
        3209,
        13,
        1291,
        4617,
        13,
        51248
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1635102821118904,
      "compression_ratio": 1.7787878787878788,
      "no_speech_prob": 0.01685609668493271
    },
    {
      "id": 349,
      "seek": 76520,
      "start": 782.88,
      "end": 787.2800000000001,
      "text": " There's the ID, the image that we pulled down, the ports that are open, and a bunch of other",
      "tokens": [
        51248,
        821,
        311,
        264,
        7348,
        11,
        264,
        3256,
        300,
        321,
        7373,
        760,
        11,
        264,
        18160,
        300,
        366,
        1269,
        11,
        293,
        257,
        3840,
        295,
        661,
        51468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1635102821118904,
      "compression_ratio": 1.7787878787878788,
      "no_speech_prob": 0.01685609668493271
    },
    {
      "id": 350,
      "seek": 76520,
      "start": 787.2800000000001,
      "end": 789.1600000000001,
      "text": " stuff, logs and such.",
      "tokens": [
        51468,
        1507,
        11,
        20820,
        293,
        1270,
        13,
        51562
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1635102821118904,
      "compression_ratio": 1.7787878787878788,
      "no_speech_prob": 0.01685609668493271
    },
    {
      "id": 351,
      "seek": 76520,
      "start": 789.1600000000001,
      "end": 790.1600000000001,
      "text": " It's great.",
      "tokens": [
        51562,
        467,
        311,
        869,
        13,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1635102821118904,
      "compression_ratio": 1.7787878787878788,
      "no_speech_prob": 0.01685609668493271
    },
    {
      "id": 352,
      "seek": 76520,
      "start": 790.1600000000001,
      "end": 793.6800000000001,
      "text": " Now for our coffee company, we don't want to only deploy one container or one pod.",
      "tokens": [
        51612,
        823,
        337,
        527,
        4982,
        2237,
        11,
        321,
        500,
        380,
        528,
        281,
        787,
        7274,
        472,
        10129,
        420,
        472,
        2497,
        13,
        51788
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1635102821118904,
      "compression_ratio": 1.7787878787878788,
      "no_speech_prob": 0.01685609668493271
    },
    {
      "id": 353,
      "seek": 79368,
      "start": 793.68,
      "end": 795.16,
      "text": " We want to deploy a bunch.",
      "tokens": [
        50364,
        492,
        528,
        281,
        7274,
        257,
        3840,
        13,
        50438
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18478660342059558,
      "compression_ratio": 1.6687306501547987,
      "no_speech_prob": 0.03022964671254158
    },
    {
      "id": 354,
      "seek": 79368,
      "start": 795.16,
      "end": 797.04,
      "text": " How do we do that with Kubernetes?",
      "tokens": [
        50438,
        1012,
        360,
        321,
        360,
        300,
        365,
        23145,
        30,
        50532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18478660342059558,
      "compression_ratio": 1.6687306501547987,
      "no_speech_prob": 0.03022964671254158
    },
    {
      "id": 355,
      "seek": 79368,
      "start": 797.04,
      "end": 798.28,
      "text": " That's what he's supposed to do, right?",
      "tokens": [
        50532,
        663,
        311,
        437,
        415,
        311,
        3442,
        281,
        360,
        11,
        558,
        30,
        50594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18478660342059558,
      "compression_ratio": 1.6687306501547987,
      "no_speech_prob": 0.03022964671254158
    },
    {
      "id": 356,
      "seek": 79368,
      "start": 798.28,
      "end": 799.28,
      "text": " Let me show you.",
      "tokens": [
        50594,
        961,
        385,
        855,
        291,
        13,
        50644
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18478660342059558,
      "compression_ratio": 1.6687306501547987,
      "no_speech_prob": 0.03022964671254158
    },
    {
      "id": 357,
      "seek": 79368,
      "start": 799.28,
      "end": 801.4399999999999,
      "text": " So what we just use the cubectl run command.",
      "tokens": [
        50644,
        407,
        437,
        321,
        445,
        764,
        264,
        13728,
        349,
        75,
        1190,
        5622,
        13,
        50752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18478660342059558,
      "compression_ratio": 1.6687306501547987,
      "no_speech_prob": 0.03022964671254158
    },
    {
      "id": 358,
      "seek": 79368,
      "start": 801.4399999999999,
      "end": 804.4399999999999,
      "text": " That's more for like ad hoc, like let me just create a pod real quick.",
      "tokens": [
        50752,
        663,
        311,
        544,
        337,
        411,
        614,
        16708,
        11,
        411,
        718,
        385,
        445,
        1884,
        257,
        2497,
        957,
        1702,
        13,
        50902
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18478660342059558,
      "compression_ratio": 1.6687306501547987,
      "no_speech_prob": 0.03022964671254158
    },
    {
      "id": 359,
      "seek": 79368,
      "start": 804.4399999999999,
      "end": 809.8,
      "text": " We're now going to try something more, more powerful, more organized, more intentional.",
      "tokens": [
        50902,
        492,
        434,
        586,
        516,
        281,
        853,
        746,
        544,
        11,
        544,
        4005,
        11,
        544,
        9983,
        11,
        544,
        21935,
        13,
        51170
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18478660342059558,
      "compression_ratio": 1.6687306501547987,
      "no_speech_prob": 0.03022964671254158
    },
    {
      "id": 360,
      "seek": 79368,
      "start": 809.8,
      "end": 811.0999999999999,
      "text": " It's called a deployment.",
      "tokens": [
        51170,
        467,
        311,
        1219,
        257,
        19317,
        13,
        51235
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18478660342059558,
      "compression_ratio": 1.6687306501547987,
      "no_speech_prob": 0.03022964671254158
    },
    {
      "id": 361,
      "seek": 79368,
      "start": 811.0999999999999,
      "end": 816.2399999999999,
      "text": " With our deployment, we're going to say, Hey, master, I don't only want just one pod.",
      "tokens": [
        51235,
        2022,
        527,
        19317,
        11,
        321,
        434,
        516,
        281,
        584,
        11,
        1911,
        11,
        4505,
        11,
        286,
        500,
        380,
        787,
        528,
        445,
        472,
        2497,
        13,
        51492
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18478660342059558,
      "compression_ratio": 1.6687306501547987,
      "no_speech_prob": 0.03022964671254158
    },
    {
      "id": 362,
      "seek": 79368,
      "start": 816.2399999999999,
      "end": 817.68,
      "text": " I want three, three of what?",
      "tokens": [
        51492,
        286,
        528,
        1045,
        11,
        1045,
        295,
        437,
        30,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18478660342059558,
      "compression_ratio": 1.6687306501547987,
      "no_speech_prob": 0.03022964671254158
    },
    {
      "id": 363,
      "seek": 79368,
      "start": 817.68,
      "end": 820.88,
      "text": " Well, I want three network, Chuck coffee websites, and I want port 80 open.",
      "tokens": [
        51564,
        1042,
        11,
        286,
        528,
        1045,
        3209,
        11,
        21607,
        4982,
        12891,
        11,
        293,
        286,
        528,
        2436,
        4688,
        1269,
        13,
        51724
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18478660342059558,
      "compression_ratio": 1.6687306501547987,
      "no_speech_prob": 0.03022964671254158
    },
    {
      "id": 364,
      "seek": 82088,
      "start": 820.88,
      "end": 824.68,
      "text": " Now the deployment, instead of just telling him in one command, I want this to happen.",
      "tokens": [
        50364,
        823,
        264,
        19317,
        11,
        2602,
        295,
        445,
        3585,
        796,
        294,
        472,
        5622,
        11,
        286,
        528,
        341,
        281,
        1051,
        13,
        50554
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13787333950674607,
      "compression_ratio": 1.7621776504297995,
      "no_speech_prob": 0.003482565749436617
    },
    {
      "id": 365,
      "seek": 82088,
      "start": 824.68,
      "end": 828.28,
      "text": " We'll actually describe what we want to happen in a file and we'll tell him to look at that",
      "tokens": [
        50554,
        492,
        603,
        767,
        6786,
        437,
        321,
        528,
        281,
        1051,
        294,
        257,
        3991,
        293,
        321,
        603,
        980,
        796,
        281,
        574,
        412,
        300,
        50734
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13787333950674607,
      "compression_ratio": 1.7621776504297995,
      "no_speech_prob": 0.003482565749436617
    },
    {
      "id": 366,
      "seek": 82088,
      "start": 828.28,
      "end": 829.28,
      "text": " file.",
      "tokens": [
        50734,
        3991,
        13,
        50784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13787333950674607,
      "compression_ratio": 1.7621776504297995,
      "no_speech_prob": 0.003482565749436617
    },
    {
      "id": 367,
      "seek": 82088,
      "start": 829.28,
      "end": 830.28,
      "text": " And I've already got the file built out.",
      "tokens": [
        50784,
        400,
        286,
        600,
        1217,
        658,
        264,
        3991,
        3094,
        484,
        13,
        50834
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13787333950674607,
      "compression_ratio": 1.7621776504297995,
      "no_speech_prob": 0.003482565749436617
    },
    {
      "id": 368,
      "seek": 82088,
      "start": 830.28,
      "end": 831.28,
      "text": " Let's go look at it real quick.",
      "tokens": [
        50834,
        961,
        311,
        352,
        574,
        412,
        309,
        957,
        1702,
        13,
        50884
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13787333950674607,
      "compression_ratio": 1.7621776504297995,
      "no_speech_prob": 0.003482565749436617
    },
    {
      "id": 369,
      "seek": 82088,
      "start": 831.28,
      "end": 832.4399999999999,
      "text": " This is our deployment file.",
      "tokens": [
        50884,
        639,
        307,
        527,
        19317,
        3991,
        13,
        50942
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13787333950674607,
      "compression_ratio": 1.7621776504297995,
      "no_speech_prob": 0.003482565749436617
    },
    {
      "id": 370,
      "seek": 82088,
      "start": 832.4399999999999,
      "end": 835.88,
      "text": " It's a YAML file, just like our cube config earlier.",
      "tokens": [
        50942,
        467,
        311,
        257,
        398,
        2865,
        43,
        3991,
        11,
        445,
        411,
        527,
        13728,
        6662,
        3071,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13787333950674607,
      "compression_ratio": 1.7621776504297995,
      "no_speech_prob": 0.003482565749436617
    },
    {
      "id": 371,
      "seek": 82088,
      "start": 835.88,
      "end": 840.8,
      "text": " These files that describe how Kubernetes can create our pods and design our infrastructure,",
      "tokens": [
        51114,
        1981,
        7098,
        300,
        6786,
        577,
        23145,
        393,
        1884,
        527,
        31925,
        293,
        1715,
        527,
        6896,
        11,
        51360
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13787333950674607,
      "compression_ratio": 1.7621776504297995,
      "no_speech_prob": 0.003482565749436617
    },
    {
      "id": 372,
      "seek": 82088,
      "start": 840.8,
      "end": 842.68,
      "text": " we often call these manifest.",
      "tokens": [
        51360,
        321,
        2049,
        818,
        613,
        10067,
        13,
        51454
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13787333950674607,
      "compression_ratio": 1.7621776504297995,
      "no_speech_prob": 0.003482565749436617
    },
    {
      "id": 373,
      "seek": 82088,
      "start": 842.68,
      "end": 845.0,
      "text": " Notice that Kubernetes is all very ship themed.",
      "tokens": [
        51454,
        13428,
        300,
        23145,
        307,
        439,
        588,
        5374,
        33920,
        13,
        51570
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13787333950674607,
      "compression_ratio": 1.7621776504297995,
      "no_speech_prob": 0.003482565749436617
    },
    {
      "id": 374,
      "seek": 82088,
      "start": 845.0,
      "end": 849.72,
      "text": " The word Kubernetes is actually the Greek word for a helmsman or a captain, a person",
      "tokens": [
        51570,
        440,
        1349,
        23145,
        307,
        767,
        264,
        10281,
        1349,
        337,
        257,
        801,
        2592,
        1601,
        420,
        257,
        14871,
        11,
        257,
        954,
        51806
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13787333950674607,
      "compression_ratio": 1.7621776504297995,
      "no_speech_prob": 0.003482565749436617
    },
    {
      "id": 375,
      "seek": 82088,
      "start": 849.72,
      "end": 850.72,
      "text": " who steers the ship.",
      "tokens": [
        51806,
        567,
        2126,
        433,
        264,
        5374,
        13,
        51856
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13787333950674607,
      "compression_ratio": 1.7621776504297995,
      "no_speech_prob": 0.003482565749436617
    },
    {
      "id": 376,
      "seek": 85072,
      "start": 850.72,
      "end": 853.08,
      "text": " And of course, ship manifest, things like that.",
      "tokens": [
        50364,
        400,
        295,
        1164,
        11,
        5374,
        10067,
        11,
        721,
        411,
        300,
        13,
        50482
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030129837116022,
      "compression_ratio": 1.9235127478753542,
      "no_speech_prob": 0.00746179511770606
    },
    {
      "id": 377,
      "seek": 85072,
      "start": 853.08,
      "end": 854.6,
      "text": " It's all very nautical.",
      "tokens": [
        50482,
        467,
        311,
        439,
        588,
        297,
        1375,
        804,
        13,
        50558
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030129837116022,
      "compression_ratio": 1.9235127478753542,
      "no_speech_prob": 0.00746179511770606
    },
    {
      "id": 378,
      "seek": 85072,
      "start": 854.6,
      "end": 858.6,
      "text": " And this particular manifest, the kind is obviously going to be a deployment.",
      "tokens": [
        50558,
        400,
        341,
        1729,
        10067,
        11,
        264,
        733,
        307,
        2745,
        516,
        281,
        312,
        257,
        19317,
        13,
        50758
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030129837116022,
      "compression_ratio": 1.9235127478753542,
      "no_speech_prob": 0.00746179511770606
    },
    {
      "id": 379,
      "seek": 85072,
      "start": 858.6,
      "end": 860.64,
      "text": " So here in this file, just a few things I'll show you real quick.",
      "tokens": [
        50758,
        407,
        510,
        294,
        341,
        3991,
        11,
        445,
        257,
        1326,
        721,
        286,
        603,
        855,
        291,
        957,
        1702,
        13,
        50860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030129837116022,
      "compression_ratio": 1.9235127478753542,
      "no_speech_prob": 0.00746179511770606
    },
    {
      "id": 380,
      "seek": 85072,
      "start": 860.64,
      "end": 861.64,
      "text": " We named it.",
      "tokens": [
        50860,
        492,
        4926,
        309,
        13,
        50910
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030129837116022,
      "compression_ratio": 1.9235127478753542,
      "no_speech_prob": 0.00746179511770606
    },
    {
      "id": 381,
      "seek": 85072,
      "start": 861.64,
      "end": 863.08,
      "text": " This is going to be a deployment.",
      "tokens": [
        50910,
        639,
        307,
        516,
        281,
        312,
        257,
        19317,
        13,
        50982
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030129837116022,
      "compression_ratio": 1.9235127478753542,
      "no_speech_prob": 0.00746179511770606
    },
    {
      "id": 382,
      "seek": 85072,
      "start": 863.08,
      "end": 866.2,
      "text": " The app will be named NC coffee replicas.",
      "tokens": [
        50982,
        440,
        724,
        486,
        312,
        4926,
        20786,
        4982,
        3248,
        9150,
        13,
        51138
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030129837116022,
      "compression_ratio": 1.9235127478753542,
      "no_speech_prob": 0.00746179511770606
    },
    {
      "id": 383,
      "seek": 85072,
      "start": 866.2,
      "end": 868.0400000000001,
      "text": " How many of these suckers do we want out there?",
      "tokens": [
        51138,
        1012,
        867,
        295,
        613,
        9967,
        433,
        360,
        321,
        528,
        484,
        456,
        30,
        51230
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030129837116022,
      "compression_ratio": 1.9235127478753542,
      "no_speech_prob": 0.00746179511770606
    },
    {
      "id": 384,
      "seek": 85072,
      "start": 868.0400000000001,
      "end": 870.0,
      "text": " We specified right here, we want three.",
      "tokens": [
        51230,
        492,
        22206,
        558,
        510,
        11,
        321,
        528,
        1045,
        13,
        51328
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030129837116022,
      "compression_ratio": 1.9235127478753542,
      "no_speech_prob": 0.00746179511770606
    },
    {
      "id": 385,
      "seek": 85072,
      "start": 870.0,
      "end": 872.48,
      "text": " And then down here, we're specifying what container we want to use.",
      "tokens": [
        51328,
        400,
        550,
        760,
        510,
        11,
        321,
        434,
        1608,
        5489,
        437,
        10129,
        321,
        528,
        281,
        764,
        13,
        51452
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030129837116022,
      "compression_ratio": 1.9235127478753542,
      "no_speech_prob": 0.00746179511770606
    },
    {
      "id": 386,
      "seek": 85072,
      "start": 872.48,
      "end": 873.96,
      "text": " We're naming our container NC coffee.",
      "tokens": [
        51452,
        492,
        434,
        25290,
        527,
        10129,
        20786,
        4982,
        13,
        51526
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030129837116022,
      "compression_ratio": 1.9235127478753542,
      "no_speech_prob": 0.00746179511770606
    },
    {
      "id": 387,
      "seek": 85072,
      "start": 873.96,
      "end": 876.2,
      "text": " And then there's our container that we're pulling from the Docker hub.",
      "tokens": [
        51526,
        400,
        550,
        456,
        311,
        527,
        10129,
        300,
        321,
        434,
        8407,
        490,
        264,
        33772,
        11838,
        13,
        51638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030129837116022,
      "compression_ratio": 1.9235127478753542,
      "no_speech_prob": 0.00746179511770606
    },
    {
      "id": 388,
      "seek": 85072,
      "start": 876.2,
      "end": 879.6800000000001,
      "text": " And then of course, we want to use port 80 because that's the website port.",
      "tokens": [
        51638,
        400,
        550,
        295,
        1164,
        11,
        321,
        528,
        281,
        764,
        2436,
        4688,
        570,
        300,
        311,
        264,
        3144,
        2436,
        13,
        51812
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030129837116022,
      "compression_ratio": 1.9235127478753542,
      "no_speech_prob": 0.00746179511770606
    },
    {
      "id": 389,
      "seek": 85072,
      "start": 879.6800000000001,
      "end": 880.6800000000001,
      "text": " So here's what we're going to do.",
      "tokens": [
        51812,
        407,
        510,
        311,
        437,
        321,
        434,
        516,
        281,
        360,
        13,
        51862
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16030129837116022,
      "compression_ratio": 1.9235127478753542,
      "no_speech_prob": 0.00746179511770606
    },
    {
      "id": 390,
      "seek": 88068,
      "start": 880.68,
      "end": 882.68,
      "text": " We're going to copy all this mess.",
      "tokens": [
        50364,
        492,
        434,
        516,
        281,
        5055,
        439,
        341,
        2082,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2465558768877017,
      "compression_ratio": 1.6444444444444444,
      "no_speech_prob": 0.010500894859433174
    },
    {
      "id": 391,
      "seek": 88068,
      "start": 882.68,
      "end": 884.4799999999999,
      "text": " I'll have that a link to the file below.",
      "tokens": [
        50464,
        286,
        603,
        362,
        300,
        257,
        2113,
        281,
        264,
        3991,
        2507,
        13,
        50554
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2465558768877017,
      "compression_ratio": 1.6444444444444444,
      "no_speech_prob": 0.010500894859433174
    },
    {
      "id": 392,
      "seek": 88068,
      "start": 884.4799999999999,
      "end": 886.68,
      "text": " We're going to hop back into our terminal here in Linux.",
      "tokens": [
        50554,
        492,
        434,
        516,
        281,
        3818,
        646,
        666,
        527,
        14709,
        510,
        294,
        18734,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2465558768877017,
      "compression_ratio": 1.6444444444444444,
      "no_speech_prob": 0.010500894859433174
    },
    {
      "id": 393,
      "seek": 88068,
      "start": 886.68,
      "end": 891.2399999999999,
      "text": " I'll create the file, do nano NC coffee deployment.",
      "tokens": [
        50664,
        286,
        603,
        1884,
        264,
        3991,
        11,
        360,
        30129,
        20786,
        4982,
        19317,
        13,
        50892
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2465558768877017,
      "compression_ratio": 1.6444444444444444,
      "no_speech_prob": 0.010500894859433174
    },
    {
      "id": 394,
      "seek": 88068,
      "start": 891.2399999999999,
      "end": 893.0,
      "text": " You can use whatever you want to name it.",
      "tokens": [
        50892,
        509,
        393,
        764,
        2035,
        291,
        528,
        281,
        1315,
        309,
        13,
        50980
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2465558768877017,
      "compression_ratio": 1.6444444444444444,
      "no_speech_prob": 0.010500894859433174
    },
    {
      "id": 395,
      "seek": 88068,
      "start": 893.0,
      "end": 894.0,
      "text": " Dot YAML.",
      "tokens": [
        50980,
        38753,
        398,
        2865,
        43,
        13,
        51030
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2465558768877017,
      "compression_ratio": 1.6444444444444444,
      "no_speech_prob": 0.010500894859433174
    },
    {
      "id": 396,
      "seek": 88068,
      "start": 894.0,
      "end": 898.92,
      "text": " And then I'll paste that stuff in there and then control X Y enter to save and it's ready.",
      "tokens": [
        51030,
        400,
        550,
        286,
        603,
        9163,
        300,
        1507,
        294,
        456,
        293,
        550,
        1969,
        1783,
        398,
        3242,
        281,
        3155,
        293,
        309,
        311,
        1919,
        13,
        51276
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2465558768877017,
      "compression_ratio": 1.6444444444444444,
      "no_speech_prob": 0.010500894859433174
    },
    {
      "id": 397,
      "seek": 88068,
      "start": 898.92,
      "end": 899.92,
      "text": " And the command is very simple.",
      "tokens": [
        51276,
        400,
        264,
        5622,
        307,
        588,
        2199,
        13,
        51326
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2465558768877017,
      "compression_ratio": 1.6444444444444444,
      "no_speech_prob": 0.010500894859433174
    },
    {
      "id": 398,
      "seek": 88068,
      "start": 899.92,
      "end": 902.12,
      "text": " Now before we do this, I want to delete our pod that we had earlier.",
      "tokens": [
        51326,
        823,
        949,
        321,
        360,
        341,
        11,
        286,
        528,
        281,
        12097,
        527,
        2497,
        300,
        321,
        632,
        3071,
        13,
        51436
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2465558768877017,
      "compression_ratio": 1.6444444444444444,
      "no_speech_prob": 0.010500894859433174
    },
    {
      "id": 399,
      "seek": 88068,
      "start": 902.12,
      "end": 907.0799999999999,
      "text": " Because if I do cube CTL get pods, he's still sitting there.",
      "tokens": [
        51436,
        1436,
        498,
        286,
        360,
        13728,
        19529,
        43,
        483,
        31925,
        11,
        415,
        311,
        920,
        3798,
        456,
        13,
        51684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2465558768877017,
      "compression_ratio": 1.6444444444444444,
      "no_speech_prob": 0.010500894859433174
    },
    {
      "id": 400,
      "seek": 88068,
      "start": 907.0799999999999,
      "end": 908.0799999999999,
      "text": " Let's delete him real quick.",
      "tokens": [
        51684,
        961,
        311,
        12097,
        796,
        957,
        1702,
        13,
        51734
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2465558768877017,
      "compression_ratio": 1.6444444444444444,
      "no_speech_prob": 0.010500894859433174
    },
    {
      "id": 401,
      "seek": 90808,
      "start": 908.08,
      "end": 911.84,
      "text": " So cube CTL delete pods.",
      "tokens": [
        50364,
        407,
        13728,
        19529,
        43,
        12097,
        31925,
        13,
        50552
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2688609935619213,
      "compression_ratio": 1.5294117647058822,
      "no_speech_prob": 0.024137800559401512
    },
    {
      "id": 402,
      "seek": 90808,
      "start": 911.84,
      "end": 917.72,
      "text": " And I'll just specify his name, network Chuck coffee.",
      "tokens": [
        50552,
        400,
        286,
        603,
        445,
        16500,
        702,
        1315,
        11,
        3209,
        21607,
        4982,
        13,
        50846
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2688609935619213,
      "compression_ratio": 1.5294117647058822,
      "no_speech_prob": 0.024137800559401512
    },
    {
      "id": 403,
      "seek": 90808,
      "start": 917.72,
      "end": 918.72,
      "text": " And he's gone.",
      "tokens": [
        50846,
        400,
        415,
        311,
        2780,
        13,
        50896
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2688609935619213,
      "compression_ratio": 1.5294117647058822,
      "no_speech_prob": 0.024137800559401512
    },
    {
      "id": 404,
      "seek": 90808,
      "start": 918.72,
      "end": 920.2800000000001,
      "text": " How do we get pods again?",
      "tokens": [
        50896,
        1012,
        360,
        321,
        483,
        31925,
        797,
        30,
        50974
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2688609935619213,
      "compression_ratio": 1.5294117647058822,
      "no_speech_prob": 0.024137800559401512
    },
    {
      "id": 405,
      "seek": 90808,
      "start": 920.2800000000001,
      "end": 921.2800000000001,
      "text": " He sure is gone.",
      "tokens": [
        50974,
        634,
        988,
        307,
        2780,
        13,
        51024
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2688609935619213,
      "compression_ratio": 1.5294117647058822,
      "no_speech_prob": 0.024137800559401512
    },
    {
      "id": 406,
      "seek": 90808,
      "start": 921.2800000000001,
      "end": 923.76,
      "text": " So now let's deploy our deployment.",
      "tokens": [
        51024,
        407,
        586,
        718,
        311,
        7274,
        527,
        19317,
        13,
        51148
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2688609935619213,
      "compression_ratio": 1.5294117647058822,
      "no_speech_prob": 0.024137800559401512
    },
    {
      "id": 407,
      "seek": 90808,
      "start": 923.76,
      "end": 930.38,
      "text": " The command will be cube CTL apply dash F and then we'll specify that file name and",
      "tokens": [
        51148,
        440,
        5622,
        486,
        312,
        13728,
        19529,
        43,
        3079,
        8240,
        479,
        293,
        550,
        321,
        603,
        16500,
        300,
        3991,
        1315,
        293,
        51479
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2688609935619213,
      "compression_ratio": 1.5294117647058822,
      "no_speech_prob": 0.024137800559401512
    },
    {
      "id": 408,
      "seek": 90808,
      "start": 930.38,
      "end": 935.4000000000001,
      "text": " see coffee deployment dot YAML.",
      "tokens": [
        51479,
        536,
        4982,
        19317,
        5893,
        398,
        2865,
        43,
        13,
        51730
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2688609935619213,
      "compression_ratio": 1.5294117647058822,
      "no_speech_prob": 0.024137800559401512
    },
    {
      "id": 409,
      "seek": 90808,
      "start": 935.4000000000001,
      "end": 936.4000000000001,
      "text": " And that's it.",
      "tokens": [
        51730,
        400,
        300,
        311,
        309,
        13,
        51780
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2688609935619213,
      "compression_ratio": 1.5294117647058822,
      "no_speech_prob": 0.024137800559401512
    },
    {
      "id": 410,
      "seek": 90808,
      "start": 936.4000000000001,
      "end": 937.6,
      "text": " I mean, it's pretty simple, right?",
      "tokens": [
        51780,
        286,
        914,
        11,
        309,
        311,
        1238,
        2199,
        11,
        558,
        30,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2688609935619213,
      "compression_ratio": 1.5294117647058822,
      "no_speech_prob": 0.024137800559401512
    },
    {
      "id": 411,
      "seek": 93760,
      "start": 937.64,
      "end": 941.52,
      "text": " All the work, all the know how is in that file and I'll hit enter.",
      "tokens": [
        50366,
        1057,
        264,
        589,
        11,
        439,
        264,
        458,
        577,
        307,
        294,
        300,
        3991,
        293,
        286,
        603,
        2045,
        3242,
        13,
        50560
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2561744658414983,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.009109953418374062
    },
    {
      "id": 412,
      "seek": 93760,
      "start": 941.52,
      "end": 942.52,
      "text": " Done.",
      "tokens": [
        50560,
        18658,
        13,
        50610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2561744658414983,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.009109953418374062
    },
    {
      "id": 413,
      "seek": 93760,
      "start": 942.52,
      "end": 947.12,
      "text": " So if I do real quick, I want to go fast, cube CTL get pods.",
      "tokens": [
        50610,
        407,
        498,
        286,
        360,
        957,
        1702,
        11,
        286,
        528,
        281,
        352,
        2370,
        11,
        13728,
        19529,
        43,
        483,
        31925,
        13,
        50840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2561744658414983,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.009109953418374062
    },
    {
      "id": 414,
      "seek": 93760,
      "start": 947.12,
      "end": 950.08,
      "text": " Look, they're creating.",
      "tokens": [
        50840,
        2053,
        11,
        436,
        434,
        4084,
        13,
        50988
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2561744658414983,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.009109953418374062
    },
    {
      "id": 415,
      "seek": 93760,
      "start": 950.08,
      "end": 951.5600000000001,
      "text": " So they're already done.",
      "tokens": [
        50988,
        407,
        436,
        434,
        1217,
        1096,
        13,
        51062
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2561744658414983,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.009109953418374062
    },
    {
      "id": 416,
      "seek": 93760,
      "start": 951.5600000000001,
      "end": 952.5600000000001,
      "text": " They're already done.",
      "tokens": [
        51062,
        814,
        434,
        1217,
        1096,
        13,
        51112
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2561744658414983,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.009109953418374062
    },
    {
      "id": 417,
      "seek": 93760,
      "start": 952.5600000000001,
      "end": 953.5600000000001,
      "text": " Okay, cool.",
      "tokens": [
        51112,
        1033,
        11,
        1627,
        13,
        51162
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2561744658414983,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.009109953418374062
    },
    {
      "id": 418,
      "seek": 93760,
      "start": 953.5600000000001,
      "end": 955.5600000000001,
      "text": " And just like that, three containers, three pods created.",
      "tokens": [
        51162,
        400,
        445,
        411,
        300,
        11,
        1045,
        17089,
        11,
        1045,
        31925,
        2942,
        13,
        51262
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2561744658414983,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.009109953418374062
    },
    {
      "id": 419,
      "seek": 93760,
      "start": 955.5600000000001,
      "end": 957.4,
      "text": " And here's the cool part about Kubernetes.",
      "tokens": [
        51262,
        400,
        510,
        311,
        264,
        1627,
        644,
        466,
        23145,
        13,
        51354
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2561744658414983,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.009109953418374062
    },
    {
      "id": 420,
      "seek": 93760,
      "start": 957.4,
      "end": 962.52,
      "text": " It's the concept of desired state that manifest file that deployment is saying, Hey, Kubernetes",
      "tokens": [
        51354,
        467,
        311,
        264,
        3410,
        295,
        14721,
        1785,
        300,
        10067,
        3991,
        300,
        19317,
        307,
        1566,
        11,
        1911,
        11,
        23145,
        51610
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2561744658414983,
      "compression_ratio": 1.6454183266932272,
      "no_speech_prob": 0.009109953418374062
    },
    {
      "id": 421,
      "seek": 96252,
      "start": 962.52,
      "end": 969.3199999999999,
      "text": " master, I want there to always be three pods with this image running always not to not",
      "tokens": [
        50364,
        4505,
        11,
        286,
        528,
        456,
        281,
        1009,
        312,
        1045,
        31925,
        365,
        341,
        3256,
        2614,
        1009,
        406,
        281,
        406,
        50704
      ],
      "temperature": 0.0,
      "avg_logprob": -0.229514075488579,
      "compression_ratio": 1.7448979591836735,
      "no_speech_prob": 0.11305903643369675
    },
    {
      "id": 422,
      "seek": 96252,
      "start": 969.3199999999999,
      "end": 972.52,
      "text": " for not 12, I want three.",
      "tokens": [
        50704,
        337,
        406,
        2272,
        11,
        286,
        528,
        1045,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.229514075488579,
      "compression_ratio": 1.7448979591836735,
      "no_speech_prob": 0.11305903643369675
    },
    {
      "id": 423,
      "seek": 96252,
      "start": 972.52,
      "end": 974.4399999999999,
      "text": " And he will constantly make sure that's the case.",
      "tokens": [
        50864,
        400,
        415,
        486,
        6460,
        652,
        988,
        300,
        311,
        264,
        1389,
        13,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.229514075488579,
      "compression_ratio": 1.7448979591836735,
      "no_speech_prob": 0.11305903643369675
    },
    {
      "id": 424,
      "seek": 96252,
      "start": 974.4399999999999,
      "end": 976.6,
      "text": " Be going, okay, so that manifests out.",
      "tokens": [
        50960,
        879,
        516,
        11,
        1392,
        11,
        370,
        300,
        50252,
        484,
        13,
        51068
      ],
      "temperature": 0.0,
      "avg_logprob": -0.229514075488579,
      "compression_ratio": 1.7448979591836735,
      "no_speech_prob": 0.11305903643369675
    },
    {
      "id": 425,
      "seek": 96252,
      "start": 976.6,
      "end": 977.6,
      "text": " Okay.",
      "tokens": [
        51068,
        1033,
        13,
        51118
      ],
      "temperature": 0.0,
      "avg_logprob": -0.229514075488579,
      "compression_ratio": 1.7448979591836735,
      "no_speech_prob": 0.11305903643369675
    },
    {
      "id": 426,
      "seek": 96252,
      "start": 977.6,
      "end": 978.6,
      "text": " Yeah.",
      "tokens": [
        51118,
        865,
        13,
        51168
      ],
      "temperature": 0.0,
      "avg_logprob": -0.229514075488579,
      "compression_ratio": 1.7448979591836735,
      "no_speech_prob": 0.11305903643369675
    },
    {
      "id": 427,
      "seek": 96252,
      "start": 978.6,
      "end": 979.6,
      "text": " Okay.",
      "tokens": [
        51168,
        1033,
        13,
        51218
      ],
      "temperature": 0.0,
      "avg_logprob": -0.229514075488579,
      "compression_ratio": 1.7448979591836735,
      "no_speech_prob": 0.11305903643369675
    },
    {
      "id": 428,
      "seek": 96252,
      "start": 979.6,
      "end": 980.6,
      "text": " We're good.",
      "tokens": [
        51218,
        492,
        434,
        665,
        13,
        51268
      ],
      "temperature": 0.0,
      "avg_logprob": -0.229514075488579,
      "compression_ratio": 1.7448979591836735,
      "no_speech_prob": 0.11305903643369675
    },
    {
      "id": 429,
      "seek": 96252,
      "start": 980.6,
      "end": 981.6,
      "text": " And he's always making sure it's that state or desired state.",
      "tokens": [
        51268,
        400,
        415,
        311,
        1009,
        1455,
        988,
        309,
        311,
        300,
        1785,
        420,
        14721,
        1785,
        13,
        51318
      ],
      "temperature": 0.0,
      "avg_logprob": -0.229514075488579,
      "compression_ratio": 1.7448979591836735,
      "no_speech_prob": 0.11305903643369675
    },
    {
      "id": 430,
      "seek": 96252,
      "start": 981.6,
      "end": 984.16,
      "text": " Now, if you were to change that manifest file, we can like, let's say, you know, three",
      "tokens": [
        51318,
        823,
        11,
        498,
        291,
        645,
        281,
        1319,
        300,
        10067,
        3991,
        11,
        321,
        393,
        411,
        11,
        718,
        311,
        584,
        11,
        291,
        458,
        11,
        1045,
        51446
      ],
      "temperature": 0.0,
      "avg_logprob": -0.229514075488579,
      "compression_ratio": 1.7448979591836735,
      "no_speech_prob": 0.11305903643369675
    },
    {
      "id": 431,
      "seek": 96252,
      "start": 984.16,
      "end": 985.16,
      "text": " isn't cutting it for me anymore.",
      "tokens": [
        51446,
        1943,
        380,
        6492,
        309,
        337,
        385,
        3602,
        13,
        51496
      ],
      "temperature": 0.0,
      "avg_logprob": -0.229514075488579,
      "compression_ratio": 1.7448979591836735,
      "no_speech_prob": 0.11305903643369675
    },
    {
      "id": 432,
      "seek": 96252,
      "start": 985.16,
      "end": 986.96,
      "text": " I want, I want 10.",
      "tokens": [
        51496,
        286,
        528,
        11,
        286,
        528,
        1266,
        13,
        51586
      ],
      "temperature": 0.0,
      "avg_logprob": -0.229514075488579,
      "compression_ratio": 1.7448979591836735,
      "no_speech_prob": 0.11305903643369675
    },
    {
      "id": 433,
      "seek": 96252,
      "start": 986.96,
      "end": 987.96,
      "text": " Let's do 10.",
      "tokens": [
        51586,
        961,
        311,
        360,
        1266,
        13,
        51636
      ],
      "temperature": 0.0,
      "avg_logprob": -0.229514075488579,
      "compression_ratio": 1.7448979591836735,
      "no_speech_prob": 0.11305903643369675
    },
    {
      "id": 434,
      "seek": 96252,
      "start": 987.96,
      "end": 988.96,
      "text": " We can edit that file.",
      "tokens": [
        51636,
        492,
        393,
        8129,
        300,
        3991,
        13,
        51686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.229514075488579,
      "compression_ratio": 1.7448979591836735,
      "no_speech_prob": 0.11305903643369675
    },
    {
      "id": 435,
      "seek": 96252,
      "start": 988.96,
      "end": 990.1999999999999,
      "text": " So let me do control L to clear it out here.",
      "tokens": [
        51686,
        407,
        718,
        385,
        360,
        1969,
        441,
        281,
        1850,
        309,
        484,
        510,
        13,
        51748
      ],
      "temperature": 0.0,
      "avg_logprob": -0.229514075488579,
      "compression_ratio": 1.7448979591836735,
      "no_speech_prob": 0.11305903643369675
    },
    {
      "id": 436,
      "seek": 99020,
      "start": 990.32,
      "end": 995.5600000000001,
      "text": " I'll do a cube CTL edit deployment and whatever we name our deployment, which I believe was",
      "tokens": [
        50370,
        286,
        603,
        360,
        257,
        13728,
        19529,
        43,
        8129,
        19317,
        293,
        2035,
        321,
        1315,
        527,
        19317,
        11,
        597,
        286,
        1697,
        390,
        50632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740598678588867,
      "compression_ratio": 1.8700787401574803,
      "no_speech_prob": 0.0587225966155529
    },
    {
      "id": 437,
      "seek": 99020,
      "start": 995.5600000000001,
      "end": 998.44,
      "text": " NC coffee deployment.",
      "tokens": [
        50632,
        20786,
        4982,
        19317,
        13,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740598678588867,
      "compression_ratio": 1.8700787401574803,
      "no_speech_prob": 0.0587225966155529
    },
    {
      "id": 438,
      "seek": 99020,
      "start": 998.44,
      "end": 999.44,
      "text": " Is that what it was?",
      "tokens": [
        50776,
        1119,
        300,
        437,
        309,
        390,
        30,
        50826
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740598678588867,
      "compression_ratio": 1.8700787401574803,
      "no_speech_prob": 0.0587225966155529
    },
    {
      "id": 439,
      "seek": 99020,
      "start": 999.44,
      "end": 1000.44,
      "text": " No, that's not what it was.",
      "tokens": [
        50826,
        883,
        11,
        300,
        311,
        406,
        437,
        309,
        390,
        13,
        50876
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740598678588867,
      "compression_ratio": 1.8700787401574803,
      "no_speech_prob": 0.0587225966155529
    },
    {
      "id": 440,
      "seek": 99020,
      "start": 1000.44,
      "end": 1003.24,
      "text": " I'm going to do a cube CTL and get deployments.",
      "tokens": [
        50876,
        286,
        478,
        516,
        281,
        360,
        257,
        13728,
        19529,
        43,
        293,
        483,
        7274,
        1117,
        13,
        51016
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740598678588867,
      "compression_ratio": 1.8700787401574803,
      "no_speech_prob": 0.0587225966155529
    },
    {
      "id": 441,
      "seek": 99020,
      "start": 1003.24,
      "end": 1004.24,
      "text": " There it is right there.",
      "tokens": [
        51016,
        821,
        309,
        307,
        558,
        456,
        13,
        51066
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740598678588867,
      "compression_ratio": 1.8700787401574803,
      "no_speech_prob": 0.0587225966155529
    },
    {
      "id": 442,
      "seek": 99020,
      "start": 1004.24,
      "end": 1005.24,
      "text": " That's another cool command, right?",
      "tokens": [
        51066,
        663,
        311,
        1071,
        1627,
        5622,
        11,
        558,
        30,
        51116
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740598678588867,
      "compression_ratio": 1.8700787401574803,
      "no_speech_prob": 0.0587225966155529
    },
    {
      "id": 443,
      "seek": 99020,
      "start": 1005.24,
      "end": 1007.5600000000001,
      "text": " We can see our deployment right there three up to date, three available.",
      "tokens": [
        51116,
        492,
        393,
        536,
        527,
        19317,
        558,
        456,
        1045,
        493,
        281,
        4002,
        11,
        1045,
        2435,
        13,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740598678588867,
      "compression_ratio": 1.8700787401574803,
      "no_speech_prob": 0.0587225966155529
    },
    {
      "id": 444,
      "seek": 99020,
      "start": 1007.5600000000001,
      "end": 1008.5600000000001,
      "text": " Awesome.",
      "tokens": [
        51232,
        10391,
        13,
        51282
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740598678588867,
      "compression_ratio": 1.8700787401574803,
      "no_speech_prob": 0.0587225966155529
    },
    {
      "id": 445,
      "seek": 99020,
      "start": 1008.5600000000001,
      "end": 1009.5600000000001,
      "text": " So now let's actually edit it.",
      "tokens": [
        51282,
        407,
        586,
        718,
        311,
        767,
        8129,
        309,
        13,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740598678588867,
      "compression_ratio": 1.8700787401574803,
      "no_speech_prob": 0.0587225966155529
    },
    {
      "id": 446,
      "seek": 99020,
      "start": 1009.5600000000001,
      "end": 1014.6400000000001,
      "text": " Cube CTL edit network Chuck coffee dash deployment.",
      "tokens": [
        51332,
        33003,
        19529,
        43,
        8129,
        3209,
        21607,
        4982,
        8240,
        19317,
        13,
        51586
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740598678588867,
      "compression_ratio": 1.8700787401574803,
      "no_speech_prob": 0.0587225966155529
    },
    {
      "id": 447,
      "seek": 99020,
      "start": 1014.6400000000001,
      "end": 1017.24,
      "text": " Now I got to specify deployment there.",
      "tokens": [
        51586,
        823,
        286,
        658,
        281,
        16500,
        19317,
        456,
        13,
        51716
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26740598678588867,
      "compression_ratio": 1.8700787401574803,
      "no_speech_prob": 0.0587225966155529
    },
    {
      "id": 448,
      "seek": 101724,
      "start": 1017.24,
      "end": 1020.92,
      "text": " So let's scroll down to the replicas right here.",
      "tokens": [
        50364,
        407,
        718,
        311,
        11369,
        760,
        281,
        264,
        3248,
        9150,
        558,
        510,
        13,
        50548
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23157098558213976,
      "compression_ratio": 1.625984251968504,
      "no_speech_prob": 0.003679640358313918
    },
    {
      "id": 449,
      "seek": 101724,
      "start": 1020.92,
      "end": 1023.6800000000001,
      "text": " I'm going to hit I to insert and start editing.",
      "tokens": [
        50548,
        286,
        478,
        516,
        281,
        2045,
        286,
        281,
        8969,
        293,
        722,
        10000,
        13,
        50686
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23157098558213976,
      "compression_ratio": 1.625984251968504,
      "no_speech_prob": 0.003679640358313918
    },
    {
      "id": 450,
      "seek": 101724,
      "start": 1023.6800000000001,
      "end": 1026.48,
      "text": " I'll delete the three and let's put in 10.",
      "tokens": [
        50686,
        286,
        603,
        12097,
        264,
        1045,
        293,
        718,
        311,
        829,
        294,
        1266,
        13,
        50826
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23157098558213976,
      "compression_ratio": 1.625984251968504,
      "no_speech_prob": 0.003679640358313918
    },
    {
      "id": 451,
      "seek": 101724,
      "start": 1026.48,
      "end": 1027.96,
      "text": " So this is going to be VI not nano.",
      "tokens": [
        50826,
        407,
        341,
        307,
        516,
        281,
        312,
        27619,
        406,
        30129,
        13,
        50900
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23157098558213976,
      "compression_ratio": 1.625984251968504,
      "no_speech_prob": 0.003679640358313918
    },
    {
      "id": 452,
      "seek": 101724,
      "start": 1027.96,
      "end": 1033.96,
      "text": " So I'll hit escape colon WQ to write and quit and enter.",
      "tokens": [
        50900,
        407,
        286,
        603,
        2045,
        7615,
        8255,
        343,
        48,
        281,
        2464,
        293,
        10366,
        293,
        3242,
        13,
        51200
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23157098558213976,
      "compression_ratio": 1.625984251968504,
      "no_speech_prob": 0.003679640358313918
    },
    {
      "id": 453,
      "seek": 101724,
      "start": 1033.96,
      "end": 1035.1200000000001,
      "text": " It's been updated.",
      "tokens": [
        51200,
        467,
        311,
        668,
        10588,
        13,
        51258
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23157098558213976,
      "compression_ratio": 1.625984251968504,
      "no_speech_prob": 0.003679640358313918
    },
    {
      "id": 454,
      "seek": 101724,
      "start": 1035.1200000000001,
      "end": 1036.68,
      "text": " So let's let's do this real quick.",
      "tokens": [
        51258,
        407,
        718,
        311,
        718,
        311,
        360,
        341,
        957,
        1702,
        13,
        51336
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23157098558213976,
      "compression_ratio": 1.625984251968504,
      "no_speech_prob": 0.003679640358313918
    },
    {
      "id": 455,
      "seek": 101724,
      "start": 1036.68,
      "end": 1040.2,
      "text": " Cube CTL get pods.",
      "tokens": [
        51336,
        33003,
        19529,
        43,
        483,
        31925,
        13,
        51512
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23157098558213976,
      "compression_ratio": 1.625984251968504,
      "no_speech_prob": 0.003679640358313918
    },
    {
      "id": 456,
      "seek": 101724,
      "start": 1040.2,
      "end": 1041.2,
      "text": " It already started creating them.",
      "tokens": [
        51512,
        467,
        1217,
        1409,
        4084,
        552,
        13,
        51562
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23157098558213976,
      "compression_ratio": 1.625984251968504,
      "no_speech_prob": 0.003679640358313918
    },
    {
      "id": 457,
      "seek": 101724,
      "start": 1041.2,
      "end": 1042.2,
      "text": " Look at that.",
      "tokens": [
        51562,
        2053,
        412,
        300,
        13,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23157098558213976,
      "compression_ratio": 1.625984251968504,
      "no_speech_prob": 0.003679640358313918
    },
    {
      "id": 458,
      "seek": 101724,
      "start": 1042.2,
      "end": 1043.2,
      "text": " That's amazing.",
      "tokens": [
        51612,
        663,
        311,
        2243,
        13,
        51662
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23157098558213976,
      "compression_ratio": 1.625984251968504,
      "no_speech_prob": 0.003679640358313918
    },
    {
      "id": 459,
      "seek": 101724,
      "start": 1043.2,
      "end": 1044.2,
      "text": " Right.",
      "tokens": [
        51662,
        1779,
        13,
        51712
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23157098558213976,
      "compression_ratio": 1.625984251968504,
      "no_speech_prob": 0.003679640358313918
    },
    {
      "id": 460,
      "seek": 101724,
      "start": 1044.2,
      "end": 1046.52,
      "text": " And just like that, 10 pods running.",
      "tokens": [
        51712,
        400,
        445,
        411,
        300,
        11,
        1266,
        31925,
        2614,
        13,
        51828
      ],
      "temperature": 0.0,
      "avg_logprob": -0.23157098558213976,
      "compression_ratio": 1.625984251968504,
      "no_speech_prob": 0.003679640358313918
    },
    {
      "id": 461,
      "seek": 104652,
      "start": 1046.52,
      "end": 1051.12,
      "text": " This is the, the commander, the helmsman, Kubernetes, the master.",
      "tokens": [
        50364,
        639,
        307,
        264,
        11,
        264,
        17885,
        11,
        264,
        801,
        2592,
        1601,
        11,
        23145,
        11,
        264,
        4505,
        13,
        50594
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357104599096213,
      "compression_ratio": 1.685121107266436,
      "no_speech_prob": 0.05530783161520958
    },
    {
      "id": 462,
      "seek": 104652,
      "start": 1051.12,
      "end": 1052.36,
      "text": " He was like, Oh, we got an updated manifest.",
      "tokens": [
        50594,
        634,
        390,
        411,
        11,
        876,
        11,
        321,
        658,
        364,
        10588,
        10067,
        13,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357104599096213,
      "compression_ratio": 1.685121107266436,
      "no_speech_prob": 0.05530783161520958
    },
    {
      "id": 463,
      "seek": 104652,
      "start": 1052.36,
      "end": 1053.36,
      "text": " Let me check it out.",
      "tokens": [
        50656,
        961,
        385,
        1520,
        309,
        484,
        13,
        50706
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357104599096213,
      "compression_ratio": 1.685121107266436,
      "no_speech_prob": 0.05530783161520958
    },
    {
      "id": 464,
      "seek": 104652,
      "start": 1053.36,
      "end": 1054.36,
      "text": " Oh, G. O. Lakers.",
      "tokens": [
        50706,
        876,
        11,
        460,
        13,
        422,
        13,
        441,
        19552,
        13,
        50756
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357104599096213,
      "compression_ratio": 1.685121107266436,
      "no_speech_prob": 0.05530783161520958
    },
    {
      "id": 465,
      "seek": 104652,
      "start": 1054.36,
      "end": 1055.36,
      "text": " We need 10.",
      "tokens": [
        50756,
        492,
        643,
        1266,
        13,
        50806
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357104599096213,
      "compression_ratio": 1.685121107266436,
      "no_speech_prob": 0.05530783161520958
    },
    {
      "id": 466,
      "seek": 104652,
      "start": 1055.36,
      "end": 1056.36,
      "text": " He talks like that.",
      "tokens": [
        50806,
        634,
        6686,
        411,
        300,
        13,
        50856
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357104599096213,
      "compression_ratio": 1.685121107266436,
      "no_speech_prob": 0.05530783161520958
    },
    {
      "id": 467,
      "seek": 104652,
      "start": 1056.36,
      "end": 1060.76,
      "text": " We need 10 of these, these 10 going right now and he does it.",
      "tokens": [
        50856,
        492,
        643,
        1266,
        295,
        613,
        11,
        613,
        1266,
        516,
        558,
        586,
        293,
        415,
        775,
        309,
        13,
        51076
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357104599096213,
      "compression_ratio": 1.685121107266436,
      "no_speech_prob": 0.05530783161520958
    },
    {
      "id": 468,
      "seek": 104652,
      "start": 1060.76,
      "end": 1063.84,
      "text": " Now 10, we only have three servers, right?",
      "tokens": [
        51076,
        823,
        1266,
        11,
        321,
        787,
        362,
        1045,
        15909,
        11,
        558,
        30,
        51230
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357104599096213,
      "compression_ratio": 1.685121107266436,
      "no_speech_prob": 0.05530783161520958
    },
    {
      "id": 469,
      "seek": 104652,
      "start": 1063.84,
      "end": 1067.46,
      "text": " Like we looking back at our diagram here, we have three servers.",
      "tokens": [
        51230,
        1743,
        321,
        1237,
        646,
        412,
        527,
        10686,
        510,
        11,
        321,
        362,
        1045,
        15909,
        13,
        51411
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357104599096213,
      "compression_ratio": 1.685121107266436,
      "no_speech_prob": 0.05530783161520958
    },
    {
      "id": 470,
      "seek": 104652,
      "start": 1067.46,
      "end": 1069.4,
      "text": " How can we have 10 containers and pods?",
      "tokens": [
        51411,
        1012,
        393,
        321,
        362,
        1266,
        17089,
        293,
        31925,
        30,
        51508
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357104599096213,
      "compression_ratio": 1.685121107266436,
      "no_speech_prob": 0.05530783161520958
    },
    {
      "id": 471,
      "seek": 104652,
      "start": 1069.4,
      "end": 1070.8,
      "text": " Well, that's the thing.",
      "tokens": [
        51508,
        1042,
        11,
        300,
        311,
        264,
        551,
        13,
        51578
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357104599096213,
      "compression_ratio": 1.685121107266436,
      "no_speech_prob": 0.05530783161520958
    },
    {
      "id": 472,
      "seek": 104652,
      "start": 1070.8,
      "end": 1074.92,
      "text": " You can have a bunch of pods of the same type on one node.",
      "tokens": [
        51578,
        509,
        393,
        362,
        257,
        3840,
        295,
        31925,
        295,
        264,
        912,
        2010,
        322,
        472,
        9984,
        13,
        51784
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357104599096213,
      "compression_ratio": 1.685121107266436,
      "no_speech_prob": 0.05530783161520958
    },
    {
      "id": 473,
      "seek": 104652,
      "start": 1074.92,
      "end": 1075.92,
      "text": " That's fine.",
      "tokens": [
        51784,
        663,
        311,
        2489,
        13,
        51834
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2357104599096213,
      "compression_ratio": 1.685121107266436,
      "no_speech_prob": 0.05530783161520958
    },
    {
      "id": 474,
      "seek": 107592,
      "start": 1075.92,
      "end": 1077.0800000000002,
      "text": " We're going to do the scheduler's job.",
      "tokens": [
        50364,
        492,
        434,
        516,
        281,
        360,
        264,
        12000,
        260,
        311,
        1691,
        13,
        50422
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2507606760660807,
      "compression_ratio": 1.7307692307692308,
      "no_speech_prob": 0.038724642246961594
    },
    {
      "id": 475,
      "seek": 107592,
      "start": 1077.0800000000002,
      "end": 1081.04,
      "text": " The master with a scheduler component will look at all his worker nodes, figure out how",
      "tokens": [
        50422,
        440,
        4505,
        365,
        257,
        12000,
        260,
        6542,
        486,
        574,
        412,
        439,
        702,
        11346,
        13891,
        11,
        2573,
        484,
        577,
        50620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2507606760660807,
      "compression_ratio": 1.7307692307692308,
      "no_speech_prob": 0.038724642246961594
    },
    {
      "id": 476,
      "seek": 107592,
      "start": 1081.04,
      "end": 1083.8400000000001,
      "text": " busy they are and assign things, give them jobs.",
      "tokens": [
        50620,
        5856,
        436,
        366,
        293,
        6269,
        721,
        11,
        976,
        552,
        4782,
        13,
        50760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2507606760660807,
      "compression_ratio": 1.7307692307692308,
      "no_speech_prob": 0.038724642246961594
    },
    {
      "id": 477,
      "seek": 107592,
      "start": 1083.8400000000001,
      "end": 1087.4,
      "text": " Again, if Rogers over there just kind of chilling out, he goes, Hey, you know, Roger can afford",
      "tokens": [
        50760,
        3764,
        11,
        498,
        29877,
        670,
        456,
        445,
        733,
        295,
        31047,
        484,
        11,
        415,
        1709,
        11,
        1911,
        11,
        291,
        458,
        11,
        17666,
        393,
        6157,
        50938
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2507606760660807,
      "compression_ratio": 1.7307692307692308,
      "no_speech_prob": 0.038724642246961594
    },
    {
      "id": 478,
      "seek": 107592,
      "start": 1087.4,
      "end": 1088.64,
      "text": " to do a few extra things.",
      "tokens": [
        50938,
        281,
        360,
        257,
        1326,
        2857,
        721,
        13,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2507606760660807,
      "compression_ratio": 1.7307692307692308,
      "no_speech_prob": 0.038724642246961594
    },
    {
      "id": 479,
      "seek": 107592,
      "start": 1088.64,
      "end": 1089.64,
      "text": " I'm going to give him something.",
      "tokens": [
        51000,
        286,
        478,
        516,
        281,
        976,
        796,
        746,
        13,
        51050
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2507606760660807,
      "compression_ratio": 1.7307692307692308,
      "no_speech_prob": 0.038724642246961594
    },
    {
      "id": 480,
      "seek": 107592,
      "start": 1089.64,
      "end": 1096.5600000000002,
      "text": " I know the cool view of our pods is a cube CTL get pods dash O and wide.",
      "tokens": [
        51050,
        286,
        458,
        264,
        1627,
        1910,
        295,
        527,
        31925,
        307,
        257,
        13728,
        19529,
        43,
        483,
        31925,
        8240,
        422,
        293,
        4874,
        13,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2507606760660807,
      "compression_ratio": 1.7307692307692308,
      "no_speech_prob": 0.038724642246961594
    },
    {
      "id": 481,
      "seek": 107592,
      "start": 1096.5600000000002,
      "end": 1101.04,
      "text": " And we can see their name and their IP address and what server they're running on or what",
      "tokens": [
        51396,
        400,
        321,
        393,
        536,
        641,
        1315,
        293,
        641,
        8671,
        2985,
        293,
        437,
        7154,
        436,
        434,
        2614,
        322,
        420,
        437,
        51620
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2507606760660807,
      "compression_ratio": 1.7307692307692308,
      "no_speech_prob": 0.038724642246961594
    },
    {
      "id": 482,
      "seek": 107592,
      "start": 1101.04,
      "end": 1102.3200000000002,
      "text": " worker node they're serve.",
      "tokens": [
        51620,
        11346,
        9984,
        436,
        434,
        4596,
        13,
        51684
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2507606760660807,
      "compression_ratio": 1.7307692307692308,
      "no_speech_prob": 0.038724642246961594
    },
    {
      "id": 483,
      "seek": 107592,
      "start": 1102.3200000000002,
      "end": 1103.3200000000002,
      "text": " They're running on.",
      "tokens": [
        51684,
        814,
        434,
        2614,
        322,
        13,
        51734
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2507606760660807,
      "compression_ratio": 1.7307692307692308,
      "no_speech_prob": 0.038724642246961594
    },
    {
      "id": 484,
      "seek": 110332,
      "start": 1103.32,
      "end": 1106.48,
      "text": " This guy right here, he's running on blah, blah, blah.",
      "tokens": [
        50364,
        639,
        2146,
        558,
        510,
        11,
        415,
        311,
        2614,
        322,
        12288,
        11,
        12288,
        11,
        12288,
        13,
        50522
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19945152438416772,
      "compression_ratio": 1.8005540166204985,
      "no_speech_prob": 0.024419516324996948
    },
    {
      "id": 485,
      "seek": 110332,
      "start": 1106.48,
      "end": 1107.8799999999999,
      "text": " The end of it is 233.",
      "tokens": [
        50522,
        440,
        917,
        295,
        309,
        307,
        6673,
        18,
        13,
        50592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19945152438416772,
      "compression_ratio": 1.8005540166204985,
      "no_speech_prob": 0.024419516324996948
    },
    {
      "id": 486,
      "seek": 110332,
      "start": 1107.8799999999999,
      "end": 1109.1599999999999,
      "text": " This guy's running on blah, blah, blah.",
      "tokens": [
        50592,
        639,
        2146,
        311,
        2614,
        322,
        12288,
        11,
        12288,
        11,
        12288,
        13,
        50656
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19945152438416772,
      "compression_ratio": 1.8005540166204985,
      "no_speech_prob": 0.024419516324996948
    },
    {
      "id": 487,
      "seek": 110332,
      "start": 1109.1599999999999,
      "end": 1111.76,
      "text": " The end of it is 712 and they're all distributed kind of evenly, right?",
      "tokens": [
        50656,
        440,
        917,
        295,
        309,
        307,
        1614,
        4762,
        293,
        436,
        434,
        439,
        12631,
        733,
        295,
        17658,
        11,
        558,
        30,
        50786
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19945152438416772,
      "compression_ratio": 1.8005540166204985,
      "no_speech_prob": 0.024419516324996948
    },
    {
      "id": 488,
      "seek": 110332,
      "start": 1111.76,
      "end": 1115.56,
      "text": " And it's the job of the master node to keep monitoring that process to make sure that",
      "tokens": [
        50786,
        400,
        309,
        311,
        264,
        1691,
        295,
        264,
        4505,
        9984,
        281,
        1066,
        11028,
        300,
        1399,
        281,
        652,
        988,
        300,
        50976
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19945152438416772,
      "compression_ratio": 1.8005540166204985,
      "no_speech_prob": 0.024419516324996948
    },
    {
      "id": 489,
      "seek": 110332,
      "start": 1115.56,
      "end": 1117.6,
      "text": " any one worker node isn't overworked.",
      "tokens": [
        50976,
        604,
        472,
        11346,
        9984,
        1943,
        380,
        670,
        1902,
        292,
        13,
        51078
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19945152438416772,
      "compression_ratio": 1.8005540166204985,
      "no_speech_prob": 0.024419516324996948
    },
    {
      "id": 490,
      "seek": 110332,
      "start": 1117.6,
      "end": 1120.8,
      "text": " And if they are overworked, he'll take away those pods.",
      "tokens": [
        51078,
        400,
        498,
        436,
        366,
        670,
        1902,
        292,
        11,
        415,
        603,
        747,
        1314,
        729,
        31925,
        13,
        51238
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19945152438416772,
      "compression_ratio": 1.8005540166204985,
      "no_speech_prob": 0.024419516324996948
    },
    {
      "id": 491,
      "seek": 110332,
      "start": 1120.8,
      "end": 1121.8,
      "text": " I'll say, Hey, you know what?",
      "tokens": [
        51238,
        286,
        603,
        584,
        11,
        1911,
        11,
        291,
        458,
        437,
        30,
        51288
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19945152438416772,
      "compression_ratio": 1.8005540166204985,
      "no_speech_prob": 0.024419516324996948
    },
    {
      "id": 492,
      "seek": 110332,
      "start": 1121.8,
      "end": 1122.8,
      "text": " You're too busy.",
      "tokens": [
        51288,
        509,
        434,
        886,
        5856,
        13,
        51338
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19945152438416772,
      "compression_ratio": 1.8005540166204985,
      "no_speech_prob": 0.024419516324996948
    },
    {
      "id": 493,
      "seek": 110332,
      "start": 1122.8,
      "end": 1123.8,
      "text": " Let me take some of that work off you.",
      "tokens": [
        51338,
        961,
        385,
        747,
        512,
        295,
        300,
        589,
        766,
        291,
        13,
        51388
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19945152438416772,
      "compression_ratio": 1.8005540166204985,
      "no_speech_prob": 0.024419516324996948
    },
    {
      "id": 494,
      "seek": 110332,
      "start": 1123.8,
      "end": 1125.76,
      "text": " He'll remove the pod and then give it to someone else.",
      "tokens": [
        51388,
        634,
        603,
        4159,
        264,
        2497,
        293,
        550,
        976,
        309,
        281,
        1580,
        1646,
        13,
        51486
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19945152438416772,
      "compression_ratio": 1.8005540166204985,
      "no_speech_prob": 0.024419516324996948
    },
    {
      "id": 495,
      "seek": 110332,
      "start": 1125.76,
      "end": 1127.84,
      "text": " Now we still have a problem here though.",
      "tokens": [
        51486,
        823,
        321,
        920,
        362,
        257,
        1154,
        510,
        1673,
        13,
        51590
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19945152438416772,
      "compression_ratio": 1.8005540166204985,
      "no_speech_prob": 0.024419516324996948
    },
    {
      "id": 496,
      "seek": 110332,
      "start": 1127.84,
      "end": 1128.84,
      "text": " Things are awesome.",
      "tokens": [
        51590,
        9514,
        366,
        3476,
        13,
        51640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19945152438416772,
      "compression_ratio": 1.8005540166204985,
      "no_speech_prob": 0.024419516324996948
    },
    {
      "id": 497,
      "seek": 110332,
      "start": 1128.84,
      "end": 1132.8,
      "text": " Actually, we, we ran our deployment and we've got a million pods out there, 10.",
      "tokens": [
        51640,
        5135,
        11,
        321,
        11,
        321,
        5872,
        527,
        19317,
        293,
        321,
        600,
        658,
        257,
        2459,
        31925,
        484,
        456,
        11,
        1266,
        13,
        51838
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19945152438416772,
      "compression_ratio": 1.8005540166204985,
      "no_speech_prob": 0.024419516324996948
    },
    {
      "id": 498,
      "seek": 113280,
      "start": 1132.8,
      "end": 1137.52,
      "text": " But every one of these pods has an internal IP address and IP address that we can't access",
      "tokens": [
        50364,
        583,
        633,
        472,
        295,
        613,
        31925,
        575,
        364,
        6920,
        8671,
        2985,
        293,
        8671,
        2985,
        300,
        321,
        393,
        380,
        2105,
        50600
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18665276403012482,
      "compression_ratio": 1.7654986522911051,
      "no_speech_prob": 0.10494278371334076
    },
    {
      "id": 499,
      "seek": 113280,
      "start": 1137.52,
      "end": 1140.52,
      "text": " like a wet like we can't go to our web browser and and put the IP address in.",
      "tokens": [
        50600,
        411,
        257,
        6630,
        411,
        321,
        393,
        380,
        352,
        281,
        527,
        3670,
        11185,
        293,
        293,
        829,
        264,
        8671,
        2985,
        294,
        13,
        50750
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18665276403012482,
      "compression_ratio": 1.7654986522911051,
      "no_speech_prob": 0.10494278371334076
    },
    {
      "id": 500,
      "seek": 113280,
      "start": 1140.52,
      "end": 1141.52,
      "text": " It won't happen.",
      "tokens": [
        50750,
        467,
        1582,
        380,
        1051,
        13,
        50800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18665276403012482,
      "compression_ratio": 1.7654986522911051,
      "no_speech_prob": 0.10494278371334076
    },
    {
      "id": 501,
      "seek": 113280,
      "start": 1141.52,
      "end": 1145.1599999999999,
      "text": " Like right now your stuff, your website, our website cannot be accessed.",
      "tokens": [
        50800,
        1743,
        558,
        586,
        428,
        1507,
        11,
        428,
        3144,
        11,
        527,
        3144,
        2644,
        312,
        34211,
        13,
        50982
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18665276403012482,
      "compression_ratio": 1.7654986522911051,
      "no_speech_prob": 0.10494278371334076
    },
    {
      "id": 502,
      "seek": 113280,
      "start": 1145.1599999999999,
      "end": 1146.52,
      "text": " How do we fix that?",
      "tokens": [
        50982,
        1012,
        360,
        321,
        3191,
        300,
        30,
        51050
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18665276403012482,
      "compression_ratio": 1.7654986522911051,
      "no_speech_prob": 0.10494278371334076
    },
    {
      "id": 503,
      "seek": 113280,
      "start": 1146.52,
      "end": 1147.8799999999999,
      "text": " Well, we have to expose it.",
      "tokens": [
        51050,
        1042,
        11,
        321,
        362,
        281,
        19219,
        309,
        13,
        51118
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18665276403012482,
      "compression_ratio": 1.7654986522911051,
      "no_speech_prob": 0.10494278371334076
    },
    {
      "id": 504,
      "seek": 113280,
      "start": 1147.8799999999999,
      "end": 1149.6399999999999,
      "text": " This is where the true power of Kubernetes comes in.",
      "tokens": [
        51118,
        639,
        307,
        689,
        264,
        2074,
        1347,
        295,
        23145,
        1487,
        294,
        13,
        51206
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18665276403012482,
      "compression_ratio": 1.7654986522911051,
      "no_speech_prob": 0.10494278371334076
    },
    {
      "id": 505,
      "seek": 113280,
      "start": 1149.6399999999999,
      "end": 1152.32,
      "text": " I know at this point it's like, okay, Chuck, I'm not seeing the big picture.",
      "tokens": [
        51206,
        286,
        458,
        412,
        341,
        935,
        309,
        311,
        411,
        11,
        1392,
        11,
        21607,
        11,
        286,
        478,
        406,
        2577,
        264,
        955,
        3036,
        13,
        51340
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18665276403012482,
      "compression_ratio": 1.7654986522911051,
      "no_speech_prob": 0.10494278371334076
    },
    {
      "id": 506,
      "seek": 113280,
      "start": 1152.32,
      "end": 1155.1599999999999,
      "text": " How is Kubernetes helping us with all this stuff?",
      "tokens": [
        51340,
        1012,
        307,
        23145,
        4315,
        505,
        365,
        439,
        341,
        1507,
        30,
        51482
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18665276403012482,
      "compression_ratio": 1.7654986522911051,
      "no_speech_prob": 0.10494278371334076
    },
    {
      "id": 507,
      "seek": 113280,
      "start": 1155.1599999999999,
      "end": 1156.76,
      "text": " We're about to unwrap it here right now.",
      "tokens": [
        51482,
        492,
        434,
        466,
        281,
        14853,
        4007,
        309,
        510,
        558,
        586,
        13,
        51562
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18665276403012482,
      "compression_ratio": 1.7654986522911051,
      "no_speech_prob": 0.10494278371334076
    },
    {
      "id": 508,
      "seek": 113280,
      "start": 1156.76,
      "end": 1159.0,
      "text": " It's cool that we can deploy pods like crazy.",
      "tokens": [
        51562,
        467,
        311,
        1627,
        300,
        321,
        393,
        7274,
        31925,
        411,
        3219,
        13,
        51674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18665276403012482,
      "compression_ratio": 1.7654986522911051,
      "no_speech_prob": 0.10494278371334076
    },
    {
      "id": 509,
      "seek": 113280,
      "start": 1159.0,
      "end": 1162.76,
      "text": " We can even say if our pods start to get stressed out, let's say they go over 712",
      "tokens": [
        51674,
        492,
        393,
        754,
        584,
        498,
        527,
        31925,
        722,
        281,
        483,
        14471,
        484,
        11,
        718,
        311,
        584,
        436,
        352,
        670,
        1614,
        4762,
        51862
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18665276403012482,
      "compression_ratio": 1.7654986522911051,
      "no_speech_prob": 0.10494278371334076
    },
    {
      "id": 510,
      "seek": 116276,
      "start": 1162.76,
      "end": 1165.0,
      "text": " percent of utilization on the CPU.",
      "tokens": [
        50364,
        3043,
        295,
        37074,
        322,
        264,
        13199,
        13,
        50476
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16957935253223339,
      "compression_ratio": 1.707236842105263,
      "no_speech_prob": 0.06291796267032623
    },
    {
      "id": 511,
      "seek": 116276,
      "start": 1165.0,
      "end": 1166.0,
      "text": " I want you to scale out.",
      "tokens": [
        50476,
        286,
        528,
        291,
        281,
        4373,
        484,
        13,
        50526
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16957935253223339,
      "compression_ratio": 1.707236842105263,
      "no_speech_prob": 0.06291796267032623
    },
    {
      "id": 512,
      "seek": 116276,
      "start": 1166.0,
      "end": 1170.92,
      "text": " I want you to go from 10 to 20 or 20 to 30.",
      "tokens": [
        50526,
        286,
        528,
        291,
        281,
        352,
        490,
        1266,
        281,
        945,
        420,
        945,
        281,
        2217,
        13,
        50772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16957935253223339,
      "compression_ratio": 1.707236842105263,
      "no_speech_prob": 0.06291796267032623
    },
    {
      "id": 513,
      "seek": 116276,
      "start": 1170.92,
      "end": 1175.32,
      "text": " The master can monitor the metrics of your, your cluster and make sure your website's",
      "tokens": [
        50772,
        440,
        4505,
        393,
        6002,
        264,
        16367,
        295,
        428,
        11,
        428,
        13630,
        293,
        652,
        988,
        428,
        3144,
        311,
        50992
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16957935253223339,
      "compression_ratio": 1.707236842105263,
      "no_speech_prob": 0.06291796267032623
    },
    {
      "id": 514,
      "seek": 116276,
      "start": 1175.32,
      "end": 1176.32,
      "text": " doing great.",
      "tokens": [
        50992,
        884,
        869,
        13,
        51042
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16957935253223339,
      "compression_ratio": 1.707236842105263,
      "no_speech_prob": 0.06291796267032623
    },
    {
      "id": 515,
      "seek": 116276,
      "start": 1176.32,
      "end": 1178.28,
      "text": " If your website isn't, well, then we better get some more stuff going.",
      "tokens": [
        51042,
        759,
        428,
        3144,
        1943,
        380,
        11,
        731,
        11,
        550,
        321,
        1101,
        483,
        512,
        544,
        1507,
        516,
        13,
        51140
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16957935253223339,
      "compression_ratio": 1.707236842105263,
      "no_speech_prob": 0.06291796267032623
    },
    {
      "id": 516,
      "seek": 116276,
      "start": 1178.28,
      "end": 1182.8,
      "text": " But anyways, let's talk about how we can get our website accessible to the outside world.",
      "tokens": [
        51140,
        583,
        13448,
        11,
        718,
        311,
        751,
        466,
        577,
        321,
        393,
        483,
        527,
        3144,
        9515,
        281,
        264,
        2380,
        1002,
        13,
        51366
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16957935253223339,
      "compression_ratio": 1.707236842105263,
      "no_speech_prob": 0.06291796267032623
    },
    {
      "id": 517,
      "seek": 116276,
      "start": 1182.8,
      "end": 1186.36,
      "text": " So in order for Johnny right here to buy our coffee, to get to our websites and get to",
      "tokens": [
        51366,
        407,
        294,
        1668,
        337,
        15999,
        558,
        510,
        281,
        2256,
        527,
        4982,
        11,
        281,
        483,
        281,
        527,
        12891,
        293,
        483,
        281,
        51544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16957935253223339,
      "compression_ratio": 1.707236842105263,
      "no_speech_prob": 0.06291796267032623
    },
    {
      "id": 518,
      "seek": 116276,
      "start": 1186.36,
      "end": 1188.44,
      "text": " our pods, we have to expose them.",
      "tokens": [
        51544,
        527,
        31925,
        11,
        321,
        362,
        281,
        19219,
        552,
        13,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16957935253223339,
      "compression_ratio": 1.707236842105263,
      "no_speech_prob": 0.06291796267032623
    },
    {
      "id": 519,
      "seek": 116276,
      "start": 1188.44,
      "end": 1189.8799999999999,
      "text": " But right now they're not exposed.",
      "tokens": [
        51648,
        583,
        558,
        586,
        436,
        434,
        406,
        9495,
        13,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16957935253223339,
      "compression_ratio": 1.707236842105263,
      "no_speech_prob": 0.06291796267032623
    },
    {
      "id": 520,
      "seek": 118988,
      "start": 1189.88,
      "end": 1194.0800000000002,
      "text": " In Kubernetes, when you want to expose a pod or a group of pods to a network, we're",
      "tokens": [
        50364,
        682,
        23145,
        11,
        562,
        291,
        528,
        281,
        19219,
        257,
        2497,
        420,
        257,
        1594,
        295,
        31925,
        281,
        257,
        3209,
        11,
        321,
        434,
        50574
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12678021000277612,
      "compression_ratio": 1.7840909090909092,
      "no_speech_prob": 0.016618650406599045
    },
    {
      "id": 521,
      "seek": 118988,
      "start": 1194.0800000000002,
      "end": 1197.0,
      "text": " going to deploy a service.",
      "tokens": [
        50574,
        516,
        281,
        7274,
        257,
        2643,
        13,
        50720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12678021000277612,
      "compression_ratio": 1.7840909090909092,
      "no_speech_prob": 0.016618650406599045
    },
    {
      "id": 522,
      "seek": 118988,
      "start": 1197.0,
      "end": 1201.3200000000002,
      "text": " This will expose our pods to the internet like we want, and it'll actually be a load",
      "tokens": [
        50720,
        639,
        486,
        19219,
        527,
        31925,
        281,
        264,
        4705,
        411,
        321,
        528,
        11,
        293,
        309,
        603,
        767,
        312,
        257,
        3677,
        50936
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12678021000277612,
      "compression_ratio": 1.7840909090909092,
      "no_speech_prob": 0.016618650406599045
    },
    {
      "id": 523,
      "seek": 118988,
      "start": 1201.3200000000002,
      "end": 1202.3200000000002,
      "text": " balancer.",
      "tokens": [
        50936,
        3119,
        28347,
        13,
        50986
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12678021000277612,
      "compression_ratio": 1.7840909090909092,
      "no_speech_prob": 0.016618650406599045
    },
    {
      "id": 524,
      "seek": 118988,
      "start": 1202.3200000000002,
      "end": 1205.6000000000001,
      "text": " So when Johnny tries to access, it'll hit that service and the service will expose the pods",
      "tokens": [
        50986,
        407,
        562,
        15999,
        9898,
        281,
        2105,
        11,
        309,
        603,
        2045,
        300,
        2643,
        293,
        264,
        2643,
        486,
        19219,
        264,
        31925,
        51150
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12678021000277612,
      "compression_ratio": 1.7840909090909092,
      "no_speech_prob": 0.016618650406599045
    },
    {
      "id": 525,
      "seek": 118988,
      "start": 1205.6000000000001,
      "end": 1209.16,
      "text": " and also load balance between the pods.",
      "tokens": [
        51150,
        293,
        611,
        3677,
        4772,
        1296,
        264,
        31925,
        13,
        51328
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12678021000277612,
      "compression_ratio": 1.7840909090909092,
      "no_speech_prob": 0.016618650406599045
    },
    {
      "id": 526,
      "seek": 118988,
      "start": 1209.16,
      "end": 1211.0800000000002,
      "text": " So let's deploy that service right now.",
      "tokens": [
        51328,
        407,
        718,
        311,
        7274,
        300,
        2643,
        558,
        586,
        13,
        51424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12678021000277612,
      "compression_ratio": 1.7840909090909092,
      "no_speech_prob": 0.016618650406599045
    },
    {
      "id": 527,
      "seek": 118988,
      "start": 1211.0800000000002,
      "end": 1216.4,
      "text": " And just like our deployment, our service will be described in a YAML file, another manifest.",
      "tokens": [
        51424,
        400,
        445,
        411,
        527,
        19317,
        11,
        527,
        2643,
        486,
        312,
        7619,
        294,
        257,
        398,
        2865,
        43,
        3991,
        11,
        1071,
        10067,
        13,
        51690
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12678021000277612,
      "compression_ratio": 1.7840909090909092,
      "no_speech_prob": 0.016618650406599045
    },
    {
      "id": 528,
      "seek": 121640,
      "start": 1216.4,
      "end": 1219.64,
      "text": " Actually just a set of instructions to give our master saying, Hey, master, make this",
      "tokens": [
        50364,
        5135,
        445,
        257,
        992,
        295,
        9415,
        281,
        976,
        527,
        4505,
        1566,
        11,
        1911,
        11,
        4505,
        11,
        652,
        341,
        50526
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2153479258219401,
      "compression_ratio": 1.8227146814404431,
      "no_speech_prob": 0.5845385193824768
    },
    {
      "id": 529,
      "seek": 121640,
      "start": 1219.64,
      "end": 1220.64,
      "text": " happen buddy.",
      "tokens": [
        50526,
        1051,
        10340,
        13,
        50576
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2153479258219401,
      "compression_ratio": 1.8227146814404431,
      "no_speech_prob": 0.5845385193824768
    },
    {
      "id": 530,
      "seek": 121640,
      "start": 1220.64,
      "end": 1221.72,
      "text": " So a few things here real quick.",
      "tokens": [
        50576,
        407,
        257,
        1326,
        721,
        510,
        957,
        1702,
        13,
        50630
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2153479258219401,
      "compression_ratio": 1.8227146814404431,
      "no_speech_prob": 0.5845385193824768
    },
    {
      "id": 531,
      "seek": 121640,
      "start": 1221.72,
      "end": 1223.22,
      "text": " The kind is a service.",
      "tokens": [
        50630,
        440,
        733,
        307,
        257,
        2643,
        13,
        50705
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2153479258219401,
      "compression_ratio": 1.8227146814404431,
      "no_speech_prob": 0.5845385193824768
    },
    {
      "id": 532,
      "seek": 121640,
      "start": 1223.22,
      "end": 1224.22,
      "text": " We're naming it coffee service.",
      "tokens": [
        50705,
        492,
        434,
        25290,
        309,
        4982,
        2643,
        13,
        50755
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2153479258219401,
      "compression_ratio": 1.8227146814404431,
      "no_speech_prob": 0.5845385193824768
    },
    {
      "id": 533,
      "seek": 121640,
      "start": 1224.22,
      "end": 1227.64,
      "text": " And then down here in the server specs, we have what type of service is going to be.",
      "tokens": [
        50755,
        400,
        550,
        760,
        510,
        294,
        264,
        7154,
        27911,
        11,
        321,
        362,
        437,
        2010,
        295,
        2643,
        307,
        516,
        281,
        312,
        13,
        50926
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2153479258219401,
      "compression_ratio": 1.8227146814404431,
      "no_speech_prob": 0.5845385193824768
    },
    {
      "id": 534,
      "seek": 121640,
      "start": 1227.64,
      "end": 1229.1200000000001,
      "text": " It's going to be a load balancer.",
      "tokens": [
        50926,
        467,
        311,
        516,
        281,
        312,
        257,
        3677,
        3119,
        28347,
        13,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2153479258219401,
      "compression_ratio": 1.8227146814404431,
      "no_speech_prob": 0.5845385193824768
    },
    {
      "id": 535,
      "seek": 121640,
      "start": 1229.1200000000001,
      "end": 1233.0800000000002,
      "text": " We're load balancing port 80 on both the load balancer and the pod website traffic.",
      "tokens": [
        51000,
        492,
        434,
        3677,
        22495,
        2436,
        4688,
        322,
        1293,
        264,
        3677,
        3119,
        28347,
        293,
        264,
        2497,
        3144,
        6419,
        13,
        51198
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2153479258219401,
      "compression_ratio": 1.8227146814404431,
      "no_speech_prob": 0.5845385193824768
    },
    {
      "id": 536,
      "seek": 121640,
      "start": 1233.0800000000002,
      "end": 1237.6000000000001,
      "text": " And then here's the important part and the killer thing about this, the selector, which",
      "tokens": [
        51198,
        400,
        550,
        510,
        311,
        264,
        1021,
        644,
        293,
        264,
        13364,
        551,
        466,
        341,
        11,
        264,
        23264,
        1672,
        11,
        597,
        51424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2153479258219401,
      "compression_ratio": 1.8227146814404431,
      "no_speech_prob": 0.5845385193824768
    },
    {
      "id": 537,
      "seek": 121640,
      "start": 1237.6000000000001,
      "end": 1239.24,
      "text": " pods are we going to load balance?",
      "tokens": [
        51424,
        31925,
        366,
        321,
        516,
        281,
        3677,
        4772,
        30,
        51506
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2153479258219401,
      "compression_ratio": 1.8227146814404431,
      "no_speech_prob": 0.5845385193824768
    },
    {
      "id": 538,
      "seek": 121640,
      "start": 1239.24,
      "end": 1242.2,
      "text": " It'll be any pod that has the app label and see coffee.",
      "tokens": [
        51506,
        467,
        603,
        312,
        604,
        2497,
        300,
        575,
        264,
        724,
        7645,
        293,
        536,
        4982,
        13,
        51654
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2153479258219401,
      "compression_ratio": 1.8227146814404431,
      "no_speech_prob": 0.5845385193824768
    },
    {
      "id": 539,
      "seek": 121640,
      "start": 1242.2,
      "end": 1245.44,
      "text": " This is important because if you look back at our deployment where we deployed our pods,",
      "tokens": [
        51654,
        639,
        307,
        1021,
        570,
        498,
        291,
        574,
        646,
        412,
        527,
        19317,
        689,
        321,
        17826,
        527,
        31925,
        11,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2153479258219401,
      "compression_ratio": 1.8227146814404431,
      "no_speech_prob": 0.5845385193824768
    },
    {
      "id": 540,
      "seek": 124544,
      "start": 1245.44,
      "end": 1247.64,
      "text": " our app label for our pods was NC coffee.",
      "tokens": [
        50364,
        527,
        724,
        7645,
        337,
        527,
        31925,
        390,
        20786,
        4982,
        13,
        50474
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11891179765973772,
      "compression_ratio": 2.0510204081632653,
      "no_speech_prob": 0.0061265272088348866
    },
    {
      "id": 541,
      "seek": 124544,
      "start": 1247.64,
      "end": 1252.28,
      "text": " So any pods that has the app label and see coffee, that low balance is going to load",
      "tokens": [
        50474,
        407,
        604,
        31925,
        300,
        575,
        264,
        724,
        7645,
        293,
        536,
        4982,
        11,
        300,
        2295,
        4772,
        307,
        516,
        281,
        3677,
        50706
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11891179765973772,
      "compression_ratio": 2.0510204081632653,
      "no_speech_prob": 0.0061265272088348866
    },
    {
      "id": 542,
      "seek": 124544,
      "start": 1252.28,
      "end": 1253.3600000000001,
      "text": " balance between those.",
      "tokens": [
        50706,
        4772,
        1296,
        729,
        13,
        50760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11891179765973772,
      "compression_ratio": 2.0510204081632653,
      "no_speech_prob": 0.0061265272088348866
    },
    {
      "id": 543,
      "seek": 124544,
      "start": 1253.3600000000001,
      "end": 1256.8,
      "text": " So here's what's killer about that is that if we create two pods, it's going to load",
      "tokens": [
        50760,
        407,
        510,
        311,
        437,
        311,
        13364,
        466,
        300,
        307,
        300,
        498,
        321,
        1884,
        732,
        31925,
        11,
        309,
        311,
        516,
        281,
        3677,
        50932
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11891179765973772,
      "compression_ratio": 2.0510204081632653,
      "no_speech_prob": 0.0061265272088348866
    },
    {
      "id": 544,
      "seek": 124544,
      "start": 1256.8,
      "end": 1259.52,
      "text": " balance that as long as it has a label and see coffee.",
      "tokens": [
        50932,
        4772,
        300,
        382,
        938,
        382,
        309,
        575,
        257,
        7645,
        293,
        536,
        4982,
        13,
        51068
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11891179765973772,
      "compression_ratio": 2.0510204081632653,
      "no_speech_prob": 0.0061265272088348866
    },
    {
      "id": 545,
      "seek": 124544,
      "start": 1259.52,
      "end": 1263.8400000000001,
      "text": " If we create 2000 pods, as long as it has the label and see coffee, it's going to load",
      "tokens": [
        51068,
        759,
        321,
        1884,
        8132,
        31925,
        11,
        382,
        938,
        382,
        309,
        575,
        264,
        7645,
        293,
        536,
        4982,
        11,
        309,
        311,
        516,
        281,
        3677,
        51284
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11891179765973772,
      "compression_ratio": 2.0510204081632653,
      "no_speech_prob": 0.0061265272088348866
    },
    {
      "id": 546,
      "seek": 124544,
      "start": 1263.8400000000001,
      "end": 1265.96,
      "text": " balance between those 2000 pods.",
      "tokens": [
        51284,
        4772,
        1296,
        729,
        8132,
        31925,
        13,
        51390
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11891179765973772,
      "compression_ratio": 2.0510204081632653,
      "no_speech_prob": 0.0061265272088348866
    },
    {
      "id": 547,
      "seek": 124544,
      "start": 1265.96,
      "end": 1266.96,
      "text": " It's just automatic.",
      "tokens": [
        51390,
        467,
        311,
        445,
        12509,
        13,
        51440
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11891179765973772,
      "compression_ratio": 2.0510204081632653,
      "no_speech_prob": 0.0061265272088348866
    },
    {
      "id": 548,
      "seek": 124544,
      "start": 1266.96,
      "end": 1268.76,
      "text": " We don't have to worry about it once you create it.",
      "tokens": [
        51440,
        492,
        500,
        380,
        362,
        281,
        3292,
        466,
        309,
        1564,
        291,
        1884,
        309,
        13,
        51530
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11891179765973772,
      "compression_ratio": 2.0510204081632653,
      "no_speech_prob": 0.0061265272088348866
    },
    {
      "id": 549,
      "seek": 124544,
      "start": 1268.76,
      "end": 1269.76,
      "text": " So let's do it.",
      "tokens": [
        51530,
        407,
        718,
        311,
        360,
        309,
        13,
        51580
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11891179765973772,
      "compression_ratio": 2.0510204081632653,
      "no_speech_prob": 0.0061265272088348866
    },
    {
      "id": 550,
      "seek": 124544,
      "start": 1269.76,
      "end": 1273.48,
      "text": " So just as before, I'm going to copy all this code here, this YAML, and I'll get back into",
      "tokens": [
        51580,
        407,
        445,
        382,
        949,
        11,
        286,
        478,
        516,
        281,
        5055,
        439,
        341,
        3089,
        510,
        11,
        341,
        398,
        2865,
        43,
        11,
        293,
        286,
        603,
        483,
        646,
        666,
        51766
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11891179765973772,
      "compression_ratio": 2.0510204081632653,
      "no_speech_prob": 0.0061265272088348866
    },
    {
      "id": 551,
      "seek": 124544,
      "start": 1273.48,
      "end": 1274.48,
      "text": " my Linux box.",
      "tokens": [
        51766,
        452,
        18734,
        2424,
        13,
        51816
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11891179765973772,
      "compression_ratio": 2.0510204081632653,
      "no_speech_prob": 0.0061265272088348866
    },
    {
      "id": 552,
      "seek": 127448,
      "start": 1274.52,
      "end": 1282.76,
      "text": " Create a new file, nano coffee dash service dot YAML, paste that in there and do a control",
      "tokens": [
        50366,
        20248,
        257,
        777,
        3991,
        11,
        30129,
        4982,
        8240,
        2643,
        5893,
        398,
        2865,
        43,
        11,
        9163,
        300,
        294,
        456,
        293,
        360,
        257,
        1969,
        50778
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22481845926355432,
      "compression_ratio": 1.6525821596244132,
      "no_speech_prob": 0.14311444759368896
    },
    {
      "id": 553,
      "seek": 127448,
      "start": 1282.76,
      "end": 1285.76,
      "text": " X to save Y for yes and get out of there.",
      "tokens": [
        50778,
        1783,
        281,
        3155,
        398,
        337,
        2086,
        293,
        483,
        484,
        295,
        456,
        13,
        50928
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22481845926355432,
      "compression_ratio": 1.6525821596244132,
      "no_speech_prob": 0.14311444759368896
    },
    {
      "id": 554,
      "seek": 127448,
      "start": 1285.76,
      "end": 1286.76,
      "text": " And then we'll apply that service.",
      "tokens": [
        50928,
        400,
        550,
        321,
        603,
        3079,
        300,
        2643,
        13,
        50978
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22481845926355432,
      "compression_ratio": 1.6525821596244132,
      "no_speech_prob": 0.14311444759368896
    },
    {
      "id": 555,
      "seek": 127448,
      "start": 1286.76,
      "end": 1293.08,
      "text": " And all we have to do is a cube CTL, just like before, we'll do apply dash F to specify",
      "tokens": [
        50978,
        400,
        439,
        321,
        362,
        281,
        360,
        307,
        257,
        13728,
        19529,
        43,
        11,
        445,
        411,
        949,
        11,
        321,
        603,
        360,
        3079,
        8240,
        479,
        281,
        16500,
        51294
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22481845926355432,
      "compression_ratio": 1.6525821596244132,
      "no_speech_prob": 0.14311444759368896
    },
    {
      "id": 556,
      "seek": 127448,
      "start": 1293.08,
      "end": 1301.16,
      "text": " our template, our manifest, and it'll be coffee dash service dot YAML dot YAML.",
      "tokens": [
        51294,
        527,
        12379,
        11,
        527,
        10067,
        11,
        293,
        309,
        603,
        312,
        4982,
        8240,
        2643,
        5893,
        398,
        2865,
        43,
        5893,
        398,
        2865,
        43,
        13,
        51698
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22481845926355432,
      "compression_ratio": 1.6525821596244132,
      "no_speech_prob": 0.14311444759368896
    },
    {
      "id": 557,
      "seek": 127448,
      "start": 1301.16,
      "end": 1303.68,
      "text": " And let's do it.",
      "tokens": [
        51698,
        400,
        718,
        311,
        360,
        309,
        13,
        51824
      ],
      "temperature": 0.0,
      "avg_logprob": -0.22481845926355432,
      "compression_ratio": 1.6525821596244132,
      "no_speech_prob": 0.14311444759368896
    },
    {
      "id": 558,
      "seek": 130368,
      "start": 1303.88,
      "end": 1304.88,
      "text": " It's doing something very exciting.",
      "tokens": [
        50374,
        467,
        311,
        884,
        746,
        588,
        4670,
        13,
        50424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2064326233659054,
      "compression_ratio": 1.8173374613003095,
      "no_speech_prob": 0.023412484675645828
    },
    {
      "id": 559,
      "seek": 130368,
      "start": 1304.88,
      "end": 1307.5600000000002,
      "text": " I'm going to, okay, I'm just going to enter this command.",
      "tokens": [
        50424,
        286,
        478,
        516,
        281,
        11,
        1392,
        11,
        286,
        478,
        445,
        516,
        281,
        3242,
        341,
        5622,
        13,
        50558
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2064326233659054,
      "compression_ratio": 1.8173374613003095,
      "no_speech_prob": 0.023412484675645828
    },
    {
      "id": 560,
      "seek": 130368,
      "start": 1307.5600000000002,
      "end": 1309.3600000000001,
      "text": " Cube CTL gets services.",
      "tokens": [
        50558,
        33003,
        19529,
        43,
        2170,
        3328,
        13,
        50648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2064326233659054,
      "compression_ratio": 1.8173374613003095,
      "no_speech_prob": 0.023412484675645828
    },
    {
      "id": 561,
      "seek": 130368,
      "start": 1309.3600000000001,
      "end": 1311.04,
      "text": " This is a service we're looking at now.",
      "tokens": [
        50648,
        639,
        307,
        257,
        2643,
        321,
        434,
        1237,
        412,
        586,
        13,
        50732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2064326233659054,
      "compression_ratio": 1.8173374613003095,
      "no_speech_prob": 0.023412484675645828
    },
    {
      "id": 562,
      "seek": 130368,
      "start": 1311.04,
      "end": 1313.4,
      "text": " And there it is right there, coffee service.",
      "tokens": [
        50732,
        400,
        456,
        309,
        307,
        558,
        456,
        11,
        4982,
        2643,
        13,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2064326233659054,
      "compression_ratio": 1.8173374613003095,
      "no_speech_prob": 0.023412484675645828
    },
    {
      "id": 563,
      "seek": 130368,
      "start": 1313.4,
      "end": 1314.92,
      "text": " And it's already done.",
      "tokens": [
        50850,
        400,
        309,
        311,
        1217,
        1096,
        13,
        50926
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2064326233659054,
      "compression_ratio": 1.8173374613003095,
      "no_speech_prob": 0.023412484675645828
    },
    {
      "id": 564,
      "seek": 130368,
      "start": 1314.92,
      "end": 1315.92,
      "text": " Crazy fast.",
      "tokens": [
        50926,
        22509,
        2370,
        13,
        50976
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2064326233659054,
      "compression_ratio": 1.8173374613003095,
      "no_speech_prob": 0.023412484675645828
    },
    {
      "id": 565,
      "seek": 130368,
      "start": 1315.92,
      "end": 1319.8400000000001,
      "text": " Now what's cool about this is that it created a load balancer in Kubernetes, but it also",
      "tokens": [
        50976,
        823,
        437,
        311,
        1627,
        466,
        341,
        307,
        300,
        309,
        2942,
        257,
        3677,
        3119,
        28347,
        294,
        23145,
        11,
        457,
        309,
        611,
        51172
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2064326233659054,
      "compression_ratio": 1.8173374613003095,
      "no_speech_prob": 0.023412484675645828
    },
    {
      "id": 566,
      "seek": 130368,
      "start": 1319.8400000000001,
      "end": 1321.88,
      "text": " created a load balancer in our cloud provider.",
      "tokens": [
        51172,
        2942,
        257,
        3677,
        3119,
        28347,
        294,
        527,
        4588,
        12398,
        13,
        51274
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2064326233659054,
      "compression_ratio": 1.8173374613003095,
      "no_speech_prob": 0.023412484675645828
    },
    {
      "id": 567,
      "seek": 130368,
      "start": 1321.88,
      "end": 1326.0800000000002,
      "text": " Remember I told you that Kubernetes loves cloud providers and then the love goes both",
      "tokens": [
        51274,
        5459,
        286,
        1907,
        291,
        300,
        23145,
        6752,
        4588,
        11330,
        293,
        550,
        264,
        959,
        1709,
        1293,
        51484
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2064326233659054,
      "compression_ratio": 1.8173374613003095,
      "no_speech_prob": 0.023412484675645828
    },
    {
      "id": 568,
      "seek": 130368,
      "start": 1326.0800000000002,
      "end": 1327.0800000000002,
      "text": " ways.",
      "tokens": [
        51484,
        2098,
        13,
        51534
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2064326233659054,
      "compression_ratio": 1.8173374613003095,
      "no_speech_prob": 0.023412484675645828
    },
    {
      "id": 569,
      "seek": 130368,
      "start": 1327.0800000000002,
      "end": 1331.04,
      "text": " So when I do this command, it actually created what's called a node balancer in Linode.",
      "tokens": [
        51534,
        407,
        562,
        286,
        360,
        341,
        5622,
        11,
        309,
        767,
        2942,
        437,
        311,
        1219,
        257,
        9984,
        3119,
        28347,
        294,
        9355,
        1429,
        13,
        51732
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2064326233659054,
      "compression_ratio": 1.8173374613003095,
      "no_speech_prob": 0.023412484675645828
    },
    {
      "id": 570,
      "seek": 130368,
      "start": 1331.04,
      "end": 1332.04,
      "text": " Let's go check it out real quick.",
      "tokens": [
        51732,
        961,
        311,
        352,
        1520,
        309,
        484,
        957,
        1702,
        13,
        51782
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2064326233659054,
      "compression_ratio": 1.8173374613003095,
      "no_speech_prob": 0.023412484675645828
    },
    {
      "id": 571,
      "seek": 133204,
      "start": 1332.04,
      "end": 1334.72,
      "text": " In Linode, I'll go back to my side menu here.",
      "tokens": [
        50364,
        682,
        9355,
        1429,
        11,
        286,
        603,
        352,
        646,
        281,
        452,
        1252,
        6510,
        510,
        13,
        50498
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19480243009679457,
      "compression_ratio": 1.8101265822784811,
      "no_speech_prob": 0.0076738265343010426
    },
    {
      "id": 572,
      "seek": 133204,
      "start": 1334.72,
      "end": 1336.72,
      "text": " And right here is a node balancer.",
      "tokens": [
        50498,
        400,
        558,
        510,
        307,
        257,
        9984,
        3119,
        28347,
        13,
        50598
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19480243009679457,
      "compression_ratio": 1.8101265822784811,
      "no_speech_prob": 0.0076738265343010426
    },
    {
      "id": 573,
      "seek": 133204,
      "start": 1336.72,
      "end": 1339.84,
      "text": " It's just their clever name for their load balancers.",
      "tokens": [
        50598,
        467,
        311,
        445,
        641,
        13494,
        1315,
        337,
        641,
        3677,
        3119,
        4463,
        433,
        13,
        50754
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19480243009679457,
      "compression_ratio": 1.8101265822784811,
      "no_speech_prob": 0.0076738265343010426
    },
    {
      "id": 574,
      "seek": 133204,
      "start": 1339.84,
      "end": 1340.96,
      "text": " Click on that.",
      "tokens": [
        50754,
        8230,
        322,
        300,
        13,
        50810
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19480243009679457,
      "compression_ratio": 1.8101265822784811,
      "no_speech_prob": 0.0076738265343010426
    },
    {
      "id": 575,
      "seek": 133204,
      "start": 1340.96,
      "end": 1341.96,
      "text": " There it is right there.",
      "tokens": [
        50810,
        821,
        309,
        307,
        558,
        456,
        13,
        50860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19480243009679457,
      "compression_ratio": 1.8101265822784811,
      "no_speech_prob": 0.0076738265343010426
    },
    {
      "id": 576,
      "seek": 133204,
      "start": 1341.96,
      "end": 1342.96,
      "text": " My node balancer was created.",
      "tokens": [
        50860,
        1222,
        9984,
        3119,
        28347,
        390,
        2942,
        13,
        50910
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19480243009679457,
      "compression_ratio": 1.8101265822784811,
      "no_speech_prob": 0.0076738265343010426
    },
    {
      "id": 577,
      "seek": 133204,
      "start": 1342.96,
      "end": 1344.6,
      "text": " You see that IP address right there?",
      "tokens": [
        50910,
        509,
        536,
        300,
        8671,
        2985,
        558,
        456,
        30,
        50992
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19480243009679457,
      "compression_ratio": 1.8101265822784811,
      "no_speech_prob": 0.0076738265343010426
    },
    {
      "id": 578,
      "seek": 133204,
      "start": 1344.6,
      "end": 1345.6,
      "text": " It's the same exact one.",
      "tokens": [
        50992,
        467,
        311,
        264,
        912,
        1900,
        472,
        13,
        51042
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19480243009679457,
      "compression_ratio": 1.8101265822784811,
      "no_speech_prob": 0.0076738265343010426
    },
    {
      "id": 579,
      "seek": 133204,
      "start": 1345.6,
      "end": 1349.3999999999999,
      "text": " It's what we're seeing here in the Kubernetes master, the external IP right there.",
      "tokens": [
        51042,
        467,
        311,
        437,
        321,
        434,
        2577,
        510,
        294,
        264,
        23145,
        4505,
        11,
        264,
        8320,
        8671,
        558,
        456,
        13,
        51232
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19480243009679457,
      "compression_ratio": 1.8101265822784811,
      "no_speech_prob": 0.0076738265343010426
    },
    {
      "id": 580,
      "seek": 133204,
      "start": 1349.3999999999999,
      "end": 1353.68,
      "text": " And we can see in the Linode portal in our backend status, we have three nodes up, which",
      "tokens": [
        51232,
        400,
        321,
        393,
        536,
        294,
        264,
        9355,
        1429,
        14982,
        294,
        527,
        38087,
        6558,
        11,
        321,
        362,
        1045,
        13891,
        493,
        11,
        597,
        51446
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19480243009679457,
      "compression_ratio": 1.8101265822784811,
      "no_speech_prob": 0.0076738265343010426
    },
    {
      "id": 581,
      "seek": 133204,
      "start": 1353.68,
      "end": 1355.52,
      "text": " is our three worker nodes.",
      "tokens": [
        51446,
        307,
        527,
        1045,
        11346,
        13891,
        13,
        51538
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19480243009679457,
      "compression_ratio": 1.8101265822784811,
      "no_speech_prob": 0.0076738265343010426
    },
    {
      "id": 582,
      "seek": 133204,
      "start": 1355.52,
      "end": 1358.76,
      "text": " But in Kubernetes, it's a load balancing between 10 pods.",
      "tokens": [
        51538,
        583,
        294,
        23145,
        11,
        309,
        311,
        257,
        3677,
        22495,
        1296,
        1266,
        31925,
        13,
        51700
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19480243009679457,
      "compression_ratio": 1.8101265822784811,
      "no_speech_prob": 0.0076738265343010426
    },
    {
      "id": 583,
      "seek": 133204,
      "start": 1358.76,
      "end": 1359.76,
      "text": " Let's see if it worked.",
      "tokens": [
        51700,
        961,
        311,
        536,
        498,
        309,
        2732,
        13,
        51750
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19480243009679457,
      "compression_ratio": 1.8101265822784811,
      "no_speech_prob": 0.0076738265343010426
    },
    {
      "id": 584,
      "seek": 133204,
      "start": 1359.76,
      "end": 1360.76,
      "text": " Let's go to our website.",
      "tokens": [
        51750,
        961,
        311,
        352,
        281,
        527,
        3144,
        13,
        51800
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19480243009679457,
      "compression_ratio": 1.8101265822784811,
      "no_speech_prob": 0.0076738265343010426
    },
    {
      "id": 585,
      "seek": 136076,
      "start": 1360.76,
      "end": 1362.16,
      "text": " We have the IP address.",
      "tokens": [
        50364,
        492,
        362,
        264,
        8671,
        2985,
        13,
        50434
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1904039110456194,
      "compression_ratio": 1.6654929577464788,
      "no_speech_prob": 0.009674597531557083
    },
    {
      "id": 586,
      "seek": 136076,
      "start": 1362.16,
      "end": 1366.0,
      "text": " Open up a new tab and see if it worked.",
      "tokens": [
        50434,
        7238,
        493,
        257,
        777,
        4421,
        293,
        536,
        498,
        309,
        2732,
        13,
        50626
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1904039110456194,
      "compression_ratio": 1.6654929577464788,
      "no_speech_prob": 0.009674597531557083
    },
    {
      "id": 587,
      "seek": 136076,
      "start": 1366.0,
      "end": 1367.4,
      "text": " Bam.",
      "tokens": [
        50626,
        26630,
        13,
        50696
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1904039110456194,
      "compression_ratio": 1.6654929577464788,
      "no_speech_prob": 0.009674597531557083
    },
    {
      "id": 588,
      "seek": 136076,
      "start": 1367.4,
      "end": 1371.84,
      "text": " There's our coffee website being low balanced across 10 pods in Kubernetes.",
      "tokens": [
        50696,
        821,
        311,
        527,
        4982,
        3144,
        885,
        2295,
        13902,
        2108,
        1266,
        31925,
        294,
        23145,
        13,
        50918
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1904039110456194,
      "compression_ratio": 1.6654929577464788,
      "no_speech_prob": 0.009674597531557083
    },
    {
      "id": 589,
      "seek": 136076,
      "start": 1371.84,
      "end": 1372.84,
      "text": " It's running.",
      "tokens": [
        50918,
        467,
        311,
        2614,
        13,
        50968
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1904039110456194,
      "compression_ratio": 1.6654929577464788,
      "no_speech_prob": 0.009674597531557083
    },
    {
      "id": 590,
      "seek": 136076,
      "start": 1372.84,
      "end": 1373.84,
      "text": " It's working.",
      "tokens": [
        50968,
        467,
        311,
        1364,
        13,
        51018
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1904039110456194,
      "compression_ratio": 1.6654929577464788,
      "no_speech_prob": 0.009674597531557083
    },
    {
      "id": 591,
      "seek": 136076,
      "start": 1373.84,
      "end": 1374.84,
      "text": " It's alive.",
      "tokens": [
        51018,
        467,
        311,
        5465,
        13,
        51068
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1904039110456194,
      "compression_ratio": 1.6654929577464788,
      "no_speech_prob": 0.009674597531557083
    },
    {
      "id": 592,
      "seek": 136076,
      "start": 1374.84,
      "end": 1375.84,
      "text": " And we can go in here and buy all the coffee we need.",
      "tokens": [
        51068,
        400,
        321,
        393,
        352,
        294,
        510,
        293,
        2256,
        439,
        264,
        4982,
        321,
        643,
        13,
        51118
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1904039110456194,
      "compression_ratio": 1.6654929577464788,
      "no_speech_prob": 0.009674597531557083
    },
    {
      "id": 593,
      "seek": 136076,
      "start": 1375.84,
      "end": 1376.84,
      "text": " And so you believe me about the Kubernetes stuff.",
      "tokens": [
        51118,
        400,
        370,
        291,
        1697,
        385,
        466,
        264,
        23145,
        1507,
        13,
        51168
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1904039110456194,
      "compression_ratio": 1.6654929577464788,
      "no_speech_prob": 0.009674597531557083
    },
    {
      "id": 594,
      "seek": 136076,
      "start": 1376.84,
      "end": 1380.76,
      "text": " I want to show you how to look at that service and verify it's going between your 10 pods.",
      "tokens": [
        51168,
        286,
        528,
        281,
        855,
        291,
        577,
        281,
        574,
        412,
        300,
        2643,
        293,
        16888,
        309,
        311,
        516,
        1296,
        428,
        1266,
        31925,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1904039110456194,
      "compression_ratio": 1.6654929577464788,
      "no_speech_prob": 0.009674597531557083
    },
    {
      "id": 595,
      "seek": 136076,
      "start": 1380.76,
      "end": 1388.52,
      "text": " If we do cube CTL, get services and we'll specify our coffee service.",
      "tokens": [
        51364,
        759,
        321,
        360,
        13728,
        19529,
        43,
        11,
        483,
        3328,
        293,
        321,
        603,
        16500,
        527,
        4982,
        2643,
        13,
        51752
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1904039110456194,
      "compression_ratio": 1.6654929577464788,
      "no_speech_prob": 0.009674597531557083
    },
    {
      "id": 596,
      "seek": 136076,
      "start": 1388.52,
      "end": 1389.52,
      "text": " We'll get the low down.",
      "tokens": [
        51752,
        492,
        603,
        483,
        264,
        2295,
        760,
        13,
        51802
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1904039110456194,
      "compression_ratio": 1.6654929577464788,
      "no_speech_prob": 0.009674597531557083
    },
    {
      "id": 597,
      "seek": 138952,
      "start": 1389.52,
      "end": 1390.8,
      "text": " Sorry, not get.",
      "tokens": [
        50364,
        4919,
        11,
        406,
        483,
        13,
        50428
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 598,
      "seek": 138952,
      "start": 1390.8,
      "end": 1391.8,
      "text": " Describe.",
      "tokens": [
        50428,
        3885,
        8056,
        13,
        50478
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 599,
      "seek": 138952,
      "start": 1391.8,
      "end": 1393.6399999999999,
      "text": " We want to describe that service.",
      "tokens": [
        50478,
        492,
        528,
        281,
        6786,
        300,
        2643,
        13,
        50570
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 600,
      "seek": 138952,
      "start": 1393.6399999999999,
      "end": 1395.6,
      "text": " So describe services.",
      "tokens": [
        50570,
        407,
        6786,
        3328,
        13,
        50668
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 601,
      "seek": 138952,
      "start": 1395.6,
      "end": 1397.44,
      "text": " Describe is always getting more detail.",
      "tokens": [
        50668,
        3885,
        8056,
        307,
        1009,
        1242,
        544,
        2607,
        13,
        50760
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 602,
      "seek": 138952,
      "start": 1397.44,
      "end": 1399.08,
      "text": " Coffee dash service.",
      "tokens": [
        50760,
        25481,
        8240,
        2643,
        13,
        50842
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 603,
      "seek": 138952,
      "start": 1399.08,
      "end": 1401.48,
      "text": " And there's all the beautiful information we want to see about this.",
      "tokens": [
        50842,
        400,
        456,
        311,
        439,
        264,
        2238,
        1589,
        321,
        528,
        281,
        536,
        466,
        341,
        13,
        50962
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 604,
      "seek": 138952,
      "start": 1401.48,
      "end": 1405.52,
      "text": " And then right here are end points, these few suckers and then seven more.",
      "tokens": [
        50962,
        400,
        550,
        558,
        510,
        366,
        917,
        2793,
        11,
        613,
        1326,
        9967,
        433,
        293,
        550,
        3407,
        544,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 605,
      "seek": 138952,
      "start": 1405.52,
      "end": 1407.6399999999999,
      "text": " It's going to be low balancing for.",
      "tokens": [
        51164,
        467,
        311,
        516,
        281,
        312,
        2295,
        22495,
        337,
        13,
        51270
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 606,
      "seek": 138952,
      "start": 1407.6399999999999,
      "end": 1408.6399999999999,
      "text": " So cool.",
      "tokens": [
        51270,
        407,
        1627,
        13,
        51320
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 607,
      "seek": 138952,
      "start": 1408.6399999999999,
      "end": 1409.6399999999999,
      "text": " Amazing.",
      "tokens": [
        51320,
        14165,
        13,
        51370
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 608,
      "seek": 138952,
      "start": 1409.6399999999999,
      "end": 1410.6399999999999,
      "text": " Oh, now hold on.",
      "tokens": [
        51370,
        876,
        11,
        586,
        1797,
        322,
        13,
        51420
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 609,
      "seek": 138952,
      "start": 1410.6399999999999,
      "end": 1411.6399999999999,
      "text": " You know what I realized?",
      "tokens": [
        51420,
        509,
        458,
        437,
        286,
        5334,
        30,
        51470
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 610,
      "seek": 138952,
      "start": 1411.6399999999999,
      "end": 1414.8,
      "text": " Looking at our coffee, we get a new coffee in Peru decaf and all we have is Peru.",
      "tokens": [
        51470,
        11053,
        412,
        527,
        4982,
        11,
        321,
        483,
        257,
        777,
        4982,
        294,
        31571,
        368,
        496,
        69,
        293,
        439,
        321,
        362,
        307,
        31571,
        13,
        51628
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 611,
      "seek": 138952,
      "start": 1414.8,
      "end": 1416.4,
      "text": " So now we have to update our website.",
      "tokens": [
        51628,
        407,
        586,
        321,
        362,
        281,
        5623,
        527,
        3144,
        13,
        51708
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 612,
      "seek": 138952,
      "start": 1416.4,
      "end": 1418.2,
      "text": " Not too bad with Kubernetes.",
      "tokens": [
        51708,
        1726,
        886,
        1578,
        365,
        23145,
        13,
        51798
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 613,
      "seek": 138952,
      "start": 1418.2,
      "end": 1419.2,
      "text": " Let's try it out real quick.",
      "tokens": [
        51798,
        961,
        311,
        853,
        309,
        484,
        957,
        1702,
        13,
        51848
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20591094790125739,
      "compression_ratio": 1.6948640483383686,
      "no_speech_prob": 0.0539381206035614
    },
    {
      "id": 614,
      "seek": 141920,
      "start": 1419.28,
      "end": 1421.04,
      "text": " We've already got the Docker image out there.",
      "tokens": [
        50368,
        492,
        600,
        1217,
        658,
        264,
        33772,
        3256,
        484,
        456,
        13,
        50456
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19532866765988754,
      "compression_ratio": 1.6526315789473685,
      "no_speech_prob": 0.0077818045392632484
    },
    {
      "id": 615,
      "seek": 141920,
      "start": 1421.04,
      "end": 1422.04,
      "text": " The Docker image is ready to go.",
      "tokens": [
        50456,
        440,
        33772,
        3256,
        307,
        1919,
        281,
        352,
        13,
        50506
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19532866765988754,
      "compression_ratio": 1.6526315789473685,
      "no_speech_prob": 0.0077818045392632484
    },
    {
      "id": 616,
      "seek": 141920,
      "start": 1422.04,
      "end": 1428.0800000000002,
      "text": " All we have to do is pull it and put it out to our, what, 10 containers now, 10 pods.",
      "tokens": [
        50506,
        1057,
        321,
        362,
        281,
        360,
        307,
        2235,
        309,
        293,
        829,
        309,
        484,
        281,
        527,
        11,
        437,
        11,
        1266,
        17089,
        586,
        11,
        1266,
        31925,
        13,
        50808
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19532866765988754,
      "compression_ratio": 1.6526315789473685,
      "no_speech_prob": 0.0077818045392632484
    },
    {
      "id": 617,
      "seek": 141920,
      "start": 1428.0800000000002,
      "end": 1429.0800000000002,
      "text": " Let's do that right now.",
      "tokens": [
        50808,
        961,
        311,
        360,
        300,
        558,
        586,
        13,
        50858
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19532866765988754,
      "compression_ratio": 1.6526315789473685,
      "no_speech_prob": 0.0077818045392632484
    },
    {
      "id": 618,
      "seek": 141920,
      "start": 1429.0800000000002,
      "end": 1430.0800000000002,
      "text": " Back at our Linux box.",
      "tokens": [
        50858,
        5833,
        412,
        527,
        18734,
        2424,
        13,
        50908
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19532866765988754,
      "compression_ratio": 1.6526315789473685,
      "no_speech_prob": 0.0077818045392632484
    },
    {
      "id": 619,
      "seek": 141920,
      "start": 1430.0800000000002,
      "end": 1431.92,
      "text": " I'm going to edit my deployment.",
      "tokens": [
        50908,
        286,
        478,
        516,
        281,
        8129,
        452,
        19317,
        13,
        51000
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19532866765988754,
      "compression_ratio": 1.6526315789473685,
      "no_speech_prob": 0.0077818045392632484
    },
    {
      "id": 620,
      "seek": 141920,
      "start": 1431.92,
      "end": 1436.32,
      "text": " So I'll do cube CTL, edit deployment.",
      "tokens": [
        51000,
        407,
        286,
        603,
        360,
        13728,
        19529,
        43,
        11,
        8129,
        19317,
        13,
        51220
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19532866765988754,
      "compression_ratio": 1.6526315789473685,
      "no_speech_prob": 0.0077818045392632484
    },
    {
      "id": 621,
      "seek": 141920,
      "start": 1436.32,
      "end": 1439.56,
      "text": " And it was network Chuck coffee dash deployment.",
      "tokens": [
        51220,
        400,
        309,
        390,
        3209,
        21607,
        4982,
        8240,
        19317,
        13,
        51382
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19532866765988754,
      "compression_ratio": 1.6526315789473685,
      "no_speech_prob": 0.0077818045392632484
    },
    {
      "id": 622,
      "seek": 141920,
      "start": 1439.56,
      "end": 1441.68,
      "text": " Why did I make it so long?",
      "tokens": [
        51382,
        1545,
        630,
        286,
        652,
        309,
        370,
        938,
        30,
        51488
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19532866765988754,
      "compression_ratio": 1.6526315789473685,
      "no_speech_prob": 0.0077818045392632484
    },
    {
      "id": 623,
      "seek": 141920,
      "start": 1441.68,
      "end": 1442.68,
      "text": " There we go.",
      "tokens": [
        51488,
        821,
        321,
        352,
        13,
        51538
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19532866765988754,
      "compression_ratio": 1.6526315789473685,
      "no_speech_prob": 0.0077818045392632484
    },
    {
      "id": 624,
      "seek": 141920,
      "start": 1442.68,
      "end": 1443.68,
      "text": " Okay.",
      "tokens": [
        51538,
        1033,
        13,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19532866765988754,
      "compression_ratio": 1.6526315789473685,
      "no_speech_prob": 0.0077818045392632484
    },
    {
      "id": 625,
      "seek": 141920,
      "start": 1443.68,
      "end": 1444.68,
      "text": " Two things I want to change right now.",
      "tokens": [
        51588,
        4453,
        721,
        286,
        528,
        281,
        1319,
        558,
        586,
        13,
        51638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19532866765988754,
      "compression_ratio": 1.6526315789473685,
      "no_speech_prob": 0.0077818045392632484
    },
    {
      "id": 626,
      "seek": 141920,
      "start": 1444.68,
      "end": 1449.16,
      "text": " First is I want, instead of 10 servers, I want to go.",
      "tokens": [
        51638,
        2386,
        307,
        286,
        528,
        11,
        2602,
        295,
        1266,
        15909,
        11,
        286,
        528,
        281,
        352,
        13,
        51862
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19532866765988754,
      "compression_ratio": 1.6526315789473685,
      "no_speech_prob": 0.0077818045392632484
    },
    {
      "id": 627,
      "seek": 144916,
      "start": 1449.8000000000002,
      "end": 1451.0800000000002,
      "text": " The 20 servers.",
      "tokens": [
        50396,
        440,
        945,
        15909,
        13,
        50460
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2224872536855201,
      "compression_ratio": 1.6622073578595318,
      "no_speech_prob": 0.004161294084042311
    },
    {
      "id": 628,
      "seek": 144916,
      "start": 1451.0800000000002,
      "end": 1452.0800000000002,
      "text": " Why not?",
      "tokens": [
        50460,
        1545,
        406,
        30,
        50510
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2224872536855201,
      "compression_ratio": 1.6622073578595318,
      "no_speech_prob": 0.004161294084042311
    },
    {
      "id": 629,
      "seek": 144916,
      "start": 1452.0800000000002,
      "end": 1455.1200000000001,
      "text": " And then I'm going to change the image I'm looking for instead of a network check coffee",
      "tokens": [
        50510,
        400,
        550,
        286,
        478,
        516,
        281,
        1319,
        264,
        3256,
        286,
        478,
        1237,
        337,
        2602,
        295,
        257,
        3209,
        1520,
        4982,
        50662
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2224872536855201,
      "compression_ratio": 1.6622073578595318,
      "no_speech_prob": 0.004161294084042311
    },
    {
      "id": 630,
      "seek": 144916,
      "start": 1455.1200000000001,
      "end": 1460.8400000000001,
      "text": " slash NC coffee, colon, pour over the new label I'm going to use is vac pot.",
      "tokens": [
        50662,
        17330,
        20786,
        4982,
        11,
        8255,
        11,
        2016,
        670,
        264,
        777,
        7645,
        286,
        478,
        516,
        281,
        764,
        307,
        2842,
        1847,
        13,
        50948
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2224872536855201,
      "compression_ratio": 1.6622073578595318,
      "no_speech_prob": 0.004161294084042311
    },
    {
      "id": 631,
      "seek": 144916,
      "start": 1460.8400000000001,
      "end": 1461.8400000000001,
      "text": " That's our latest version.",
      "tokens": [
        50948,
        663,
        311,
        527,
        6792,
        3037,
        13,
        50998
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2224872536855201,
      "compression_ratio": 1.6622073578595318,
      "no_speech_prob": 0.004161294084042311
    },
    {
      "id": 632,
      "seek": 144916,
      "start": 1461.8400000000001,
      "end": 1465.2,
      "text": " So I'm changing the images going to pull from if you want to follow along, you can do this",
      "tokens": [
        50998,
        407,
        286,
        478,
        4473,
        264,
        5267,
        516,
        281,
        2235,
        490,
        498,
        291,
        528,
        281,
        1524,
        2051,
        11,
        291,
        393,
        360,
        341,
        51166
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2224872536855201,
      "compression_ratio": 1.6622073578595318,
      "no_speech_prob": 0.004161294084042311
    },
    {
      "id": 633,
      "seek": 144916,
      "start": 1465.2,
      "end": 1466.8000000000002,
      "text": " same thing right now.",
      "tokens": [
        51166,
        912,
        551,
        558,
        586,
        13,
        51246
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2224872536855201,
      "compression_ratio": 1.6622073578595318,
      "no_speech_prob": 0.004161294084042311
    },
    {
      "id": 634,
      "seek": 144916,
      "start": 1466.8000000000002,
      "end": 1472.52,
      "text": " I'm going to hit escape colon WQ to write and quit and hit enter.",
      "tokens": [
        51246,
        286,
        478,
        516,
        281,
        2045,
        7615,
        8255,
        343,
        48,
        281,
        2464,
        293,
        10366,
        293,
        2045,
        3242,
        13,
        51532
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2224872536855201,
      "compression_ratio": 1.6622073578595318,
      "no_speech_prob": 0.004161294084042311
    },
    {
      "id": 635,
      "seek": 144916,
      "start": 1472.52,
      "end": 1473.52,
      "text": " It's been updated.",
      "tokens": [
        51532,
        467,
        311,
        668,
        10588,
        13,
        51582
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2224872536855201,
      "compression_ratio": 1.6622073578595318,
      "no_speech_prob": 0.004161294084042311
    },
    {
      "id": 636,
      "seek": 144916,
      "start": 1473.52,
      "end": 1474.52,
      "text": " It's been edited.",
      "tokens": [
        51582,
        467,
        311,
        668,
        23016,
        13,
        51632
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2224872536855201,
      "compression_ratio": 1.6622073578595318,
      "no_speech_prob": 0.004161294084042311
    },
    {
      "id": 637,
      "seek": 144916,
      "start": 1474.52,
      "end": 1478.92,
      "text": " And what should be happening now is if I do cube CTL, get pods.",
      "tokens": [
        51632,
        400,
        437,
        820,
        312,
        2737,
        586,
        307,
        498,
        286,
        360,
        13728,
        19529,
        43,
        11,
        483,
        31925,
        13,
        51852
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2224872536855201,
      "compression_ratio": 1.6622073578595318,
      "no_speech_prob": 0.004161294084042311
    },
    {
      "id": 638,
      "seek": 147892,
      "start": 1478.92,
      "end": 1481.0,
      "text": " I should have a bunch of new pods.",
      "tokens": [
        50364,
        286,
        820,
        362,
        257,
        3840,
        295,
        777,
        31925,
        13,
        50468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1912048790189955,
      "compression_ratio": 1.7116788321167884,
      "no_speech_prob": 0.0029492743778973818
    },
    {
      "id": 639,
      "seek": 147892,
      "start": 1481.0,
      "end": 1485.16,
      "text": " Now see it's creating some new ones and terminating old ones because it's updating the existing",
      "tokens": [
        50468,
        823,
        536,
        309,
        311,
        4084,
        512,
        777,
        2306,
        293,
        1433,
        8205,
        1331,
        2306,
        570,
        309,
        311,
        25113,
        264,
        6741,
        50676
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1912048790189955,
      "compression_ratio": 1.7116788321167884,
      "no_speech_prob": 0.0029492743778973818
    },
    {
      "id": 640,
      "seek": 147892,
      "start": 1485.16,
      "end": 1486.16,
      "text": " ones.",
      "tokens": [
        50676,
        2306,
        13,
        50726
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1912048790189955,
      "compression_ratio": 1.7116788321167884,
      "no_speech_prob": 0.0029492743778973818
    },
    {
      "id": 641,
      "seek": 147892,
      "start": 1486.16,
      "end": 1487.16,
      "text": " And now just like that.",
      "tokens": [
        50726,
        400,
        586,
        445,
        411,
        300,
        13,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1912048790189955,
      "compression_ratio": 1.7116788321167884,
      "no_speech_prob": 0.0029492743778973818
    },
    {
      "id": 642,
      "seek": 147892,
      "start": 1487.16,
      "end": 1488.16,
      "text": " Look at that.",
      "tokens": [
        50776,
        2053,
        412,
        300,
        13,
        50826
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1912048790189955,
      "compression_ratio": 1.7116788321167884,
      "no_speech_prob": 0.0029492743778973818
    },
    {
      "id": 643,
      "seek": 147892,
      "start": 1488.16,
      "end": 1489.2,
      "text": " It's so crazy.",
      "tokens": [
        50826,
        467,
        311,
        370,
        3219,
        13,
        50878
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1912048790189955,
      "compression_ratio": 1.7116788321167884,
      "no_speech_prob": 0.0029492743778973818
    },
    {
      "id": 644,
      "seek": 147892,
      "start": 1489.2,
      "end": 1490.76,
      "text": " So now we have 20 pods.",
      "tokens": [
        50878,
        407,
        586,
        321,
        362,
        945,
        31925,
        13,
        50956
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1912048790189955,
      "compression_ratio": 1.7116788321167884,
      "no_speech_prob": 0.0029492743778973818
    },
    {
      "id": 645,
      "seek": 147892,
      "start": 1490.76,
      "end": 1494.0800000000002,
      "text": " The 10 we already had or updated.",
      "tokens": [
        50956,
        440,
        1266,
        321,
        1217,
        632,
        420,
        10588,
        13,
        51122
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1912048790189955,
      "compression_ratio": 1.7116788321167884,
      "no_speech_prob": 0.0029492743778973818
    },
    {
      "id": 646,
      "seek": 147892,
      "start": 1494.0800000000002,
      "end": 1496.0800000000002,
      "text": " They were killed, brought down, terminated.",
      "tokens": [
        51122,
        814,
        645,
        4652,
        11,
        3038,
        760,
        11,
        1433,
        5410,
        13,
        51222
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1912048790189955,
      "compression_ratio": 1.7116788321167884,
      "no_speech_prob": 0.0029492743778973818
    },
    {
      "id": 647,
      "seek": 147892,
      "start": 1496.0800000000002,
      "end": 1497.16,
      "text": " You're fired.",
      "tokens": [
        51222,
        509,
        434,
        11777,
        13,
        51276
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1912048790189955,
      "compression_ratio": 1.7116788321167884,
      "no_speech_prob": 0.0029492743778973818
    },
    {
      "id": 648,
      "seek": 147892,
      "start": 1497.16,
      "end": 1499.8000000000002,
      "text": " And we created 10 new ones with that new image.",
      "tokens": [
        51276,
        400,
        321,
        2942,
        1266,
        777,
        2306,
        365,
        300,
        777,
        3256,
        13,
        51408
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1912048790189955,
      "compression_ratio": 1.7116788321167884,
      "no_speech_prob": 0.0029492743778973818
    },
    {
      "id": 649,
      "seek": 147892,
      "start": 1499.8000000000002,
      "end": 1502.3600000000001,
      "text": " And then we added 10 more with that new image.",
      "tokens": [
        51408,
        400,
        550,
        321,
        3869,
        1266,
        544,
        365,
        300,
        777,
        3256,
        13,
        51536
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1912048790189955,
      "compression_ratio": 1.7116788321167884,
      "no_speech_prob": 0.0029492743778973818
    },
    {
      "id": 650,
      "seek": 147892,
      "start": 1502.3600000000001,
      "end": 1507.6000000000001,
      "text": " And if we look at our load balancer, if I do cube CTL, get services.",
      "tokens": [
        51536,
        400,
        498,
        321,
        574,
        412,
        527,
        3677,
        3119,
        28347,
        11,
        498,
        286,
        360,
        13728,
        19529,
        43,
        11,
        483,
        3328,
        13,
        51798
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1912048790189955,
      "compression_ratio": 1.7116788321167884,
      "no_speech_prob": 0.0029492743778973818
    },
    {
      "id": 651,
      "seek": 150760,
      "start": 1507.6,
      "end": 1508.8,
      "text": " And I look at my load balancer again.",
      "tokens": [
        50364,
        400,
        286,
        574,
        412,
        452,
        3677,
        3119,
        28347,
        797,
        13,
        50424
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18170887231826782,
      "compression_ratio": 1.5770609318996416,
      "no_speech_prob": 0.05192383751273155
    },
    {
      "id": 652,
      "seek": 150760,
      "start": 1508.8,
      "end": 1517.52,
      "text": " So I do cube CTL, describe services, coffee dash service.",
      "tokens": [
        50424,
        407,
        286,
        360,
        13728,
        19529,
        43,
        11,
        6786,
        3328,
        11,
        4982,
        8240,
        2643,
        13,
        50860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18170887231826782,
      "compression_ratio": 1.5770609318996416,
      "no_speech_prob": 0.05192383751273155
    },
    {
      "id": 653,
      "seek": 150760,
      "start": 1517.52,
      "end": 1518.52,
      "text": " Look at that.",
      "tokens": [
        50860,
        2053,
        412,
        300,
        13,
        50910
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18170887231826782,
      "compression_ratio": 1.5770609318996416,
      "no_speech_prob": 0.05192383751273155
    },
    {
      "id": 654,
      "seek": 150760,
      "start": 1518.52,
      "end": 1523.12,
      "text": " My endpoints, it's automatically load balancing between the 20.",
      "tokens": [
        50910,
        1222,
        917,
        20552,
        11,
        309,
        311,
        6772,
        3677,
        22495,
        1296,
        264,
        945,
        13,
        51140
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18170887231826782,
      "compression_ratio": 1.5770609318996416,
      "no_speech_prob": 0.05192383751273155
    },
    {
      "id": 655,
      "seek": 150760,
      "start": 1523.12,
      "end": 1524.12,
      "text": " That's powerful.",
      "tokens": [
        51140,
        663,
        311,
        4005,
        13,
        51190
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18170887231826782,
      "compression_ratio": 1.5770609318996416,
      "no_speech_prob": 0.05192383751273155
    },
    {
      "id": 656,
      "seek": 150760,
      "start": 1524.12,
      "end": 1525.8,
      "text": " I save myself a lot of time now.",
      "tokens": [
        51190,
        286,
        3155,
        2059,
        257,
        688,
        295,
        565,
        586,
        13,
        51274
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18170887231826782,
      "compression_ratio": 1.5770609318996416,
      "no_speech_prob": 0.05192383751273155
    },
    {
      "id": 657,
      "seek": 150760,
      "start": 1525.8,
      "end": 1530.36,
      "text": " When I update my website, I update it in one place, my Docker image.",
      "tokens": [
        51274,
        1133,
        286,
        5623,
        452,
        3144,
        11,
        286,
        5623,
        309,
        294,
        472,
        1081,
        11,
        452,
        33772,
        3256,
        13,
        51502
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18170887231826782,
      "compression_ratio": 1.5770609318996416,
      "no_speech_prob": 0.05192383751273155
    },
    {
      "id": 658,
      "seek": 150760,
      "start": 1530.36,
      "end": 1533.76,
      "text": " And then I just update my manifest file and the rest is history.",
      "tokens": [
        51502,
        400,
        550,
        286,
        445,
        5623,
        452,
        10067,
        3991,
        293,
        264,
        1472,
        307,
        2503,
        13,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18170887231826782,
      "compression_ratio": 1.5770609318996416,
      "no_speech_prob": 0.05192383751273155
    },
    {
      "id": 659,
      "seek": 150760,
      "start": 1533.76,
      "end": 1535.24,
      "text": " How great, how amazing is that?",
      "tokens": [
        51672,
        1012,
        869,
        11,
        577,
        2243,
        307,
        300,
        30,
        51746
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18170887231826782,
      "compression_ratio": 1.5770609318996416,
      "no_speech_prob": 0.05192383751273155
    },
    {
      "id": 660,
      "seek": 150760,
      "start": 1535.24,
      "end": 1536.6,
      "text": " Let's see if the website works though, by the way.",
      "tokens": [
        51746,
        961,
        311,
        536,
        498,
        264,
        3144,
        1985,
        1673,
        11,
        538,
        264,
        636,
        13,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18170887231826782,
      "compression_ratio": 1.5770609318996416,
      "no_speech_prob": 0.05192383751273155
    },
    {
      "id": 661,
      "seek": 153660,
      "start": 1536.6,
      "end": 1540.1599999999999,
      "text": " Let's see if our Peru decaf has been added.",
      "tokens": [
        50364,
        961,
        311,
        536,
        498,
        527,
        31571,
        368,
        496,
        69,
        575,
        668,
        3869,
        13,
        50542
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15748639223052235,
      "compression_ratio": 1.6686567164179105,
      "no_speech_prob": 0.01209634356200695
    },
    {
      "id": 662,
      "seek": 153660,
      "start": 1540.1599999999999,
      "end": 1541.76,
      "text": " So I'll just refresh this page.",
      "tokens": [
        50542,
        407,
        286,
        603,
        445,
        15134,
        341,
        3028,
        13,
        50622
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15748639223052235,
      "compression_ratio": 1.6686567164179105,
      "no_speech_prob": 0.01209634356200695
    },
    {
      "id": 663,
      "seek": 153660,
      "start": 1541.76,
      "end": 1542.76,
      "text": " There it is.",
      "tokens": [
        50622,
        821,
        309,
        307,
        13,
        50672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15748639223052235,
      "compression_ratio": 1.6686567164179105,
      "no_speech_prob": 0.01209634356200695
    },
    {
      "id": 664,
      "seek": 153660,
      "start": 1542.76,
      "end": 1543.76,
      "text": " There it is.",
      "tokens": [
        50672,
        821,
        309,
        307,
        13,
        50722
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15748639223052235,
      "compression_ratio": 1.6686567164179105,
      "no_speech_prob": 0.01209634356200695
    },
    {
      "id": 665,
      "seek": 153660,
      "start": 1543.76,
      "end": 1544.76,
      "text": " Oh my gosh.",
      "tokens": [
        50722,
        876,
        452,
        6502,
        13,
        50772
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15748639223052235,
      "compression_ratio": 1.6686567164179105,
      "no_speech_prob": 0.01209634356200695
    },
    {
      "id": 666,
      "seek": 153660,
      "start": 1544.76,
      "end": 1545.76,
      "text": " How exciting is that?",
      "tokens": [
        50772,
        1012,
        4670,
        307,
        300,
        30,
        50822
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15748639223052235,
      "compression_ratio": 1.6686567164179105,
      "no_speech_prob": 0.01209634356200695
    },
    {
      "id": 667,
      "seek": 153660,
      "start": 1545.76,
      "end": 1549.6799999999998,
      "text": " Kubernetes, truly container orchestration, container automation.",
      "tokens": [
        50822,
        23145,
        11,
        4908,
        10129,
        14161,
        2405,
        11,
        10129,
        17769,
        13,
        51018
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15748639223052235,
      "compression_ratio": 1.6686567164179105,
      "no_speech_prob": 0.01209634356200695
    },
    {
      "id": 668,
      "seek": 153660,
      "start": 1549.6799999999998,
      "end": 1553.08,
      "text": " Now I just scratched the stinking surface with Kubernetes.",
      "tokens": [
        51018,
        823,
        286,
        445,
        40513,
        264,
        342,
        12408,
        3753,
        365,
        23145,
        13,
        51188
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15748639223052235,
      "compression_ratio": 1.6686567164179105,
      "no_speech_prob": 0.01209634356200695
    },
    {
      "id": 669,
      "seek": 153660,
      "start": 1553.08,
      "end": 1555.12,
      "text": " So much I glossed over and so much you can do.",
      "tokens": [
        51188,
        407,
        709,
        286,
        19574,
        292,
        670,
        293,
        370,
        709,
        291,
        393,
        360,
        13,
        51290
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15748639223052235,
      "compression_ratio": 1.6686567164179105,
      "no_speech_prob": 0.01209634356200695
    },
    {
      "id": 670,
      "seek": 153660,
      "start": 1555.12,
      "end": 1558.9199999999998,
      "text": " If you want to dive deeper, it's right here in your website.",
      "tokens": [
        51290,
        759,
        291,
        528,
        281,
        9192,
        7731,
        11,
        309,
        311,
        558,
        510,
        294,
        428,
        3144,
        13,
        51480
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15748639223052235,
      "compression_ratio": 1.6686567164179105,
      "no_speech_prob": 0.01209634356200695
    },
    {
      "id": 671,
      "seek": 153660,
      "start": 1558.9199999999998,
      "end": 1561.08,
      "text": " First of all, if you don't know what a Docker container is, go watch my video.",
      "tokens": [
        51480,
        2386,
        295,
        439,
        11,
        498,
        291,
        500,
        380,
        458,
        437,
        257,
        33772,
        10129,
        307,
        11,
        352,
        1159,
        452,
        960,
        13,
        51588
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15748639223052235,
      "compression_ratio": 1.6686567164179105,
      "no_speech_prob": 0.01209634356200695
    },
    {
      "id": 672,
      "seek": 153660,
      "start": 1561.08,
      "end": 1562.08,
      "text": " That's a link to that.",
      "tokens": [
        51588,
        663,
        311,
        257,
        2113,
        281,
        300,
        13,
        51638
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15748639223052235,
      "compression_ratio": 1.6686567164179105,
      "no_speech_prob": 0.01209634356200695
    },
    {
      "id": 673,
      "seek": 153660,
      "start": 1562.08,
      "end": 1566.4399999999998,
      "text": " What I used to go a bit deeper with Kubernetes is first this Pluralsight course by Nigel,",
      "tokens": [
        51638,
        708,
        286,
        1143,
        281,
        352,
        257,
        857,
        7731,
        365,
        23145,
        307,
        700,
        341,
        2149,
        374,
        1124,
        397,
        1164,
        538,
        39554,
        338,
        11,
        51856
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15748639223052235,
      "compression_ratio": 1.6686567164179105,
      "no_speech_prob": 0.01209634356200695
    },
    {
      "id": 674,
      "seek": 156644,
      "start": 1566.44,
      "end": 1568.48,
      "text": " Trevor's name is great.",
      "tokens": [
        50364,
        26245,
        311,
        1315,
        307,
        869,
        13,
        50466
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20186363617119762,
      "compression_ratio": 1.7478510028653296,
      "no_speech_prob": 0.16436152160167694
    },
    {
      "id": 675,
      "seek": 156644,
      "start": 1568.48,
      "end": 1569.48,
      "text": " Fantastic.",
      "tokens": [
        50466,
        21320,
        13,
        50516
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20186363617119762,
      "compression_ratio": 1.7478510028653296,
      "no_speech_prob": 0.16436152160167694
    },
    {
      "id": 676,
      "seek": 156644,
      "start": 1569.48,
      "end": 1570.48,
      "text": " Check that out.",
      "tokens": [
        50516,
        6881,
        300,
        484,
        13,
        50566
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20186363617119762,
      "compression_ratio": 1.7478510028653296,
      "no_speech_prob": 0.16436152160167694
    },
    {
      "id": 677,
      "seek": 156644,
      "start": 1570.48,
      "end": 1572.0800000000002,
      "text": " And then a book called Kubernetes in Action.",
      "tokens": [
        50566,
        400,
        550,
        257,
        1446,
        1219,
        23145,
        294,
        16261,
        13,
        50646
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20186363617119762,
      "compression_ratio": 1.7478510028653296,
      "no_speech_prob": 0.16436152160167694
    },
    {
      "id": 678,
      "seek": 156644,
      "start": 1572.0800000000002,
      "end": 1574.68,
      "text": " It is insanely detailed and amazing.",
      "tokens": [
        50646,
        467,
        307,
        40965,
        9942,
        293,
        2243,
        13,
        50776
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20186363617119762,
      "compression_ratio": 1.7478510028653296,
      "no_speech_prob": 0.16436152160167694
    },
    {
      "id": 679,
      "seek": 156644,
      "start": 1574.68,
      "end": 1575.68,
      "text": " Go check that out.",
      "tokens": [
        50776,
        1037,
        1520,
        300,
        484,
        13,
        50826
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20186363617119762,
      "compression_ratio": 1.7478510028653296,
      "no_speech_prob": 0.16436152160167694
    },
    {
      "id": 680,
      "seek": 156644,
      "start": 1575.68,
      "end": 1579.76,
      "text": " And of course, if you want to support more of what I'm doing, go check out this is IT",
      "tokens": [
        50826,
        400,
        295,
        1164,
        11,
        498,
        291,
        528,
        281,
        1406,
        544,
        295,
        437,
        286,
        478,
        884,
        11,
        352,
        1520,
        484,
        341,
        307,
        6783,
        51030
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20186363617119762,
      "compression_ratio": 1.7478510028653296,
      "no_speech_prob": 0.16436152160167694
    },
    {
      "id": 681,
      "seek": 156644,
      "start": 1579.76,
      "end": 1580.76,
      "text": " and support the mission.",
      "tokens": [
        51030,
        293,
        1406,
        264,
        4447,
        13,
        51080
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20186363617119762,
      "compression_ratio": 1.7478510028653296,
      "no_speech_prob": 0.16436152160167694
    },
    {
      "id": 682,
      "seek": 156644,
      "start": 1580.76,
      "end": 1583.48,
      "text": " Now, if you haven't already, you can do this live yourself.",
      "tokens": [
        51080,
        823,
        11,
        498,
        291,
        2378,
        380,
        1217,
        11,
        291,
        393,
        360,
        341,
        1621,
        1803,
        13,
        51216
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20186363617119762,
      "compression_ratio": 1.7478510028653296,
      "no_speech_prob": 0.16436152160167694
    },
    {
      "id": 683,
      "seek": 156644,
      "start": 1583.48,
      "end": 1584.88,
      "text": " Go sign up for a free account with Lenoade.",
      "tokens": [
        51216,
        1037,
        1465,
        493,
        337,
        257,
        1737,
        2696,
        365,
        45661,
        762,
        13,
        51286
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20186363617119762,
      "compression_ratio": 1.7478510028653296,
      "no_speech_prob": 0.16436152160167694
    },
    {
      "id": 684,
      "seek": 156644,
      "start": 1584.88,
      "end": 1588.52,
      "text": " You get $100 of credit just to play with and use and you can do this.",
      "tokens": [
        51286,
        509,
        483,
        1848,
        6879,
        295,
        5397,
        445,
        281,
        862,
        365,
        293,
        764,
        293,
        291,
        393,
        360,
        341,
        13,
        51468
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20186363617119762,
      "compression_ratio": 1.7478510028653296,
      "no_speech_prob": 0.16436152160167694
    },
    {
      "id": 685,
      "seek": 156644,
      "start": 1588.52,
      "end": 1589.52,
      "text": " So check it out.",
      "tokens": [
        51468,
        407,
        1520,
        309,
        484,
        13,
        51518
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20186363617119762,
      "compression_ratio": 1.7478510028653296,
      "no_speech_prob": 0.16436152160167694
    },
    {
      "id": 686,
      "seek": 156644,
      "start": 1589.52,
      "end": 1592.44,
      "text": " Link below and thanks to Lenoade for doing that and for sponsoring this video.",
      "tokens": [
        51518,
        8466,
        2507,
        293,
        3231,
        281,
        45661,
        762,
        337,
        884,
        300,
        293,
        337,
        30311,
        341,
        960,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20186363617119762,
      "compression_ratio": 1.7478510028653296,
      "no_speech_prob": 0.16436152160167694
    },
    {
      "id": 687,
      "seek": 156644,
      "start": 1592.44,
      "end": 1596.3600000000001,
      "text": " Now real quick, if you did it already, make sure you clean up after yourself.",
      "tokens": [
        51664,
        823,
        957,
        1702,
        11,
        498,
        291,
        630,
        309,
        1217,
        11,
        652,
        988,
        291,
        2541,
        493,
        934,
        1803,
        13,
        51860
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20186363617119762,
      "compression_ratio": 1.7478510028653296,
      "no_speech_prob": 0.16436152160167694
    },
    {
      "id": 688,
      "seek": 159636,
      "start": 1596.36,
      "end": 1599.9599999999998,
      "text": " And what I mean is you don't want to leave this running open-ended because you'll see",
      "tokens": [
        50364,
        400,
        437,
        286,
        914,
        307,
        291,
        500,
        380,
        528,
        281,
        1856,
        341,
        2614,
        1269,
        12,
        3502,
        570,
        291,
        603,
        536,
        50544
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1811346424569329,
      "compression_ratio": 1.7077464788732395,
      "no_speech_prob": 0.11408273875713348
    },
    {
      "id": 689,
      "seek": 159636,
      "start": 1599.9599999999998,
      "end": 1602.24,
      "text": " a bill if you leave it going forever.",
      "tokens": [
        50544,
        257,
        2961,
        498,
        291,
        1856,
        309,
        516,
        5680,
        13,
        50658
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1811346424569329,
      "compression_ratio": 1.7077464788732395,
      "no_speech_prob": 0.11408273875713348
    },
    {
      "id": 690,
      "seek": 159636,
      "start": 1602.24,
      "end": 1608.3999999999999,
      "text": " So what I would do is once you're done playing, get to your Lenoade dashboard, go to the Kubernetes",
      "tokens": [
        50658,
        407,
        437,
        286,
        576,
        360,
        307,
        1564,
        291,
        434,
        1096,
        2433,
        11,
        483,
        281,
        428,
        45661,
        762,
        18342,
        11,
        352,
        281,
        264,
        23145,
        50966
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1811346424569329,
      "compression_ratio": 1.7077464788732395,
      "no_speech_prob": 0.11408273875713348
    },
    {
      "id": 691,
      "seek": 159636,
      "start": 1608.3999999999999,
      "end": 1615.7199999999998,
      "text": " cluster and you can click your little dots here at the bottom right and say delete.",
      "tokens": [
        50966,
        13630,
        293,
        291,
        393,
        2052,
        428,
        707,
        15026,
        510,
        412,
        264,
        2767,
        558,
        293,
        584,
        12097,
        13,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1811346424569329,
      "compression_ratio": 1.7077464788732395,
      "no_speech_prob": 0.11408273875713348
    },
    {
      "id": 692,
      "seek": 159636,
      "start": 1615.7199999999998,
      "end": 1616.7199999999998,
      "text": " You'll see, are you sure?",
      "tokens": [
        51332,
        509,
        603,
        536,
        11,
        366,
        291,
        988,
        30,
        51382
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1811346424569329,
      "compression_ratio": 1.7077464788732395,
      "no_speech_prob": 0.11408273875713348
    },
    {
      "id": 693,
      "seek": 159636,
      "start": 1616.7199999999998,
      "end": 1618.04,
      "text": " You really want to do this?",
      "tokens": [
        51382,
        509,
        534,
        528,
        281,
        360,
        341,
        30,
        51448
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1811346424569329,
      "compression_ratio": 1.7077464788732395,
      "no_speech_prob": 0.11408273875713348
    },
    {
      "id": 694,
      "seek": 159636,
      "start": 1618.04,
      "end": 1619.28,
      "text": " And yeah, I do.",
      "tokens": [
        51448,
        400,
        1338,
        11,
        286,
        360,
        13,
        51510
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1811346424569329,
      "compression_ratio": 1.7077464788732395,
      "no_speech_prob": 0.11408273875713348
    },
    {
      "id": 695,
      "seek": 159636,
      "start": 1619.28,
      "end": 1623.8,
      "text": " So just put your cluster name in there, network.coffee and click on delete.",
      "tokens": [
        51510,
        407,
        445,
        829,
        428,
        13630,
        1315,
        294,
        456,
        11,
        3209,
        13,
        1291,
        4617,
        293,
        2052,
        322,
        12097,
        13,
        51736
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1811346424569329,
      "compression_ratio": 1.7077464788732395,
      "no_speech_prob": 0.11408273875713348
    },
    {
      "id": 696,
      "seek": 159636,
      "start": 1623.8,
      "end": 1624.8799999999999,
      "text": " And it goes away.",
      "tokens": [
        51736,
        400,
        309,
        1709,
        1314,
        13,
        51790
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1811346424569329,
      "compression_ratio": 1.7077464788732395,
      "no_speech_prob": 0.11408273875713348
    },
    {
      "id": 697,
      "seek": 159636,
      "start": 1624.8799999999999,
      "end": 1625.8799999999999,
      "text": " It goes away.",
      "tokens": [
        51790,
        467,
        1709,
        1314,
        13,
        51840
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1811346424569329,
      "compression_ratio": 1.7077464788732395,
      "no_speech_prob": 0.11408273875713348
    },
    {
      "id": 698,
      "seek": 162588,
      "start": 1625.92,
      "end": 1627.44,
      "text": " And then it will cost you money being charged to you.",
      "tokens": [
        50366,
        400,
        550,
        309,
        486,
        2063,
        291,
        1460,
        885,
        11109,
        281,
        291,
        13,
        50442
      ],
      "temperature": 0.6,
      "avg_logprob": -0.25007894179400275,
      "compression_ratio": 1.8352941176470587,
      "no_speech_prob": 0.16185042262077332
    },
    {
      "id": 699,
      "seek": 162588,
      "start": 1627.44,
      "end": 1630.68,
      "text": " And then also don't forget about the node balancers that will not go away by itself,",
      "tokens": [
        50442,
        400,
        550,
        611,
        500,
        380,
        2870,
        466,
        264,
        9984,
        3119,
        4463,
        433,
        300,
        486,
        406,
        352,
        1314,
        538,
        2564,
        11,
        50604
      ],
      "temperature": 0.6,
      "avg_logprob": -0.25007894179400275,
      "compression_ratio": 1.8352941176470587,
      "no_speech_prob": 0.16185042262077332
    },
    {
      "id": 700,
      "seek": 162588,
      "start": 1630.68,
      "end": 1631.68,
      "text": " I don't believe.",
      "tokens": [
        50604,
        286,
        500,
        380,
        1697,
        13,
        50654
      ],
      "temperature": 0.6,
      "avg_logprob": -0.25007894179400275,
      "compression_ratio": 1.8352941176470587,
      "no_speech_prob": 0.16185042262077332
    },
    {
      "id": 701,
      "seek": 162588,
      "start": 1631.68,
      "end": 1636.44,
      "text": " So if you go to the left panel here, go to node balancers.",
      "tokens": [
        50654,
        407,
        498,
        291,
        352,
        281,
        264,
        1411,
        4831,
        510,
        11,
        352,
        281,
        9984,
        3119,
        4463,
        433,
        13,
        50892
      ],
      "temperature": 0.6,
      "avg_logprob": -0.25007894179400275,
      "compression_ratio": 1.8352941176470587,
      "no_speech_prob": 0.16185042262077332
    },
    {
      "id": 702,
      "seek": 162588,
      "start": 1636.44,
      "end": 1638.2600000000002,
      "text": " There's the one you should have there.",
      "tokens": [
        50892,
        821,
        311,
        264,
        472,
        291,
        820,
        362,
        456,
        13,
        50983
      ],
      "temperature": 0.6,
      "avg_logprob": -0.25007894179400275,
      "compression_ratio": 1.8352941176470587,
      "no_speech_prob": 0.16185042262077332
    },
    {
      "id": 703,
      "seek": 162588,
      "start": 1638.2600000000002,
      "end": 1639.2600000000002,
      "text": " Same thing.",
      "tokens": [
        50983,
        10635,
        551,
        13,
        51033
      ],
      "temperature": 0.6,
      "avg_logprob": -0.25007894179400275,
      "compression_ratio": 1.8352941176470587,
      "no_speech_prob": 0.16185042262077332
    },
    {
      "id": 704,
      "seek": 162588,
      "start": 1639.2600000000002,
      "end": 1641.2600000000002,
      "text": " Click on the dots and click delete and it goes away.",
      "tokens": [
        51033,
        8230,
        322,
        264,
        15026,
        293,
        2052,
        12097,
        293,
        309,
        1709,
        1314,
        13,
        51133
      ],
      "temperature": 0.6,
      "avg_logprob": -0.25007894179400275,
      "compression_ratio": 1.8352941176470587,
      "no_speech_prob": 0.16185042262077332
    },
    {
      "id": 705,
      "seek": 162588,
      "start": 1641.2600000000002,
      "end": 1642.92,
      "text": " That node balancer also does cost money.",
      "tokens": [
        51133,
        663,
        9984,
        3119,
        28347,
        611,
        775,
        2063,
        1460,
        13,
        51216
      ],
      "temperature": 0.6,
      "avg_logprob": -0.25007894179400275,
      "compression_ratio": 1.8352941176470587,
      "no_speech_prob": 0.16185042262077332
    },
    {
      "id": 706,
      "seek": 162588,
      "start": 1642.92,
      "end": 1645.0800000000002,
      "text": " I think it's about $10 a month as well.",
      "tokens": [
        51216,
        286,
        519,
        309,
        311,
        466,
        1848,
        3279,
        257,
        1618,
        382,
        731,
        13,
        51324
      ],
      "temperature": 0.6,
      "avg_logprob": -0.25007894179400275,
      "compression_ratio": 1.8352941176470587,
      "no_speech_prob": 0.16185042262077332
    },
    {
      "id": 707,
      "seek": 162588,
      "start": 1645.0800000000002,
      "end": 1646.5800000000002,
      "text": " And that's Kubernetes.",
      "tokens": [
        51324,
        400,
        300,
        311,
        23145,
        13,
        51399
      ],
      "temperature": 0.6,
      "avg_logprob": -0.25007894179400275,
      "compression_ratio": 1.8352941176470587,
      "no_speech_prob": 0.16185042262077332
    },
    {
      "id": 708,
      "seek": 162588,
      "start": 1646.5800000000002,
      "end": 1650.3600000000001,
      "text": " It's kind of an intense thing to learn because you already have to know about Docker containers",
      "tokens": [
        51399,
        467,
        311,
        733,
        295,
        364,
        9447,
        551,
        281,
        1466,
        570,
        291,
        1217,
        362,
        281,
        458,
        466,
        33772,
        17089,
        51588
      ],
      "temperature": 0.6,
      "avg_logprob": -0.25007894179400275,
      "compression_ratio": 1.8352941176470587,
      "no_speech_prob": 0.16185042262077332
    },
    {
      "id": 709,
      "seek": 162588,
      "start": 1650.3600000000001,
      "end": 1654.72,
      "text": " and then you build on that knowledge by learning about the container orchestration, which is",
      "tokens": [
        51588,
        293,
        550,
        291,
        1322,
        322,
        300,
        3601,
        538,
        2539,
        466,
        264,
        10129,
        14161,
        2405,
        11,
        597,
        307,
        51806
      ],
      "temperature": 0.6,
      "avg_logprob": -0.25007894179400275,
      "compression_ratio": 1.8352941176470587,
      "no_speech_prob": 0.16185042262077332
    },
    {
      "id": 710,
      "seek": 162588,
      "start": 1654.72,
      "end": 1655.72,
      "text": " really cool.",
      "tokens": [
        51806,
        534,
        1627,
        13,
        51856
      ],
      "temperature": 0.6,
      "avg_logprob": -0.25007894179400275,
      "compression_ratio": 1.8352941176470587,
      "no_speech_prob": 0.16185042262077332
    },
    {
      "id": 711,
      "seek": 165572,
      "start": 1655.72,
      "end": 1657.32,
      "text": " But it can be very complex.",
      "tokens": [
        50364,
        583,
        309,
        393,
        312,
        588,
        3997,
        13,
        50444
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19091414125173684,
      "compression_ratio": 1.812883435582822,
      "no_speech_prob": 0.4198133051395416
    },
    {
      "id": 712,
      "seek": 165572,
      "start": 1657.32,
      "end": 1661.24,
      "text": " Now if you want to play with Kubernetes more, of course you can do that in the cloud.",
      "tokens": [
        50444,
        823,
        498,
        291,
        528,
        281,
        862,
        365,
        23145,
        544,
        11,
        295,
        1164,
        291,
        393,
        360,
        300,
        294,
        264,
        4588,
        13,
        50640
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19091414125173684,
      "compression_ratio": 1.812883435582822,
      "no_speech_prob": 0.4198133051395416
    },
    {
      "id": 713,
      "seek": 165572,
      "start": 1661.24,
      "end": 1664.58,
      "text": " Most cloud providers have Kubernetes built in.",
      "tokens": [
        50640,
        4534,
        4588,
        11330,
        362,
        23145,
        3094,
        294,
        13,
        50807
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19091414125173684,
      "compression_ratio": 1.812883435582822,
      "no_speech_prob": 0.4198133051395416
    },
    {
      "id": 714,
      "seek": 165572,
      "start": 1664.58,
      "end": 1667.64,
      "text": " That's one of the reasons you should learn Kubernetes because it makes you more valuable",
      "tokens": [
        50807,
        663,
        311,
        472,
        295,
        264,
        4112,
        291,
        820,
        1466,
        23145,
        570,
        309,
        1669,
        291,
        544,
        8263,
        50960
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19091414125173684,
      "compression_ratio": 1.812883435582822,
      "no_speech_prob": 0.4198133051395416
    },
    {
      "id": 715,
      "seek": 165572,
      "start": 1667.64,
      "end": 1669.32,
      "text": " when you're going down that cloud path.",
      "tokens": [
        50960,
        562,
        291,
        434,
        516,
        760,
        300,
        4588,
        3100,
        13,
        51044
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19091414125173684,
      "compression_ratio": 1.812883435582822,
      "no_speech_prob": 0.4198133051395416
    },
    {
      "id": 716,
      "seek": 165572,
      "start": 1669.32,
      "end": 1674.08,
      "text": " If you know how to operate and use Kubernetes, valuable skill.",
      "tokens": [
        51044,
        759,
        291,
        458,
        577,
        281,
        9651,
        293,
        764,
        23145,
        11,
        8263,
        5389,
        13,
        51282
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19091414125173684,
      "compression_ratio": 1.812883435582822,
      "no_speech_prob": 0.4198133051395416
    },
    {
      "id": 717,
      "seek": 165572,
      "start": 1674.08,
      "end": 1678.52,
      "text": " But as far as having your own lab, you can run Kubernetes in your own lab on bare metal",
      "tokens": [
        51282,
        583,
        382,
        1400,
        382,
        1419,
        428,
        1065,
        2715,
        11,
        291,
        393,
        1190,
        23145,
        294,
        428,
        1065,
        2715,
        322,
        6949,
        5760,
        51504
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19091414125173684,
      "compression_ratio": 1.812883435582822,
      "no_speech_prob": 0.4198133051395416
    },
    {
      "id": 718,
      "seek": 165572,
      "start": 1678.52,
      "end": 1681.4,
      "text": " servers, on virtual machines, or even just on your one computer.",
      "tokens": [
        51504,
        15909,
        11,
        322,
        6374,
        8379,
        11,
        420,
        754,
        445,
        322,
        428,
        472,
        3820,
        13,
        51648
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19091414125173684,
      "compression_ratio": 1.812883435582822,
      "no_speech_prob": 0.4198133051395416
    },
    {
      "id": 719,
      "seek": 165572,
      "start": 1681.4,
      "end": 1683.2,
      "text": " They have what's called Minicube.",
      "tokens": [
        51648,
        814,
        362,
        437,
        311,
        1219,
        2829,
        299,
        1977,
        13,
        51738
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19091414125173684,
      "compression_ratio": 1.812883435582822,
      "no_speech_prob": 0.4198133051395416
    },
    {
      "id": 720,
      "seek": 165572,
      "start": 1683.2,
      "end": 1685.4,
      "text": " And you can just run Kubernetes on one workstation.",
      "tokens": [
        51738,
        400,
        291,
        393,
        445,
        1190,
        23145,
        322,
        472,
        589,
        19159,
        13,
        51848
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19091414125173684,
      "compression_ratio": 1.812883435582822,
      "no_speech_prob": 0.4198133051395416
    },
    {
      "id": 721,
      "seek": 168540,
      "start": 1685.4,
      "end": 1686.4,
      "text": " That's pretty cool.",
      "tokens": [
        50364,
        663,
        311,
        1238,
        1627,
        13,
        50414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1261907519716205,
      "compression_ratio": 1.8224299065420562,
      "no_speech_prob": 0.023246774449944496
    },
    {
      "id": 722,
      "seek": 168540,
      "start": 1686.4,
      "end": 1687.4,
      "text": " So there are options.",
      "tokens": [
        50414,
        407,
        456,
        366,
        3956,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1261907519716205,
      "compression_ratio": 1.8224299065420562,
      "no_speech_prob": 0.023246774449944496
    },
    {
      "id": 723,
      "seek": 168540,
      "start": 1687.4,
      "end": 1689.5600000000002,
      "text": " But anyways, let me know what you think in the comments below.",
      "tokens": [
        50464,
        583,
        13448,
        11,
        718,
        385,
        458,
        437,
        291,
        519,
        294,
        264,
        3053,
        2507,
        13,
        50572
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1261907519716205,
      "compression_ratio": 1.8224299065420562,
      "no_speech_prob": 0.023246774449944496
    },
    {
      "id": 724,
      "seek": 168540,
      "start": 1689.5600000000002,
      "end": 1691.6000000000001,
      "text": " Let me know if you're able to go through the lab.",
      "tokens": [
        50572,
        961,
        385,
        458,
        498,
        291,
        434,
        1075,
        281,
        352,
        807,
        264,
        2715,
        13,
        50674
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1261907519716205,
      "compression_ratio": 1.8224299065420562,
      "no_speech_prob": 0.023246774449944496
    },
    {
      "id": 725,
      "seek": 168540,
      "start": 1691.6000000000001,
      "end": 1694.2,
      "text": " If you think Kubernetes is amazing, just let me know below.",
      "tokens": [
        50674,
        759,
        291,
        519,
        23145,
        307,
        2243,
        11,
        445,
        718,
        385,
        458,
        2507,
        13,
        50804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1261907519716205,
      "compression_ratio": 1.8224299065420562,
      "no_speech_prob": 0.023246774449944496
    },
    {
      "id": 726,
      "seek": 168540,
      "start": 1694.2,
      "end": 1697.88,
      "text": " I love seeing your comments and it really encourages me to keep going and keep making",
      "tokens": [
        50804,
        286,
        959,
        2577,
        428,
        3053,
        293,
        309,
        534,
        28071,
        385,
        281,
        1066,
        516,
        293,
        1066,
        1455,
        50988
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1261907519716205,
      "compression_ratio": 1.8224299065420562,
      "no_speech_prob": 0.023246774449944496
    },
    {
      "id": 727,
      "seek": 168540,
      "start": 1697.88,
      "end": 1698.88,
      "text": " videos like this.",
      "tokens": [
        50988,
        2145,
        411,
        341,
        13,
        51038
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1261907519716205,
      "compression_ratio": 1.8224299065420562,
      "no_speech_prob": 0.023246774449944496
    },
    {
      "id": 728,
      "seek": 168540,
      "start": 1698.88,
      "end": 1700.52,
      "text": " Well, that's all I got.",
      "tokens": [
        51038,
        1042,
        11,
        300,
        311,
        439,
        286,
        658,
        13,
        51120
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1261907519716205,
      "compression_ratio": 1.8224299065420562,
      "no_speech_prob": 0.023246774449944496
    },
    {
      "id": 729,
      "seek": 168540,
      "start": 1700.52,
      "end": 1702.0800000000002,
      "text": " This video took a lot.",
      "tokens": [
        51120,
        639,
        960,
        1890,
        257,
        688,
        13,
        51198
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1261907519716205,
      "compression_ratio": 1.8224299065420562,
      "no_speech_prob": 0.023246774449944496
    },
    {
      "id": 730,
      "seek": 168540,
      "start": 1702.0800000000002,
      "end": 1704.52,
      "text": " I had to learn Kubernetes from the ground up.",
      "tokens": [
        51198,
        286,
        632,
        281,
        1466,
        23145,
        490,
        264,
        2727,
        493,
        13,
        51320
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1261907519716205,
      "compression_ratio": 1.8224299065420562,
      "no_speech_prob": 0.023246774449944496
    },
    {
      "id": 731,
      "seek": 168540,
      "start": 1704.52,
      "end": 1706.0400000000002,
      "text": " But it's fun learning new things.",
      "tokens": [
        51320,
        583,
        309,
        311,
        1019,
        2539,
        777,
        721,
        13,
        51396
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1261907519716205,
      "compression_ratio": 1.8224299065420562,
      "no_speech_prob": 0.023246774449944496
    },
    {
      "id": 732,
      "seek": 168540,
      "start": 1706.0400000000002,
      "end": 1708.6000000000001,
      "text": " And I encourage you to do what I did.",
      "tokens": [
        51396,
        400,
        286,
        5373,
        291,
        281,
        360,
        437,
        286,
        630,
        13,
        51524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1261907519716205,
      "compression_ratio": 1.8224299065420562,
      "no_speech_prob": 0.023246774449944496
    },
    {
      "id": 733,
      "seek": 168540,
      "start": 1708.6000000000001,
      "end": 1712.52,
      "text": " When you learn something new like this, turn it around and make a video about it or make",
      "tokens": [
        51524,
        1133,
        291,
        1466,
        746,
        777,
        411,
        341,
        11,
        1261,
        309,
        926,
        293,
        652,
        257,
        960,
        466,
        309,
        420,
        652,
        51720
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1261907519716205,
      "compression_ratio": 1.8224299065420562,
      "no_speech_prob": 0.023246774449944496
    },
    {
      "id": 734,
      "seek": 168540,
      "start": 1712.52,
      "end": 1714.2,
      "text": " a blog post.",
      "tokens": [
        51720,
        257,
        6968,
        2183,
        13,
        51804
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1261907519716205,
      "compression_ratio": 1.8224299065420562,
      "no_speech_prob": 0.023246774449944496
    },
    {
      "id": 735,
      "seek": 171420,
      "start": 1714.2,
      "end": 1715.88,
      "text": " Teach someone about it.",
      "tokens": [
        50364,
        26816,
        1580,
        466,
        309,
        13,
        50448
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1845399956954153,
      "compression_ratio": 1.7376543209876543,
      "no_speech_prob": 0.43215587735176086
    },
    {
      "id": 736,
      "seek": 171420,
      "start": 1715.88,
      "end": 1716.88,
      "text": " Really two things happen.",
      "tokens": [
        50448,
        4083,
        732,
        721,
        1051,
        13,
        50498
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1845399956954153,
      "compression_ratio": 1.7376543209876543,
      "no_speech_prob": 0.43215587735176086
    },
    {
      "id": 737,
      "seek": 171420,
      "start": 1716.88,
      "end": 1718.76,
      "text": " You learn it better when you teach it.",
      "tokens": [
        50498,
        509,
        1466,
        309,
        1101,
        562,
        291,
        2924,
        309,
        13,
        50592
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1845399956954153,
      "compression_ratio": 1.7376543209876543,
      "no_speech_prob": 0.43215587735176086
    },
    {
      "id": 738,
      "seek": 171420,
      "start": 1718.76,
      "end": 1720.2,
      "text": " And also you're helping people.",
      "tokens": [
        50592,
        400,
        611,
        291,
        434,
        4315,
        561,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1845399956954153,
      "compression_ratio": 1.7376543209876543,
      "no_speech_prob": 0.43215587735176086
    },
    {
      "id": 739,
      "seek": 171420,
      "start": 1720.2,
      "end": 1723.92,
      "text": " You're helping someone else who's coming behind you to learn that same technology.",
      "tokens": [
        50664,
        509,
        434,
        4315,
        1580,
        1646,
        567,
        311,
        1348,
        2261,
        291,
        281,
        1466,
        300,
        912,
        2899,
        13,
        50850
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1845399956954153,
      "compression_ratio": 1.7376543209876543,
      "no_speech_prob": 0.43215587735176086
    },
    {
      "id": 740,
      "seek": 171420,
      "start": 1723.92,
      "end": 1729.4,
      "text": " And then third, kind of a bonus, it shows future employers that you can first of all",
      "tokens": [
        50850,
        400,
        550,
        2636,
        11,
        733,
        295,
        257,
        10882,
        11,
        309,
        3110,
        2027,
        16744,
        300,
        291,
        393,
        700,
        295,
        439,
        51124
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1845399956954153,
      "compression_ratio": 1.7376543209876543,
      "no_speech_prob": 0.43215587735176086
    },
    {
      "id": 741,
      "seek": 171420,
      "start": 1729.4,
      "end": 1731.72,
      "text": " communicate and learn something new.",
      "tokens": [
        51124,
        7890,
        293,
        1466,
        746,
        777,
        13,
        51240
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1845399956954153,
      "compression_ratio": 1.7376543209876543,
      "no_speech_prob": 0.43215587735176086
    },
    {
      "id": 742,
      "seek": 171420,
      "start": 1731.72,
      "end": 1732.72,
      "text": " You're hungry for knowledge.",
      "tokens": [
        51240,
        509,
        434,
        8067,
        337,
        3601,
        13,
        51290
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1845399956954153,
      "compression_ratio": 1.7376543209876543,
      "no_speech_prob": 0.43215587735176086
    },
    {
      "id": 743,
      "seek": 171420,
      "start": 1732.72,
      "end": 1734.24,
      "text": " Anyways, yeah, that's really all I got.",
      "tokens": [
        51290,
        15585,
        11,
        1338,
        11,
        300,
        311,
        534,
        439,
        286,
        658,
        13,
        51366
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1845399956954153,
      "compression_ratio": 1.7376543209876543,
      "no_speech_prob": 0.43215587735176086
    },
    {
      "id": 744,
      "seek": 171420,
      "start": 1734.24,
      "end": 1736.04,
      "text": " I'm going to stop talking now.",
      "tokens": [
        51366,
        286,
        478,
        516,
        281,
        1590,
        1417,
        586,
        13,
        51456
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1845399956954153,
      "compression_ratio": 1.7376543209876543,
      "no_speech_prob": 0.43215587735176086
    },
    {
      "id": 745,
      "seek": 171420,
      "start": 1736.04,
      "end": 1737.4,
      "text": " If you haven't already hit that like button.",
      "tokens": [
        51456,
        759,
        291,
        2378,
        380,
        1217,
        2045,
        300,
        411,
        2960,
        13,
        51524
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1845399956954153,
      "compression_ratio": 1.7376543209876543,
      "no_speech_prob": 0.43215587735176086
    },
    {
      "id": 746,
      "seek": 171420,
      "start": 1737.4,
      "end": 1739.16,
      "text": " If you like the video, it does help.",
      "tokens": [
        51524,
        759,
        291,
        411,
        264,
        960,
        11,
        309,
        775,
        854,
        13,
        51612
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1845399956954153,
      "compression_ratio": 1.7376543209876543,
      "no_speech_prob": 0.43215587735176086
    },
    {
      "id": 747,
      "seek": 171420,
      "start": 1739.16,
      "end": 1742.16,
      "text": " Subscribe, notification bell, you know, all that stuff.",
      "tokens": [
        51612,
        10611,
        11,
        11554,
        4549,
        11,
        291,
        458,
        11,
        439,
        300,
        1507,
        13,
        51762
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1845399956954153,
      "compression_ratio": 1.7376543209876543,
      "no_speech_prob": 0.43215587735176086
    },
    {
      "id": 748,
      "seek": 174216,
      "start": 1742.16,
      "end": 1747.0400000000002,
      "text": " And if you want to help me do more of this, make training, make videos, make certification",
      "tokens": [
        50364,
        400,
        498,
        291,
        528,
        281,
        854,
        385,
        360,
        544,
        295,
        341,
        11,
        652,
        3097,
        11,
        652,
        2145,
        11,
        652,
        21775,
        50608
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2346409131895821,
      "compression_ratio": 1.5569620253164558,
      "no_speech_prob": 0.27184435725212097
    },
    {
      "id": 749,
      "seek": 174216,
      "start": 1747.0400000000002,
      "end": 1752.6000000000001,
      "text": " stuff, check out this as IT or hit the join button on the YouTube thing below.",
      "tokens": [
        50608,
        1507,
        11,
        1520,
        484,
        341,
        382,
        6783,
        420,
        2045,
        264,
        3917,
        2960,
        322,
        264,
        3088,
        551,
        2507,
        13,
        50886
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2346409131895821,
      "compression_ratio": 1.5569620253164558,
      "no_speech_prob": 0.27184435725212097
    },
    {
      "id": 750,
      "seek": 174216,
      "start": 1752.6000000000001,
      "end": 1753.6000000000001,
      "text": " Or you know what?",
      "tokens": [
        50886,
        1610,
        291,
        458,
        437,
        30,
        50936
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2346409131895821,
      "compression_ratio": 1.5569620253164558,
      "no_speech_prob": 0.27184435725212097
    },
    {
      "id": 751,
      "seek": 174216,
      "start": 1753.6000000000001,
      "end": 1756.2,
      "text": " You can buy some network check copy because it's a legit thing.",
      "tokens": [
        50936,
        509,
        393,
        2256,
        512,
        3209,
        1520,
        5055,
        570,
        309,
        311,
        257,
        10275,
        551,
        13,
        51066
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2346409131895821,
      "compression_ratio": 1.5569620253164558,
      "no_speech_prob": 0.27184435725212097
    },
    {
      "id": 752,
      "seek": 174216,
      "start": 1756.2,
      "end": 1757.44,
      "text": " Go to networkcheck.coffee.",
      "tokens": [
        51066,
        1037,
        281,
        3209,
        15723,
        13,
        1291,
        4617,
        13,
        51128
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2346409131895821,
      "compression_ratio": 1.5569620253164558,
      "no_speech_prob": 0.27184435725212097
    },
    {
      "id": 753,
      "seek": 174216,
      "start": 1757.44,
      "end": 1759.76,
      "text": " You can actually go to my real website.",
      "tokens": [
        51128,
        509,
        393,
        767,
        352,
        281,
        452,
        957,
        3144,
        13,
        51244
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2346409131895821,
      "compression_ratio": 1.5569620253164558,
      "no_speech_prob": 0.27184435725212097
    },
    {
      "id": 754,
      "seek": 174216,
      "start": 1759.76,
      "end": 1761.52,
      "text": " Well guys, that's all I got.",
      "tokens": [
        51244,
        1042,
        1074,
        11,
        300,
        311,
        439,
        286,
        658,
        13,
        51332
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2346409131895821,
      "compression_ratio": 1.5569620253164558,
      "no_speech_prob": 0.27184435725212097
    },
    {
      "id": 755,
      "seek": 174216,
      "start": 1761.52,
      "end": 1762.16,
      "text": " I'll catch you later.",
      "tokens": [
        51332,
        286,
        603,
        3745,
        291,
        1780,
        13,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2346409131895821,
      "compression_ratio": 1.5569620253164558,
      "no_speech_prob": 0.27184435725212097
    }
  ],
  "processing_metadata": {
    "processed_at": "2025-06-25T23:06:44.004915",
    "whisper_model": "small",
    "personality_detected": "networkchuck",
    "domain_focus": "technology_networking"
  },
  "source_metadata": {
    "url": "https://www.youtube.com/watch?v=7bA0gTroJjw",
    "title": "you need to learn Kubernetes RIGHT NOW!!",
    "category": "Cloud Computing & Containers",
    "difficulty": "advanced",
    "key_topics": [
      "Kubernetes",
      "orchestration",
      "containers",
      "deployment"
    ],
    "priority": "high"
  }
}
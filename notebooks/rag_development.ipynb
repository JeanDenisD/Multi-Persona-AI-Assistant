{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362e0851",
   "metadata": {},
   "source": [
    "# NetworkChuck AI Chatbot - RAG Development & Testing\n",
    "## Interactive development and testing of the RAG system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bf90b0",
   "metadata": {},
   "source": [
    "### 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eec697d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# === SETUP AND IMPORTS ===\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "import logging\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd()\n",
    "if 'notebooks' in str(project_root):\n",
    "    project_root = project_root.parent\n",
    "sys.path.append(str(project_root / 'src'))\n",
    "\n",
    "# Third-party imports\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "import openai\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a29abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RAG RETRIEVER ===\n",
    "class RAGRetriever:\n",
    "    def __init__(self, index_name: str = \"networkchuck-ai-chatbot\"):\n",
    "        self.index_name = index_name\n",
    "        self.setup_components()\n",
    "        \n",
    "    def setup_components(self):\n",
    "        # Initialize embeddings\n",
    "        self.embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    "        )\n",
    "        \n",
    "        # Connect to vectorstore\n",
    "        self.vectorstore = LangchainPinecone.from_existing_index(\n",
    "            index_name=self.index_name,\n",
    "            embedding=self.embeddings\n",
    "        )\n",
    "        print(\"‚úÖ RAG Retriever ready!\")\n",
    "    \n",
    "    def retrieve_context(self, query: str, personality: str, top_k: int = 5):\n",
    "        metadata_filter = {\"personality\": personality}\n",
    "        docs = self.vectorstore.similarity_search_with_score(\n",
    "            query=query, k=top_k, filter=metadata_filter\n",
    "        )\n",
    "        return [(doc, score) for doc, score in docs]\n",
    "    \n",
    "    def format_context(self, doc_score_pairs: List[Tuple], max_length: int = 3000):\n",
    "        if not doc_score_pairs:\n",
    "            return \"No relevant context found.\"\n",
    "        \n",
    "        context_parts = []\n",
    "        current_length = 0\n",
    "        \n",
    "        for doc, score in doc_score_pairs:\n",
    "            video_title = doc.metadata.get('video_title', 'Unknown Video')\n",
    "            timestamp = doc.metadata.get('start_time', 0)\n",
    "            entry = f\"[From: {video_title} at {timestamp}s] (Score: {score:.3f})\\n{doc.page_content}\\n\\n\"\n",
    "            \n",
    "            if current_length + len(entry) > max_length:\n",
    "                break\n",
    "            context_parts.append(entry)\n",
    "            current_length += len(entry)\n",
    "        \n",
    "        return \"\".join(context_parts).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fd5e4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PERSONALITY PROMPTS ===\n",
    "class PersonalityPromptManager:\n",
    "    def __init__(self):\n",
    "        self.personalities = {\n",
    "            \"networkchuck\": {\n",
    "                \"system_prompt\": \"\"\"You are NetworkChuck, an enthusiastic cybersecurity and networking expert who loves to teach technology in an engaging, hands-on way.\n",
    "\n",
    "PERSONALITY TRAITS:\n",
    "- Energetic and passionate about technology\n",
    "- Uses casual, friendly language with occasional excitement\n",
    "- Loves practical, hands-on demonstrations  \n",
    "- Often mentions coffee and encourages learning\n",
    "- Explains complex topics in simple terms\n",
    "- Focuses on real-world applications\n",
    "\n",
    "EXPERTISE: Networking, cybersecurity, Linux, cloud computing, Python, DevOps\n",
    "\n",
    "RESPONSE STYLE:\n",
    "- Start with enthusiasm\n",
    "- Break down concepts step-by-step\n",
    "- Include practical examples\n",
    "- Use analogies to make concepts relatable\n",
    "- Encourage hands-on practice\n",
    "- End with motivation to keep learning\"\"\"\n",
    "            },\n",
    "            \"bloomy\": {\n",
    "                \"system_prompt\": \"\"\"You are Bloomy, a professional financial analyst and Excel expert with deep knowledge of Bloomberg Terminal and advanced financial modeling.\n",
    "\n",
    "PERSONALITY TRAITS:\n",
    "- Professional and analytical approach\n",
    "- Precise and detail-oriented\n",
    "- Focuses on practical financial applications\n",
    "- Values efficiency and accuracy\n",
    "- Explains complex financial concepts clearly\n",
    "- Emphasizes best practices and industry standards\n",
    "\n",
    "EXPERTISE: Bloomberg Terminal, Excel, financial modeling, VBA, Power Query, risk management\n",
    "\n",
    "RESPONSE STYLE:\n",
    "- Professional but approachable tone\n",
    "- Structured, logical explanations\n",
    "- Focus on practical financial applications\n",
    "- Include specific function names and shortcuts\n",
    "- Emphasize accuracy and best practices\"\"\"\n",
    "            }\n",
    "        }\n",
    "        print(\"‚úÖ Personality prompts loaded!\")\n",
    "    \n",
    "    def build_prompt(self, personality: str, user_query: str, context: str):\n",
    "        config = self.personalities.get(personality.lower())\n",
    "        if not config:\n",
    "            raise ValueError(f\"Unknown personality: {personality}\")\n",
    "        \n",
    "        return f\"\"\"{config['system_prompt']}\n",
    "\n",
    "RELEVANT CONTEXT FROM YOUR VIDEOS:\n",
    "{context}\n",
    "\n",
    "USER QUESTION: {user_query}\n",
    "\n",
    "Please respond as {personality.title()}, using the context from your videos while maintaining your authentic personality and teaching style.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed56c50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG Retriever ready!\n",
      "‚úÖ Personality prompts loaded!\n",
      "‚úÖ RAG Engine ready!\n"
     ]
    }
   ],
   "source": [
    "# === RAG ENGINE ===\n",
    "class RAGEngine:\n",
    "    def __init__(self):\n",
    "        self.retriever = RAGRetriever()\n",
    "        self.prompt_manager = PersonalityPromptManager()\n",
    "        self.client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "        print(\"‚úÖ RAG Engine ready!\")\n",
    "    \n",
    "    def generate_response(self, user_query: str, personality: str = \"networkchuck\"):\n",
    "        try:\n",
    "            # Retrieve context\n",
    "            doc_score_pairs = self.retriever.retrieve_context(user_query, personality)\n",
    "            context = self.retriever.format_context(doc_score_pairs)\n",
    "            \n",
    "            # Build prompt\n",
    "            prompt = self.prompt_manager.build_prompt(personality, user_query, context)\n",
    "            \n",
    "            # Generate response\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "                temperature=0 # 0.7\n",
    "            )\n",
    "            \n",
    "            return {\n",
    "                \"response\": response.choices[0].message.content,\n",
    "                \"context\": context,\n",
    "                \"sources\": len(doc_score_pairs),\n",
    "                \"personality\": personality\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"response\": f\"Sorry, I encountered an error: {e}\",\n",
    "                \"context\": \"\",\n",
    "                \"sources\": 0,\n",
    "                \"personality\": personality\n",
    "            }\n",
    "\n",
    "# Initialize RAG Engine\n",
    "rag_engine = RAGEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "247b6597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test function ready!\n"
     ]
    }
   ],
   "source": [
    "# === TEST FUNCTION ===\n",
    "def test_query(query: str, personality: str = \"networkchuck\"):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ü§ñ Testing {personality.upper()} personality\")\n",
    "    print(f\"‚ùì Query: {query}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    result = rag_engine.generate_response(query, personality)\n",
    "    \n",
    "    print(f\"\\nüìä RESULTS:\")\n",
    "    print(f\"Sources found: {result['sources']}\")\n",
    "    print(f\"Context length: {len(result['context'])} characters\")\n",
    "    print(f\"\\nü§ñ RESPONSE:\")\n",
    "    print(result['response'])\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"‚úÖ Test function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0703aea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gradio interface created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeand\\AppData\\Local\\Temp\\ipykernel_34712\\1697031208.py:20: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Chat History\")\n"
     ]
    }
   ],
   "source": [
    "# === GRADIO INTERFACE ===\n",
    "def create_gradio_interface():\n",
    "    def chat_interface(message, personality, history):\n",
    "        result = rag_engine.generate_response(message, personality.lower())\n",
    "        history.append((message, result['response']))\n",
    "        return history, \"\"\n",
    "    \n",
    "    with gr.Blocks(title=\"NetworkChuck AI Chatbot\") as interface:\n",
    "        gr.Markdown(\"# ü§ñ NetworkChuck AI Chatbot\")\n",
    "        gr.Markdown(\"Choose a personality and start chatting!\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                personality = gr.Radio(\n",
    "                    choices=[\"NetworkChuck\", \"Bloomy\"],\n",
    "                    value=\"NetworkChuck\",\n",
    "                    label=\"Choose Personality\"\n",
    "                )\n",
    "                \n",
    "                chatbot = gr.Chatbot(label=\"Chat History\")\n",
    "                msg = gr.Textbox(\n",
    "                    label=\"Your Message\",\n",
    "                    placeholder=\"Ask me about networking, cybersecurity, Excel, or finance!\",\n",
    "                    lines=2\n",
    "                )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    submit_btn = gr.Button(\"Send\", variant=\"primary\")\n",
    "                    clear_btn = gr.Button(\"Clear Chat\")\n",
    "        \n",
    "        # Event handlers\n",
    "        submit_btn.click(chat_interface, [msg, personality, chatbot], [chatbot, msg])\n",
    "        msg.submit(chat_interface, [msg, personality, chatbot], [chatbot, msg])\n",
    "        clear_btn.click(lambda: ([], \"\"), outputs=[chatbot, msg])\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create interface\n",
    "gradio_app = create_gradio_interface()\n",
    "print(\"‚úÖ Gradio interface created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7113f4",
   "metadata": {},
   "source": [
    "## üöÄ Ready to Use!\n",
    "\n",
    "### Test Individual Queries:\n",
    "```python\n",
    "test_query(\"How do I set up Docker containers?\", \"networkchuck\")\n",
    "test_query(\"How do I use VLOOKUP in Excel?\", \"bloomy\")\n",
    "```\n",
    "\n",
    "### Launch Web Interface:\n",
    "```python\n",
    "gradio_app.launch()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b0ed2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ü§ñ Testing BLOOMY personality\n",
      "‚ùì Query: How to create a table in Excel\n",
      "============================================================\n",
      "\n",
      "üìä RESULTS:\n",
      "Sources found: 5\n",
      "Context length: 677 characters\n",
      "\n",
      "ü§ñ RESPONSE:\n",
      "To create a table in Excel, you can follow these steps:\n",
      "\n",
      "1. Select the data range that you want to include in your table.\n",
      "2. Go to the \"Insert\" tab on the Excel ribbon.\n",
      "3. Click on the \"Table\" option. This will prompt a dialog box where Excel will automatically select the data range for your table.\n",
      "4. Ensure that the \"My table has headers\" box is checked if your data includes headers.\n",
      "5. Click \"OK\" to create the table.\n",
      "\n",
      "By creating a table in Excel, you can easily manage and analyze your data. Tables offer features like structured formatting, automatic filtering, and dynamic ranges that can enhance your data analysis capabilities.\n",
      "\n",
      "If you encounter any issues or have further questions about creating tables in Excel, feel free to ask for more guidance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': 'To create a table in Excel, you can follow these steps:\\n\\n1. Select the data range that you want to include in your table.\\n2. Go to the \"Insert\" tab on the Excel ribbon.\\n3. Click on the \"Table\" option. This will prompt a dialog box where Excel will automatically select the data range for your table.\\n4. Ensure that the \"My table has headers\" box is checked if your data includes headers.\\n5. Click \"OK\" to create the table.\\n\\nBy creating a table in Excel, you can easily manage and analyze your data. Tables offer features like structured formatting, automatic filtering, and dynamic ranges that can enhance your data analysis capabilities.\\n\\nIf you encounter any issues or have further questions about creating tables in Excel, feel free to ask for more guidance.',\n",
       " 'context': '[From: How to use the Bloomberg Data Set (BDS) function in Excel (2 minutes) at 10.12s] (Score: 0.575)\\nin Excel.\\n\\n[From: How to use the Bloomberg Query Language (BQL) Builder for panel data in Excel at 21.96s] (Score: 0.575)\\nin Excel.\\n\\n[From: How to use the Bloomberg Data Point (BDP) function in Excel (2 minutes) at 10.16s] (Score: 0.541)\\nfunction in Excel.\\n\\n[From: How to use the Bloomberg Data History (BDH) function in Excel (2 minutes) at 10.04s] (Score: 0.541)\\nfunction in Excel.\\n\\n[From: Watch this to solve circular reference errors in Excel (2 minutes) at 37.56s] (Score: 0.540)\\nSo to illustrate the problem with circular references in Excel I created this small table',\n",
       " 'sources': 5,\n",
       " 'personality': 'bloomy'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === LAUNCH ===\n",
    "# Test it works\n",
    "test_query(\"How to create a table in Excel\", \"bloomy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d93256ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch web interface\n",
    "gradio_app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-chatbot-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
